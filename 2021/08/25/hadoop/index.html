<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="大数据大数据概念 大数据（Big Data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。 大数据主要解决，海量数据的采集、存储和分析计算问题。 按顺序给出数据存储单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。 1 Byte &#x3D; 8">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop 入门">
<meta property="og:url" content="http://example.com/2021/08/25/hadoop/index.html">
<meta property="og:site_name" content="XiSun的博客">
<meta property="og:description" content="大数据大数据概念 大数据（Big Data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。 大数据主要解决，海量数据的采集、存储和分析计算问题。 按顺序给出数据存储单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。 1 Byte &#x3D; 8">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825170020065.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825170536329.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825171613059.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825171705459.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825171731759.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825171816855.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825173206311.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210826101511233.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825232032562.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825232856313.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210825233533121.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210826110750495.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831115613196.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831143510629.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831114058447.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831144645384.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831153016702.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831153058005.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831153154765.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210831154042555.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210901133253592.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210901151616233.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909161942025.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909163524558.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909162213537.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909162538370.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903165511703.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210901231013153.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210901231122710.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210901232124548.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902101737216.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902101938588.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902102355046.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903145651737.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902104359318.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903150350257.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903150602428.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902111343188.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902132243410.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902152328283.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902152507027.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902153939242.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902153854565.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210902165115208.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903163243434.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903165715516.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903165748149.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903170115237.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210903170728742.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906163539785.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906163702812.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906233413928.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906232417504.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906232525065.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906232834423.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210906233140290.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907150906533.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907153615806.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907154935556.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907155850375.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907155455332.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907155532293.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907161117479.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907171215574.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210907171344066.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908104338787.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908104610376.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908091317080.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908102248682.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908105937977.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908114133555.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908162349654.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210908232731057.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909092530067.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909113318240.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909132534626.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909152245552.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909132534626.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909153850477.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909164336456.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909170809620.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909171256904.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909173251464.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210909234011348.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210910171552241.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210910230253307.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210912181004046.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210912180732521.png">
<meta property="og:image" content="http://example.com/2021/08/25/hadoop/image-20210912180838645.png">
<meta property="article:published_time" content="2021-08-25T07:53:38.000Z">
<meta property="article:modified_time" content="2022-01-12T02:43:37.786Z">
<meta property="article:author" content="XiSun">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/08/25/hadoop/image-20210825170020065.png">

<link rel="canonical" href="http://example.com/2021/08/25/hadoop/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop 入门 | XiSun的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">XiSun的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Learning is endless</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/08/25/hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="XiSun">
      <meta itemprop="description" content="心如止水者，虽世间繁华之红尘纷扰，已然空无一物">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XiSun的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop 入门
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-25 15:53:38" itemprop="dateCreated datePublished" datetime="2021-08-25T15:53:38+08:00">2021-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-01-12 10:43:37" itemprop="dateModified" datetime="2022-01-12T10:43:37+08:00">2022-01-12</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>168k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2:33</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><h3 id="大数据概念"><a href="#大数据概念" class="headerlink" title="大数据概念"></a>大数据概念</h3><ul>
<li>大数据（Big Data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</li>
<li><strong>大数据主要解决，海量数据的采集、存储和分析计算问题。</strong></li>
<li>按顺序给出数据存储单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。<ul>
<li><code>1 Byte = 8 bit</code>，<code>1 KB = 1024 Byte</code>，<code>1 MB = 1024 KB</code>，<code>1 GB = 1024 MB</code>，<code>1 TB = 1024 GB</code>，<code>1 PB= 1024 TB</code></li>
</ul>
</li>
</ul>
<h3 id="大数据特点"><a href="#大数据特点" class="headerlink" title="大数据特点"></a>大数据特点</h3><ul>
<li>Volume（大量）<ul>
<li>截至目前，人类生产的所有印刷材料的数据量是 200 PB，而历史上全人类总共说过的话的数据量大约是 5 EB。当前，典型个人计算机硬盘的容量为 TB 量级，而一些大企业的数据量已经接近 EB 量级。</li>
</ul>
</li>
<li>Velocity（高速）<ul>
<li>这是大数据区分于传统数据挖掘的最显著特征。根据 IDC 的“数字宇宙”的报告，预计到 2025 年，全球数据使用量将达到 163 ZB。在如此海量的数据面前，处理数据的效率就是企业的生命。</li>
<li>天猫双十一：2017 年，3 分 01 秒，天猫交易额超过 100 亿；2020 年，96 秒，天猫交易额超过 100 亿。</li>
</ul>
</li>
<li>Variety（多样）<ul>
<li>这种类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的以数据库/文本为主的结构化数据，非结构化数据越来越多，包括网络日志、音频、视频、图片、地理位置信息等，这些多类型的数据对数据的处理能力提出了更高要求。</li>
</ul>
</li>
<li>Value（低价值密度）<ul>
<li>价值密度的高低与数据总量的大小成反比。比如，在一天的监控视频中，我们只关心宋老师晚上在床上健身那一分钟，如何快速对有价值数据“提纯”，成为目前大数据背景下待解决的难题。</li>
</ul>
</li>
</ul>
<h2 id="Hadoop-概述"><a href="#Hadoop-概述" class="headerlink" title="Hadoop 概述"></a>Hadoop 概述</h2><h3 id="Hadoop-是什么"><a href="#Hadoop-是什么" class="headerlink" title="Hadoop 是什么"></a>Hadoop 是什么</h3><ul>
<li><p>Hadoop 是一个由 Apache 基金会所开发的<strong>分布式系统基础架构</strong>。</p>
</li>
<li><p><strong>主要解决，海量数据的存储和海量数据的分析计算问题。</strong></p>
</li>
<li><p>广义上来说，Hadoop 通常是指一个更广泛的概念 — Hadoop 生态圈。</p>
<p><img src="/2021/08/25/hadoop/image-20210825170020065.png" alt="image-20210825170020065"></p>
</li>
</ul>
<h3 id="Hadoop-发展历史"><a href="#Hadoop-发展历史" class="headerlink" title="Hadoop 发展历史"></a>Hadoop 发展历史</h3><ul>
<li><p>Hadoop 创始人 Doug Cutting，为了实现与 Google 类似的全文搜索功能，他在 Lucene 框架基础上进行优化升级，查询引擎和索引引擎。</p>
</li>
<li><p>2001 年年底，Lucene 成为 Apache 基金会的一个子项目。</p>
</li>
<li><p>对于海量数据的场景，Lucene 框架面对与 Google 同样的困难，存储海量数据困难，检索海量速度慢。</p>
</li>
<li><p>学习和模仿 Google 解决这些问题的办法：微型版 Nutch。</p>
</li>
<li><p>可以说 Google 是 Hadoop 的思想之源（Google 在大数据方面的三篇论文）：</p>
<ul>
<li>GFS —&gt; HDFS</li>
<li>MapReduce —&gt; MR</li>
<li>BigTable —&gt; HBase</li>
</ul>
</li>
<li><p>2003 - 2004 年，Google 公开了部分 GFS 和 MapReduce 思想的细节，以此为基础，Doug Cutting 等人用了 2 年业余时间实现了 DFS 和 MapReduce 机制，使 Nutch 性能飙升。</p>
</li>
<li><p>2005 年，Hadoop 作为 Lucene 的子项目 Nutch 的一部分正式引入 Apache 基金会。</p>
</li>
<li><p>2006 年 3 月份，MapReduce 和 Nutch Distributed File System（NDFS）分别被纳入到 Hadoop 项目中，Hadoop 就此正式诞生，标志着大数据时代来临。</p>
</li>
<li><p>名字来源于 Doug Cutting 儿子的玩具大象：</p>
<p><img src="/2021/08/25/hadoop/image-20210825170536329.png" alt="image-20210825170536329"></p>
</li>
</ul>
<h3 id="Hadoop-三大发行版本"><a href="#Hadoop-三大发行版本" class="headerlink" title="Hadoop 三大发行版本"></a>Hadoop 三大发行版本</h3><ul>
<li>Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。</li>
<li>Apache 版本是最原始（最基础）的版本，对于入门学习最好。— 2006 年</li>
<li>Cloudera 内部集成了很多大数据框架，对应产品 CDH。— 2008 年</li>
<li>Hortonworks 文档较好，对应产品 HDP。— 2011 年<ul>
<li>Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。</li>
</ul>
</li>
</ul>
<h4 id="Apache-Hadoop"><a href="#Apache-Hadoop" class="headerlink" title="Apache Hadoop"></a>Apache Hadoop</h4><ul>
<li>官网地址：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/releases.html">https://hadoop.apache.org/releases.html</a></li>
</ul>
<h4 id="Cloudera-Hadoop"><a href="#Cloudera-Hadoop" class="headerlink" title="Cloudera Hadoop"></a>Cloudera Hadoop</h4><ul>
<li>官网地址：<a target="_blank" rel="noopener" href="https://www.cloudera.com/downloads/cdh">https://www.cloudera.com/downloads/cdh</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_6_download.html">https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_6_download.html</a></li>
</ul>
<h4 id="Hortonworks-Hadoop"><a href="#Hortonworks-Hadoop" class="headerlink" title="Hortonworks Hadoop"></a>Hortonworks Hadoop</h4><ul>
<li>官网地址：<a target="_blank" rel="noopener" href="https://hortonworks.com/products/data-center/hdp/">https://hortonworks.com/products/data-center/hdp/</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="https://hortonworks.com/downloads/#data-platform">https://hortonworks.com/downloads/#data-platform</a></li>
</ul>
<h3 id="Hadoop-优势"><a href="#Hadoop-优势" class="headerlink" title="Hadoop 优势"></a>Hadoop 优势</h3><ul>
<li><p>高可靠性：Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。</p>
<p><img src="/2021/08/25/hadoop/image-20210825171613059.png" alt="image-20210825171613059"></p>
</li>
<li><p>高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。</p>
<p><img src="/2021/08/25/hadoop/image-20210825171705459.png" alt="image-20210825171705459"></p>
</li>
<li><p>高效性：在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。</p>
<p><img src="/2021/08/25/hadoop/image-20210825171731759.png" alt="image-20210825171731759"></p>
</li>
<li><p>高容错性：能够自动将失败的任务重新分配。</p>
<p><img src="/2021/08/25/hadoop/image-20210825171816855.png" alt="image-20210825171816855"></p>
</li>
</ul>
<h3 id="Hadoop-组成"><a href="#Hadoop-组成" class="headerlink" title="Hadoop 组成"></a>Hadoop 组成</h3><p><img src="/2021/08/25/hadoop/image-20210825173206311.png" alt="image-20210825173206311"></p>
<ul>
<li>Hadoop 1.x 时 代 ，Hadoop 中的 MapReduce 同时处理业务逻辑运算和资源的调度，耦合性较大。</li>
<li>Hadoop 2.x 时代，增加了 Yarn。Yarn 只负责资源的调度，MapReduce 只负责运算。</li>
<li>Hadoop 3.x 时代，在组成上没有变化。</li>
</ul>
<h4 id="HDFS-架构概述"><a href="#HDFS-架构概述" class="headerlink" title="HDFS 架构概述"></a>HDFS 架构概述</h4><ul>
<li>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。包含三个模块：<ul>
<li>NameNode：简称 nn，存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的 DataNode 等。</li>
<li>DataNode：简称 dn，在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>Secondary NameNode：简称 2nn，每隔一段时间对 NameNode 元数据备份。</li>
</ul>
</li>
</ul>
<h4 id="YARN-架构概述"><a href="#YARN-架构概述" class="headerlink" title="YARN 架构概述"></a>YARN 架构概述</h4><ul>
<li><p>Yet Another Resource Negotiator，简称 YARN ，另一种资源协调者，是 Hadoop 的资源管理器。有两大组件：</p>
<p><img src="/2021/08/25/hadoop/image-20210826101511233.png" alt="image-20210826101511233"></p>
<ul>
<li>ResourceManager：简称 RM，整个集群资源（内存、CPU 等）的管理者。</li>
<li>NodeManager：简称 NM，单个节点服务器资源的管理者。每个 NodeManager 上可以有多个 Container。<ul>
<li>Container：容器，相当于一台独立的服务器，里面封装了任务运行所需要的资源，如内存、CPU、磁盘、网络等。</li>
<li>ApplicationMaster：简称 AM，单个任务运行的管理者。</li>
</ul>
</li>
</ul>
</li>
<li><p>客户端 client 可以有多个。</p>
</li>
<li><p>集群上可以运行多个 ApplicationMaster。</p>
</li>
</ul>
<h4 id="MapReduce-架构概述"><a href="#MapReduce-架构概述" class="headerlink" title="MapReduce 架构概述"></a>MapReduce 架构概述</h4><ul>
<li><p>MapReduce 将计算过程分为两个阶段：Map 和 Reduce。</p>
<p><img src="/2021/08/25/hadoop/image-20210825232032562.png" alt="image-20210825232032562"></p>
<ul>
<li>Map 阶段并行处理输入数据。</li>
<li>Reduce 阶段对 Map 结果进行汇总。</li>
</ul>
</li>
</ul>
<h4 id="HDFS-、YARN-、MapReduce-三者关系"><a href="#HDFS-、YARN-、MapReduce-三者关系" class="headerlink" title="HDFS 、YARN 、MapReduce 三者关系"></a>HDFS 、YARN 、MapReduce 三者关系</h4><p><img src="/2021/08/25/hadoop/image-20210825232856313.png" alt="image-20210825232856313"></p>
<h3 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h3><p><img src="/2021/08/25/hadoop/image-20210825233533121.png" alt="image-20210825233533121"></p>
<ul>
<li>Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive 与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如：MySQL，Oracle 等）中的数据导进到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。</li>
<li>Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据。</li>
<li>Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统。</li>
<li>Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数据进行计算。</li>
<li>Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</li>
<li>Oozie：Oozie 是一个管理 Hadoop 作业（job）的工作流程调度管理系统。</li>
<li>Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</li>
<li>Hive：Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</li>
<li>ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</li>
</ul>
<h3 id="推荐系统框架图"><a href="#推荐系统框架图" class="headerlink" title="推荐系统框架图"></a>推荐系统框架图</h3><p><img src="/2021/08/25/hadoop/image-20210826110750495.png" alt="image-20210826110750495"></p>
<h2 id="Hadoop-运行环境搭建"><a href="#Hadoop-运行环境搭建" class="headerlink" title="Hadoop 运行环境搭建"></a>Hadoop 运行环境搭建</h2><h3 id="模板虚拟机环境准备"><a href="#模板虚拟机环境准备" class="headerlink" title="模板虚拟机环境准备"></a>模板虚拟机环境准备</h3><ul>
<li><p>安装模板虚拟机，IP 地址 192.168.10.100、主机名称 hadoop100、内存 2 G、硬盘 50 G。</p>
<ul>
<li>主机名称不要起 hadoop，hadoop000 等特殊名称。</li>
</ul>
</li>
<li><p>开启虚拟机，切换到 root 用户操作下面得命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 ~]$ su root</span><br><span class="line">密码：</span><br></pre></td></tr></table></figure>
</li>
<li><p>确保虚拟机可以正常上网：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># ping www.baidu.com</span></span><br><span class="line">PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=128 time=41.0 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=128 time=40.9 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=128 time=41.3 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=128 time=42.5 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3007ms</span><br><span class="line">rtt min/avg/max/mdev = 40.987/41.495/42.582/0.674 ms</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 epel-release：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># yum install -y epel-release</span></span><br><span class="line">已加载插件：fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.njupt.edu.cn</span><br><span class="line"> * extras: mirrors.njupt.edu.cn</span><br><span class="line"> * updates: mirrors.njupt.edu.cn</span><br><span class="line">base                                                                                                                                                                                        | 3.6 kB  00:00:00     </span><br><span class="line">extras                                                                                                                                                                                      | 2.9 kB  00:00:00     </span><br><span class="line">updates                                                                                                                                                                                     | 2.9 kB  00:00:00     </span><br><span class="line">正在解决依赖关系</span><br><span class="line">--&gt; 正在检查事务</span><br><span class="line">---&gt; 软件包 epel-release.noarch.0.7-11 将被 安装</span><br><span class="line">--&gt; 解决依赖关系完成</span><br><span class="line"></span><br><span class="line">依赖关系解决</span><br><span class="line"></span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line"> Package                                                 架构                                              版本                                            源                                                 大小</span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line">正在安装:</span><br><span class="line"> epel-release                                            noarch                                            7-11                                            extras                                             15 k</span><br><span class="line"></span><br><span class="line">事务概要</span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line">安装  1 软件包</span><br><span class="line"></span><br><span class="line">总下载量：15 k</span><br><span class="line">安装大小：24 k</span><br><span class="line">Downloading packages:</span><br><span class="line">警告：/var/cache/yum/x86_64/7/extras/packages/epel-release-7-11.noarch.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY</span><br><span class="line">epel-release-7-11.noarch.rpm 的公钥尚未安装</span><br><span class="line">epel-release-7-11.noarch.rpm                                                                                                                                                                |  15 kB  00:00:00     </span><br><span class="line">从 file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 检索密钥</span><br><span class="line">导入 GPG key 0xF4A80EB5:</span><br><span class="line"> 用户ID     : <span class="string">&quot;CentOS-7 Key (CentOS 7 Official Signing Key) &lt;security@centos.org&gt;&quot;</span></span><br><span class="line"> 指纹       : 6341 ab27 53d7 8a78 a7c2 7bb1 24c6 a8a7 f4a8 0eb5</span><br><span class="line"> 软件包     : centos-release-7-8.2003.0.el7.centos.x86_64 (@anaconda)</span><br><span class="line"> 来自       : /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction <span class="built_in">test</span></span><br><span class="line">Transaction <span class="built_in">test</span> succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  正在安装    : epel-release-7-11.noarch                                                                                                                                                                       1/1 </span><br><span class="line">  验证中      : epel-release-7-11.noarch                                                                                                                                                                       1/1 </span><br><span class="line"></span><br><span class="line">已安装:</span><br><span class="line">  epel-release.noarch 0:7-11                                                                                                                                                                                       </span><br><span class="line"></span><br><span class="line">完毕！</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的。</p>
</li>
<li><p>如果 Linux 安装的是最小系统版，还需要安装如下工具，如果安装的是 Linux 桌面标准版，不需要执行如下操作（本机安装的是桌面版）：</p>
<ul>
<li><p>net-tool：工具包集合，包含 ifconfig 等命令。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># yum install -y net-tools</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>vim：编辑器。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># yum install -y vim</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>关闭防火墙，关闭防火墙开机自启：</p>
<ul>
<li><p>查看防火墙状态：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># firewall-cmd --state</span></span><br><span class="line">running</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭防火墙：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># systemctl stop firewalld.service</span></span><br><span class="line">[root@hadoop100 xisun]<span class="comment"># firewall-cmd --state</span></span><br><span class="line">not running</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭防火墙开机自启：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># systemctl disable firewalld.service </span></span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br></pre></td></tr></table></figure>
</li>
<li><p>在企业开发时，通常单个服务器的防火墙是关闭的，公司整体对外访问时会设置非常安全的防火墙。</p>
</li>
</ul>
</li>
<li><p>创建新用户，并修改新用户的密码（可省略）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># useradd xisun</span></span><br><span class="line">[root@hadoop100 xisun]<span class="comment"># passwd xisun</span></span><br></pre></td></tr></table></figure>

<ul>
<li>生产环境下，应避免使用 root 用户直接操作。</li>
</ul>
</li>
<li><p>配置刚创建的新用户具有 root 权限，方便后期加 sudo 执行 root 权限的命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># vim /etc/sudoers</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改 <code>/etc/sudoers</code> 文件，在 %wheel 这行下面添加一行，将新用户 xisun 设置为免密使用 root 权限，如下所示：</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">## Allow root to run any commands anywhere </span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">## Allows members of the &#x27;sys&#x27; group to run networking, software, </span><br><span class="line">## service management apps and more.</span><br><span class="line"># %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS</span><br><span class="line"></span><br><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">%wheel  ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">xisun   ALL=(ALL)     NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<ul>
<li>xisun 这一行不要直接放到 root 行下面，因为所有用户都属于 wheel 组，如果放在 root 行下面，则是先配置了 xisun 用户在使用 sudo 命令时具有免输入密码功能，但是程序执行到 %wheel 行时，该功能又会被覆盖回需要密码。所以 xisun 这一行要放到 %wheel 这行下面。</li>
</ul>
</li>
</ul>
</li>
<li><p>从 root 用户退回到 xisun 用户：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 xisun]<span class="comment"># exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在 <code>/opt</code> 目录下创建文件夹：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 ~]$ <span class="built_in">cd</span> /opt/</span><br><span class="line">[xisun@hadoop100 opt]$ sudo mkdir module</span><br><span class="line">[xisun@hadoop100 opt]$ sudo mkdir software</span><br><span class="line">[xisun@hadoop100 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:08 module</span><br><span class="line">drwxr-xr-x. 2 root root 6 10月 31 2018 rh</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:09 software</span><br><span class="line">[xisun@hadoop100 opt]$ sudo rm -r rh</span><br><span class="line">[xisun@hadoop100 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:08 module</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:09 software</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>/opt</code> 目录下，需要使用 sudo 命令才能创建和删除文件夹：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 opt]$ mkdir <span class="built_in">test</span></span><br><span class="line">mkdir: 无法创建目录<span class="string">&quot;test&quot;</span>: 权限不够</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>修改创建的文件夹所属主和所属组为 xisun 用户：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:08 module</span><br><span class="line">drwxr-xr-x. 2 root root 6 8月  30 22:09 software</span><br><span class="line">[xisun@hadoop100 opt]$ sudo chown xisun:xisun module/</span><br><span class="line">[xisun@hadoop100 opt]$ sudo chown xisun:xisun software/</span><br><span class="line">[xisun@hadoop100 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  30 22:08 module</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  30 22:09 software</span><br></pre></td></tr></table></figure>
</li>
<li><p>卸载虚拟机自带的 JDK，以 root 用户执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 opt]$ su root</span><br><span class="line">密码：</span><br><span class="line">[root@hadoop100 opt]<span class="comment"># rpm -qa | grep -i java</span></span><br><span class="line">javapackages-tools-3.4.1-11.el7.noarch</span><br><span class="line">tzdata-java-2019c-1.el7.noarch</span><br><span class="line">java-1.8.0-openjdk-headless-1.8.0.242.b08-1.el7.x86_64</span><br><span class="line">java-1.8.0-openjdk-1.8.0.242.b08-1.el7.x86_64</span><br><span class="line">java-1.7.0-openjdk-headless-1.7.0.251-2.6.21.1.el7.x86_64</span><br><span class="line">python-javapackages-3.4.1-11.el7.noarch</span><br><span class="line">java-1.7.0-openjdk-1.7.0.251-2.6.21.1.el7.x86_64</span><br><span class="line">[root@hadoop100 opt]<span class="comment"># rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span></span><br><span class="line">[root@hadoop100 opt]<span class="comment"># rpm -qa | grep -i java</span></span><br></pre></td></tr></table></figure>

<ul>
<li>如果你的虚拟机是最小化安装不需要执行这一步。</li>
<li><code>rpm -qa</code>：查询所安装的所有 rpm 软件包。</li>
<li><code>grep -i</code>：忽略大小写。</li>
<li><code>xargs -n1</code>：表示每次只传递一个参数。</li>
<li><code>rpm -e –nodeps</code>：强制卸载软件。</li>
</ul>
</li>
<li><p>重启虚拟机：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 opt]<span class="comment"># reboot</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h3><ul>
<li><p>利用模板机 hadoop100，克隆三台虚拟机：hadoop102，hadoop103，hadoop104。</p>
<ul>
<li>注意：克隆时，要先关闭 hadoop100。</li>
</ul>
</li>
<li><p>修改克隆机的 IP 地址和主机名，以 hadoop102 为例，进行说明：</p>
<ul>
<li><p>开启 hadoop102，以 root 账户登录。</p>
</li>
<li><p>修改 IP 地址：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># vim /etc/sysconfig/network-scripts/ifcfg-ens33</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改 ifcfg-ens33 文件中的 IPADDR：</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">TYPE=&quot;Ethernet&quot;</span><br><span class="line">PROXY_METHOD=&quot;none&quot;</span><br><span class="line">BROWSER_ONLY=&quot;no&quot;</span><br><span class="line">BOOTPROTO=&quot;static&quot;</span><br><span class="line">DEFROUTE=&quot;yes&quot;</span><br><span class="line">IPV4_FAILURE_FATAL=&quot;no&quot;</span><br><span class="line">IPV6INIT=&quot;yes&quot;</span><br><span class="line">IPV6_AUTOCONF=&quot;yes&quot;</span><br><span class="line">IPV6_DEFROUTE=&quot;yes&quot;</span><br><span class="line">IPV6_FAILURE_FATAL=&quot;no&quot;</span><br><span class="line">IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;</span><br><span class="line">NAME=&quot;ens33&quot;</span><br><span class="line">UUID=&quot;eb503f88-96af-455d-b8f9-dbda02ca79d4&quot;</span><br><span class="line">DEVICE=&quot;ens33&quot;</span><br><span class="line">ONBOOT=&quot;yes&quot;</span><br><span class="line"></span><br><span class="line">IPADDR=192.168.10.102		# 修改IP地址为192.168.10.102</span><br><span class="line">GATEWAY=192.168.10.2</span><br><span class="line">DNS1=192.168.10.2</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>修改主机名：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># vim /etc/hostname</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># reboot</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>验证 IP 地址和主机名，以及网络是否正常：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># ifconfig</span></span><br><span class="line">ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.10.102  netmask 255.255.255.0  broadcast 192.168.10.255</span><br><span class="line">        inet6 fe80::ac1e:7fe1:a566:2670  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 00:0c:29:c5:1d:96  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1025  bytes 878131 (857.5 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 442  bytes 35254 (34.4 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 48  bytes 4080 (3.9 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 48  bytes 4080 (3.9 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.122.1  netmask 255.255.255.0  broadcast 192.168.122.255</span><br><span class="line">        ether 52:54:00:97:ed:a7  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]<span class="comment"># hostname</span></span><br><span class="line">hadoop102</span><br><span class="line">[root@hadoop102 ~]<span class="comment"># ping www.baidu.com</span></span><br><span class="line">PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=128 time=42.9 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=128 time=42.6 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=128 time=42.7 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=128 time=42.8 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=5 ttl=128 time=42.8 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0% packet loss, time 4012ms</span><br><span class="line">rtt min/avg/max/mdev = 42.689/42.814/42.930/0.276 ms</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照相同的步骤，修改 hadoop103 的 IP 地址为 192.168.10.103，主机名为 hadoop103，hadoop104 的 IP 地址为 192.168.10.104，主机名为 hadoop104，并验证。</p>
</li>
</ul>
</li>
</ul>
<h3 id="安装-JDK"><a href="#安装-JDK" class="headerlink" title="安装 JDK"></a>安装 JDK</h3><ul>
<li><p>下面步骤以 hadoop102 为例，进行说明。</p>
</li>
<li><p>安装 JDK 前，一定确保提前删除了虚拟机自带的 JDK，此步骤在前面已执行。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ rpm -qa | grep -i java</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop100 ~]$ rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ java -version</span><br><span class="line">bash: java: 未找到命令...</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 OpenJDK 8。</p>
</li>
</ul>
<ul>
<li><p>下载地址：<a target="_blank" rel="noopener" href="https://openjdk.java.net/%EF%BC%8Chttps://openjdk.java.net/install/index.html">https://openjdk.java.net/，https://openjdk.java.net/install/index.html</a></p>
<p><img src="/2021/08/25/hadoop/image-20210831115613196.png" alt="image-20210831115613196"></p>
</li>
<li><p>使用 root 权限，以命令行安装：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ sudo yum install -y java-1.8.0-openjdk-devel</span><br><span class="line">已加载插件：fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.cqu.edu.cn</span><br><span class="line"> * epel: mirror.sjtu.edu.cn</span><br><span class="line"> * extras: mirrors.cn99.com</span><br><span class="line"> * updates: mirrors.cn99.com</span><br><span class="line">正在解决依赖关系</span><br><span class="line">--&gt; 正在检查事务</span><br><span class="line">---&gt; 软件包 java-1.8.0-openjdk-devel.x86_64.1.1.8.0.302.b08-0.el7_9 将被 安装</span><br><span class="line">--&gt; 正在处理依赖关系 java-1.8.0-openjdk(x86-64) = 1:1.8.0.302.b08-0.el7_9，它被软件包 1:java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64 需要</span><br><span class="line">--&gt; 正在处理依赖关系 libjvm.so()(64bit)，它被软件包 1:java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64 需要</span><br><span class="line">--&gt; 正在处理依赖关系 libjava.so()(64bit)，它被软件包 1:java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64 需要</span><br><span class="line">--&gt; 正在检查事务</span><br><span class="line">---&gt; 软件包 java-1.8.0-openjdk.x86_64.1.1.8.0.302.b08-0.el7_9 将被 安装</span><br><span class="line">---&gt; 软件包 java-1.8.0-openjdk-headless.x86_64.1.1.8.0.302.b08-0.el7_9 将被 安装</span><br><span class="line">--&gt; 正在处理依赖关系 tzdata-java &gt;= 2021a，它被软件包 1:java-1.8.0-openjdk-headless-1.8.0.302.b08-0.el7_9.x86_64 需要</span><br><span class="line">--&gt; 正在处理依赖关系 jpackage-utils，它被软件包 1:java-1.8.0-openjdk-headless-1.8.0.302.b08-0.el7_9.x86_64 需要</span><br><span class="line">--&gt; 正在检查事务</span><br><span class="line">---&gt; 软件包 javapackages-tools.noarch.0.3.4.1-11.el7 将被 安装</span><br><span class="line">--&gt; 正在处理依赖关系 python-javapackages = 3.4.1-11.el7，它被软件包 javapackages-tools-3.4.1-11.el7.noarch 需要</span><br><span class="line">---&gt; 软件包 tzdata-java.noarch.0.2021a-1.el7 将被 安装</span><br><span class="line">--&gt; 正在检查事务</span><br><span class="line">---&gt; 软件包 python-javapackages.noarch.0.3.4.1-11.el7 将被 安装</span><br><span class="line">--&gt; 解决依赖关系完成</span><br><span class="line"></span><br><span class="line">依赖关系解决</span><br><span class="line"></span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line"> Package                                                       架构                                     版本                                                       源                                         大小</span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line">正在安装:</span><br><span class="line"> java-1.8.0-openjdk-devel                                      x86_64                                   1:1.8.0.302.b08-0.el7_9                                    updates                                   9.8 M</span><br><span class="line">为依赖而安装:</span><br><span class="line"> java-1.8.0-openjdk                                            x86_64                                   1:1.8.0.302.b08-0.el7_9                                    updates                                   311 k</span><br><span class="line"> java-1.8.0-openjdk-headless                                   x86_64                                   1:1.8.0.302.b08-0.el7_9                                    updates                                    33 M</span><br><span class="line"> javapackages-tools                                            noarch                                   3.4.1-11.el7                                               base                                       73 k</span><br><span class="line"> python-javapackages                                           noarch                                   3.4.1-11.el7                                               base                                       31 k</span><br><span class="line"> tzdata-java                                                   noarch                                   2021a-1.el7                                                updates                                   191 k</span><br><span class="line"></span><br><span class="line">事务概要</span><br><span class="line">===================================================================================================================================================================================================================</span><br><span class="line">安装  1 软件包 (+5 依赖软件包)</span><br><span class="line"></span><br><span class="line">总下载量：43 M</span><br><span class="line">安装大小：152 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/6): python-javapackages-3.4.1-11.el7.noarch.rpm                                                                                                                                          |  31 kB  00:00:00     </span><br><span class="line">(2/6): java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64.rpm                                                                                                                                  | 311 kB  00:00:00     </span><br><span class="line">(3/6): javapackages-tools-3.4.1-11.el7.noarch.rpm                                                                                                                                           |  73 kB  00:00:00     </span><br><span class="line">(4/6): tzdata-java-2021a-1.el7.noarch.rpm                                                                                                                                                   | 191 kB  00:00:01     </span><br><span class="line">(5/6): java-1.8.0-openjdk-headless-1.8.0.302.b08-0.el7_9.x86_64.rpm                                                                                                                         |  33 MB  00:00:07     </span><br><span class="line">(6/6): java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64.rpm                                                                                                                            | 9.8 MB  00:00:13     </span><br><span class="line">-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">总计                                                                                                                                                                               3.1 MB/s |  43 MB  00:00:13     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction <span class="built_in">test</span></span><br><span class="line">Transaction <span class="built_in">test</span> succeeded</span><br><span class="line">Running transaction</span><br><span class="line">警告：RPM 数据库已被非 yum 程序修改。</span><br><span class="line">** 发现 9 个已存在的 RPM 数据库问题， <span class="string">&#x27;yum check&#x27;</span> 输出如下：</span><br><span class="line">icedtea-web-1.7.1-2.el7_6.x86_64 有缺少的需求 java-1.8.0-openjdk</span><br><span class="line">icedtea-web-1.7.1-2.el7_6.x86_64 有缺少的需求 jpackage-utils</span><br><span class="line">icedtea-web-1.7.1-2.el7_6.x86_64 有缺少的需求 jpackage-utils</span><br><span class="line">jline-1.0-8.el7.noarch 有缺少的需求 java &gt;= (<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1.5&#x27;</span>, None)</span><br><span class="line">jline-1.0-8.el7.noarch 有缺少的需求 jpackage-utils</span><br><span class="line">rhino-1.7R5-1.el7.noarch 有缺少的需求 jpackage-utils</span><br><span class="line">rhino-1.7R5-1.el7.noarch 有缺少的需求 jpackage-utils</span><br><span class="line">tagsoup-1.2.1-8.el7.noarch 有缺少的需求 jpackage-utils</span><br><span class="line">tagsoup-1.2.1-8.el7.noarch 有缺少的需求 jpackage-utils &gt;= (<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1.6&#x27;</span>, None)</span><br><span class="line">  正在安装    : tzdata-java-2021a-1.el7.noarch                                                                                                                                                                 1/6 </span><br><span class="line">  正在安装    : python-javapackages-3.4.1-11.el7.noarch                                                                                                                                                        2/6 </span><br><span class="line">  正在安装    : javapackages-tools-3.4.1-11.el7.noarch                                                                                                                                                         3/6 </span><br><span class="line">  正在安装    : 1:java-1.8.0-openjdk-headless-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                     4/6 </span><br><span class="line">  正在安装    : 1:java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                              5/6 </span><br><span class="line">  正在安装    : 1:java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                        6/6 </span><br><span class="line">  验证中      : 1:java-1.8.0-openjdk-headless-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                     1/6 </span><br><span class="line">  验证中      : python-javapackages-3.4.1-11.el7.noarch                                                                                                                                                        2/6 </span><br><span class="line">  验证中      : tzdata-java-2021a-1.el7.noarch                                                                                                                                                                 3/6 </span><br><span class="line">  验证中      : 1:java-1.8.0-openjdk-devel-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                        4/6 </span><br><span class="line">  验证中      : 1:java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64                                                                                                                                              5/6 </span><br><span class="line">  验证中      : javapackages-tools-3.4.1-11.el7.noarch                                                                                                                                                         6/6 </span><br><span class="line"></span><br><span class="line">已安装:</span><br><span class="line">  java-1.8.0-openjdk-devel.x86_64 1:1.8.0.302.b08-0.el7_9                                                                                                                                                          </span><br><span class="line"></span><br><span class="line">作为依赖被安装:</span><br><span class="line">  java-1.8.0-openjdk.x86_64 1:1.8.0.302.b08-0.el7_9     java-1.8.0-openjdk-headless.x86_64 1:1.8.0.302.b08-0.el7_9     javapackages-tools.noarch 0:3.4.1-11.el7     python-javapackages.noarch 0:3.4.1-11.el7    </span><br><span class="line">  tzdata-java.noarch 0:2021a-1.el7                     </span><br><span class="line"></span><br><span class="line">完毕！</span><br></pre></td></tr></table></figure>

<blockquote>
<p>公司生产环境使用的是 OpenJDK 8，此处保持一致。</p>
</blockquote>
</li>
<li><p>验证 JDK 是否安装成功：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ java -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_302&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_302-b08)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode)</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 JDK 环境变量：</p>
<ul>
<li><p>查看 jre/bin 路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ dirname $(readlink $(readlink $(<span class="built_in">which</span> java)))</span><br><span class="line">/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64/jre/bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>新建 <code>/etc/profile.d/my_env.sh</code> 文件，添加 Java 环境变量：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># JAVA_HOME</span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<ul>
<li><p>正常情况下，会将 Java 环境变量添加在 <code>/etc/profile</code> 文件的最后，但该文件有如下设置，因此，可以在 <code>/etc/profile.d</code> 路径下自定义一个以 sh 结尾的文件，能达到同样的效果：</p>
<p><img src="/2021/08/25/hadoop/image-20210831143510629.png" alt="image-20210831143510629"></p>
</li>
</ul>
</li>
<li><p>source 一下 <code>/etc/profile</code> 文件，让新的环境变量 PATH 生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 etc]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看配置是否生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 etc]$ <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h3 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a>安装 Hadoop</h3><ul>
<li><p>下面步骤以 hadoop102 为例，进行说明。</p>
</li>
<li><p>下载地址：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/releases.html">https://hadoop.apache.org/releases.html</a></p>
<p><img src="/2021/08/25/hadoop/image-20210831114058447.png" alt="image-20210831114058447"></p>
<p><img src="/2021/08/25/hadoop/image-20210831144645384.png" alt="image-20210831144645384"></p>
<blockquote>
<p>公司生产环境使用的是 hadoop-3.2.1，此处保持一致。</p>
</blockquote>
</li>
<li><p>在 <code>opt/software</code> 路径下，使用 wget 命令下载安装包：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 software]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/software</span><br><span class="line">[xisun@hadoop102 software]$ wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz</span><br><span class="line">--2021-08-31 11:44:19--  https://archive.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz</span><br><span class="line">正在解析主机 archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2</span><br><span class="line">正在连接 archive.apache.org (archive.apache.org)|138.201.131.134|:443... 已连接。</span><br><span class="line">已发出 HTTP 请求，正在等待回应... 200 OK</span><br><span class="line">长度：359196911 (343M) [application/x-gzip]</span><br><span class="line">正在保存至: “hadoop-3.2.1.tar.gz”</span><br><span class="line"></span><br><span class="line">100%[=========================================================================================================================================================================&gt;] 359,196,911 57.8KB/s 用时 57m 32s</span><br><span class="line"></span><br><span class="line">2021-08-31 12:41:54 (102 KB/s) - 已保存 “hadoop-3.2.1.tar.gz” [359196911/359196911])</span><br><span class="line">[xisun@hadoop102 software]$ ll</span><br><span class="line">总用量 350780</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 359196911 7月   3 2020 hadoop-3.2.1.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>解压安装包到 <code>/opt/module</code> 路径下面：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 software]$ tar -zxvf hadoop-3.2.1.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 software]$ ll ../module/</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 9 xisun xisun 149 9月  11 2019 hadoop-3.2.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>将 Hadoop 添加到环境变量：</p>
<ul>
<li><p>获取 Hadoop 安装路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改 <code>etc/profile.d/my_env.sh</code> 文件，添加 Hadoop 环境变量：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.2.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>
</li>
<li><p>source 一下 <code>/etc/profile</code> 文件，让新的环境变量 PATH 生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看配置是否生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ <span class="built_in">echo</span> <span class="variable">$HADOOP_HOME</span></span><br><span class="line">/opt/module/hadoop-3.2.1</span><br><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ hadoop version</span><br><span class="line">Hadoop 3.2.1</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842</span><br><span class="line">Compiled by rohithsharmaks on 2019-09-10T15:56Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 776eaf9eee9c0ffc370bcbc1888737</span><br><span class="line">This <span class="built_in">command</span> was run using /opt/module/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h3 id="Hadoop-目录结构"><a href="#Hadoop-目录结构" class="headerlink" title="Hadoop 目录结构"></a>Hadoop 目录结构</h3><ul>
<li><p>查看 Hadoop 的目录结构：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1</span><br><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ ll</span><br><span class="line">总用量 180</span><br><span class="line">drwxr-xr-x. 2 xisun xisun    203 9月  11 2019 bin</span><br><span class="line">drwxr-xr-x. 3 xisun xisun     20 9月  10 2019 etc</span><br><span class="line">drwxr-xr-x. 2 xisun xisun    106 9月  11 2019 include</span><br><span class="line">drwxr-xr-x. 3 xisun xisun     20 9月  11 2019 lib</span><br><span class="line">drwxr-xr-x. 4 xisun xisun    288 9月  11 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 150569 9月  10 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  22125 9月  10 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1361 9月  10 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 xisun xisun   4096 9月  10 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 xisun xisun     31 9月  11 2019 share</span><br></pre></td></tr></table></figure>
</li>
<li><p>重要目录</p>
<ul>
<li><p>bin 目录：存放对 Hadoop 相关服务（hdfs，yarn，mapred）进行操作的脚本。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ ls bin/</span><br><span class="line">container-executor  hadoop  hadoop.cmd  hdfs  hdfs.cmd  mapred  mapred.cmd  oom-listener  test-container-executor  yarn  yarn.cmd</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210831153016702.png" alt="image-20210831153016702"></p>
</li>
<li><p>etc 目录：Hadoop 的配置文件目录，存放 Hadoop 的配置文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ ls etc/</span><br><span class="line">hadoop</span><br><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ ls etc/hadoop/</span><br><span class="line">capacity-scheduler.xml  hadoop-env.sh                     httpfs-env.sh            kms-env.sh            mapred-env.sh               ssl-server.xml.example         yarnservice-log4j.properties</span><br><span class="line">configuration.xsl       hadoop-metrics2.properties        httpfs-log4j.properties  kms-log4j.properties  mapred-queues.xml.template  user_ec_policies.xml.template  yarn-site.xml</span><br><span class="line">container-executor.cfg  hadoop-policy.xml                 httpfs-signature.secret  kms-site.xml          mapred-site.xml             workers</span><br><span class="line">core-site.xml           hadoop-user-functions.sh.example  httpfs-site.xml          log4j.properties      shellprofile.d              yarn-env.cmd</span><br><span class="line">hadoop-env.cmd          hdfs-site.xml                     kms-acls.xml             mapred-env.cmd        ssl-client.xml.example      yarn-env.sh</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210831153058005.png" alt="image-20210831153058005"></p>
</li>
<li><p>lib 目录：存放 Hadoop 的本地库（对数据进行压缩解压缩功能）。</p>
</li>
<li><p>sbin 目录：存放启动或停止 Hadoop 相关服务的脚本。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ ls sbin/</span><br><span class="line">distribute-exclude.sh  hadoop-daemons.sh  mr-jobhistory-daemon.sh  start-all.sh       start-dfs.sh         start-yarn.sh  stop-balancer.sh  stop-secure-dns.sh  workers.sh</span><br><span class="line">FederationStateStore   httpfs.sh          refresh-namenodes.sh     start-balancer.sh  start-secure-dns.sh  stop-all.cmd   stop-dfs.cmd      stop-yarn.cmd       yarn-daemon.sh</span><br><span class="line">hadoop-daemon.sh       kms.sh             start-all.cmd            start-dfs.cmd      start-yarn.cmd       stop-all.sh    stop-dfs.sh       stop-yarn.sh        yarn-daemons.sh</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210831153154765.png" alt="image-20210831153154765"></p>
</li>
<li><p>share 目录：存放 Hadoop 的依赖 JAR 包、文档、和官方案例。</p>
</li>
</ul>
</li>
</ul>
<h2 id="Hadoop-运行模式"><a href="#Hadoop-运行模式" class="headerlink" title="Hadoop 运行模式"></a>Hadoop 运行模式</h2><ul>
<li><p>Hadoop 官方网站：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
</li>
<li><p>Hadoop 运行模式包括：本地模式、伪分布式模式以及完全分布式模式。</p>
<p><img src="/2021/08/25/hadoop/image-20210831154042555.png" alt="image-20210831154042555"></p>
<ul>
<li>本地模式：单机运行，只是用来演示一下官方案例。<ul>
<li>数据存储在 Linux 本地，偶尔测试时使用。</li>
</ul>
</li>
<li>伪分布式模式：也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模拟一个分布式的环境。<ul>
<li>数据存储在 HDFS 上，个别缺钱的公司用来测试，生产环境一般不用。</li>
</ul>
</li>
<li>完全分布式模式：多台服务器组成分布式环境。<ul>
<li>数据存储在 HDFS 上，企业生产环境大量使用。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h3><ul>
<li><p>以官方 WordCount 进行说明。</p>
</li>
<li><p>第一步：在 hadoop-3.2.1 文件下面创建一个 wcinput 文件夹。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ mkdir wcinput</span><br></pre></td></tr></table></figure>
</li>
<li><p>第二步：在 wcinput 文件下创建一个 word.txt 文件，并输入一些单词做测试。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 wcinput]$ vim word.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xisun</span><br><span class="line">xisun</span><br></pre></td></tr></table></figure>
</li>
<li><p>第三步：回到 Hadoop 目录 <code>/opt/module/hadoop-3.2.1</code>。</p>
</li>
<li><p>第四步：执行 wordcount 程序，统计 word.txt 文件中各单词的个数。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount wcinput/ ./wcoutput</span><br></pre></td></tr></table></figure>

<blockquote>
<p>本地模式下，输入路径 <code>/wcinput</code> 和输出路径 <code>./wcoutput</code> 都是本地路径。</p>
<p>注意：结果输出路径 wcoutput 不能已经存在，否则程序会报错 <code>org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/opt/module/hadoop-3.2.1/wcoutput already exists</code>。</p>
</blockquote>
</li>
<li><p>第五步：查看结果。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop-3.2.1]$ <span class="built_in">cd</span> wcoutput/</span><br><span class="line">[xisun@hadoop102 wcoutput]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 xisun xisun 36 8月  31 16:04 part-r-00000</span><br><span class="line">-rw-r--r--. 1 xisun xisun  0 8月  31 16:04 _SUCCESS</span><br><span class="line">[xisun@hadoop102 wcoutput]$ cat part-r-00000 </span><br><span class="line">hadoop	2</span><br><span class="line">mapreduce	1</span><br><span class="line">xisun	2</span><br><span class="line">yarn	1</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="完全分布式模式"><a href="#完全分布式模式" class="headerlink" title="完全分布式模式"></a>完全分布式模式</h3><h4 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h4><ul>
<li><p>虚拟机 hadoop102 已准备好，参考前面章节。</p>
</li>
<li><p>在 hadoop103 和 hadoop104 安装 OpenJDK：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ sudo yum install -y java-1.8.0-openjdk-devel</span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop102，hadoop103 和 hadoop104 三台虚拟机，安装的 JDK 环境和 Hadoop 版本相同，因此，环境变量配置也相同。对于这种情况，不需要在每台虚拟机上再配置环境变量，可以使用 scp 或 rsync 命令等，直接拷贝模板虚拟机 hadoop102 上的配置文件到 hadoop103 和 hadoop104 上。在后面章节，也可以使用集群分发脚本 xsync 拷贝。</p>
<ul>
<li><p>如果使用 scp 命令，拷贝 hadoop102 上环境变量配置的 <code>etc/profile.d/my_env.sh</code> 文件到 hadoop103 和 hadoop104 的 <code>etc/profile.d</code> 路径下，方式如下。</p>
<ul>
<li><p>方式一，在 hadoop102 上使用 scp 命令，拷贝本地文件到 hadoop103 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 profile.d]$ sudo scp /etc/profile.d/my_env.sh root@hadoop103:/etc/profile.d/</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop103 (192.168.10.103)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop103,192.168.10.103<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">root@hadoop103&#x27;</span>s password: </span><br><span class="line">my_env.sh      </span><br></pre></td></tr></table></figure>
</li>
<li><p>方式二，在 hadoop104 上使用 scp 命令，拷贝 hadoop102 上的文件到本地：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 profile.d]$ sudo scp root@hadoop102:/etc/profile.d/my_env.sh /etc/profile.d/</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop102 (192.168.10.102)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop102,192.168.10.102<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">root@hadoop102&#x27;</span>s password: </span><br><span class="line">my_env.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>方式三，在 hadoop103 上使用 scp 命令，拷贝 hadoop102 上的文件到 hadoop104 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 profile.d]$ sudo scp root@hadoop102:/etc/profile.d/my_env.sh root@hadoop104:/etc/profile.d/</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>如果使用集群分发脚本 xsync 拷贝，需要注意，my_env.sh 文件是 root 权限的，需要给脚本添加 sudo 命令，同时，xsync 脚本需要补全路径，否则 sudo 识别不出来：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ sudo /home/xisun/bin/xsync /etc/profile.d/my_env.sh </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">root@hadoop102<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">root@hadoop102&#x27;</span>s password: </span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 48 bytes  received 12 bytes  24.00 bytes/sec</span><br><span class="line">total size is 253  speedup is 4.22</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">root@hadoop103<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">root@hadoop103&#x27;</span>s password: </span><br><span class="line">sending incremental file list</span><br><span class="line">my_env.sh</span><br><span class="line"></span><br><span class="line">sent 348 bytes  received 35 bytes  153.20 bytes/sec</span><br><span class="line">total size is 253  speedup is 0.66</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop104 (192.168.10.104)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop104,192.168.10.104<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">root@hadoop104&#x27;</span>s password: </span><br><span class="line">root@hadoop104<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">sending incremental file list</span></span><br><span class="line"><span class="string">my_env.sh</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sent 348 bytes  received 35 bytes  153.20 bytes/sec</span></span><br><span class="line"><span class="string">total size is 253  speedup is 0.66</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意，需要输入的是各主机 root 用户的密码。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>在 hadoop103 和 hadoop104 上 source 一下 <code>/etc/profile</code> 文件，让新的环境变量 PATH 生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ <span class="built_in">source</span> /etc/profile</span><br><span class="line">[xisun@hadoop103 ~]$ <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 ~]$ <span class="built_in">source</span> /etc/profile</span><br><span class="line">[xisun@hadoop104 ~]$ <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="编写集群分发脚本-xsync"><a href="#编写集群分发脚本-xsync" class="headerlink" title="编写集群分发脚本 xsync"></a>编写集群分发脚本 xsync</h4><h5 id="scp（secure-copy）安全拷贝"><a href="#scp（secure-copy）安全拷贝" class="headerlink" title="scp（secure copy）安全拷贝"></a>scp（secure copy）安全拷贝</h5><ul>
<li><p>scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）</p>
</li>
<li><p>基本语法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp    -r        <span class="variable">$pdir</span>/<span class="variable">$fname</span>         <span class="variable">$user</span>@<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   递归     要拷贝的文件路径/名称   	 目的地用户@主机:目的地路径/名称</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例：拷贝 hadoop102 上的 Hadoop 安装包到 hadoop103 和 hadoop104 上。</p>
<ul>
<li><p>前提：在 hadoop102、hadoop103、hadoop104 三台虚拟机上，都已经创建好 <code>/opt/module</code> 和 <code>/opt/software</code> 两个路径，并且已经把这两个路径的权限修改为 xisun:xisun。</p>
</li>
<li><p>方式一，在 hadoop102 上使用 scp 命令，拷贝本地文件到 hadoop103 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 opt]$ scp -r /opt/module/hadoop-3.2.1/ xisun@hadoop103:/opt/module/</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop103 (192.168.10.103)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop103,192.168.10.103<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">xisun@hadoop103&#x27;</span>s password:</span><br></pre></td></tr></table></figure>


</li>
</ul>
</li>
</ul>
<ul>
<li><p>方式二，在 hadoop104 上使用 scp 命令，拷贝 hadoop102 上的文件到本地：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 opt]$ scp -r xisun@hadoop102:/opt/module/hadoop-3.2.1/ /opt/module/</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop102 (192.168.10.102)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop104,192.168.10.102<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">xisun@hadoop102&#x27;</span>s password:</span><br></pre></td></tr></table></figure>
</li>
<li><p>方式三，在 hadoop103 上使用 scp 命令，拷贝 hadoop102 上的文件到 hadoop104 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 opt]$ scp -r xisun@hadoop102:/opt/module/hadoop-3.2.1/ xisun@hadoop104:/opt/module/</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a>rsync 远程同步工具</h5><ul>
<li><p>rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
</li>
<li><p>rsync 和 scp 的区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新。scp 是把所有文件都复制过去。</p>
</li>
<li><p>rsync 第一次使用，等同于 scp。</p>
</li>
<li><p>基本语法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync    -av       <span class="variable">$pdir</span>/<span class="variable">$fname</span>          <span class="variable">$user</span>@<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令    选项参数    要拷贝的文件路径/名称     目的地用户@主机:目的地路径/名称</span><br></pre></td></tr></table></figure>

<ul>
<li><p>参数说明：</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>实例：</p>
<ul>
<li><p>删除 hadoop103 和 hadoop104 上 <code>/opt/module/hadoop-3.2.1</code> 路径下的 wcinput 和 wcoutput 文件夹。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 hadoop-3.2.1]$ rm -r wcinput/ wcoutput/</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 hadoop-3.2.1]$ rm -r wcinput/ wcoutput/</span><br></pre></td></tr></table></figure>
</li>
<li><p>同步 hadoop102 上的 <code>/opt/module/hadoop-3.2.1</code> 到 hadoop103 和 hadoop104 上。</p>
<ul>
<li><p>方式一，在 hadoop102 上使用  rsync 命令，同步本地文件到 hadoop103 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ rsync -av /opt/module/hadoop-3.2.1/ xisun@hadoop103:/opt/module/hadoop-3.2.1/</span><br><span class="line">xisun@hadoop103<span class="string">&#x27;s password: </span></span><br></pre></td></tr></table></figure>
</li>
<li><p>方式二，在 hadoop104 上使用 rsync 命令，同步 hadoop102 上的文件到本地：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 ~]$ rsync -av xisun@hadoop102:/opt/module/hadoop-3.2.1/ /opt/module/hadoop-3.2.1/</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop102 (192.168.10.102)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop102,192.168.10.102<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">xisun@hadoop102&#x27;</span>s password: </span><br></pre></td></tr></table></figure>
</li>
<li><p>方式三，在 hadoop103 上使用 rsync 命令，同步 hadoop102 上的文件到 hadoop104 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ rsync -av xisun@hadoop102:/opt/module/hadoop-3.2.1/ xisun@hadoop104:/opt/module/hadoop-3.2.1/</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="xsync-集群分发脚本"><a href="#xsync-集群分发脚本" class="headerlink" title="xsync 集群分发脚本"></a>xsync 集群分发脚本</h5><ul>
<li><p>需求：编写脚本，指定需要同步的文件路径参数，能够循环复制该路径下的所有文件到所有节点的相同路径下。</p>
</li>
<li><p>需求分析：</p>
<ul>
<li><p>使用 rsync 命令，实现同步拷贝。</p>
</li>
<li><p>期望脚本格式：<code>xsync 需要同步的文件名称</code></p>
</li>
<li><p>期望脚本在任何路径都能使用：将脚本放在声明了全局环境变量的路径下。</p>
<ul>
<li><p>查看全局变量的路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/home/xisun/.<span class="built_in">local</span>/bin:/home/xisun/bin:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.302.b08-0.el7_9.x86_64/bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以看出，在全局变量的路径中，有一个 <code>/home/xisun/bin:</code>，如果把编写的脚本 xsync 放在此路径下，即可在任何路径都能使用。或者，直接把脚本 xsync 所在的路径，配置到全局环境变量中也可以。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>脚本实现：</p>
<ul>
<li><p>在 <code>/home/xisun</code> 路径下，创建 bin 目录：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun</span><br><span class="line">[xisun@hadoop102 ~]$ mkdir bin</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 6 9月   1 11:43 bin</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun 6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 <code>/home/xisun/bin</code> 路径下，创建 xsync 文件，并添加脚本代码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 bin]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun/bin</span><br><span class="line">[xisun@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 1.判断参数个数，如果参数个数小于1，直接退出，$#是获得参数个数</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 2.遍历集群所有机器</span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo ====================  $host  ====================</span><br><span class="line">    # 3.遍历所有目录，挨个发送，$@是脚本的参数，可以有多个</span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        # 4.判断文件是否存在</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">            then</span><br><span class="line">                # 5.获取父目录</span><br><span class="line">                pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">                # 6.获取当前文件的名称</span><br><span class="line">                fname=$(basename $file)</span><br><span class="line">                # 7.在目标主机上，创建目录</span><br><span class="line">                ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                # 8.同步拷贝</span><br><span class="line">                rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">            else</span><br><span class="line">                echo $file does not exists!</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210901133253592.png" alt="image-20210901133253592"></p>
</li>
<li><p>修改脚本 xsync，使其具有可执行权限：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 bin]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 908 9月   1 13:33 xsync</span><br><span class="line">[xisun@hadoop102 bin]$ chmod 777 xsync </span><br><span class="line">[xisun@hadoop102 bin]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">-rwxrwxrwx. 1 xisun xisun 908 9月   1 13:33 xsync</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试脚本，将 hadoop102 上的 <code>/home/xisun/bin</code> 目录，同步到 hadoop103 和 hadoop104 上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun</span><br><span class="line">[xisun@hadoop102 ~]$ xsync /home/xisun/bin/</span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop102 (192.168.10.102)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:AOkUHU40E6uekNRiFpZkT4R2gfoE+s9ujdYTZ5e8kwM.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:dd:80:45:3e:83:75:92:fe:57:d3:78:fa:af:5a:ca:1b.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>hadoop102,192.168.10.102<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">xisun@hadoop102&#x27;</span>s password: </span><br><span class="line">xisun@hadoop102<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">sending incremental file list</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sent 90 bytes  received 17 bytes  16.46 bytes/sec</span></span><br><span class="line"><span class="string">total size is 908  speedup is 8.49</span></span><br><span class="line"><span class="string">==================== hadoop103 ====================</span></span><br><span class="line"><span class="string">xisun@hadoop103&#x27;</span>s password: </span><br><span class="line">xisun@hadoop103<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">sending incremental file list</span></span><br><span class="line"><span class="string">bin/</span></span><br><span class="line"><span class="string">bin/xsync</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sent 1,044 bytes  received 39 bytes  196.91 bytes/sec</span></span><br><span class="line"><span class="string">total size is 908  speedup is 0.84</span></span><br><span class="line"><span class="string">==================== hadoop104 ====================</span></span><br><span class="line"><span class="string">xisun@hadoop104&#x27;</span>s password: </span><br><span class="line">xisun@hadoop104<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">sending incremental file list</span></span><br><span class="line"><span class="string">bin/</span></span><br><span class="line"><span class="string">bin/xsync</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sent 1,044 bytes  received 39 bytes  240.67 bytes/sec</span></span><br><span class="line"><span class="string">total size is 908  speedup is 0.84</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h4 id="ssh-免密登录配置"><a href="#ssh-免密登录配置" class="headerlink" title="ssh 免密登录配置"></a>ssh 免密登录配置</h4><ul>
<li><p>ssh 命令可以在当前主机上，连接另一台主机，在连接过程中，需要另一台主机的通行密码。</p>
<ul>
<li><p>基本语法：<code>ssh 另一台主机的IP地址</code></p>
</li>
<li><p>ssh 连接时出现 Host key verification failed 的解决方法：输入 yes 并回车。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Are you sure you want to <span class="built_in">continue</span> connecting (yes/no)? </span><br></pre></td></tr></table></figure>
</li>
<li><p>ssh 连接到另一台主机后，使用 exit 命令可以回到原来的主机：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ ssh hadoop103</span><br><span class="line">xisun@hadoop103<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string">Last login: Tue Aug 31 16:47:43 2021 from 192.168.10.1</span></span><br><span class="line"><span class="string">[xisun@hadoop103 ~]$ exit </span></span><br><span class="line"><span class="string">登出</span></span><br><span class="line"><span class="string">Connection to hadoop103 closed.</span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ </span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>免密钥配置</p>
<ul>
<li><p>免密登录原理：</p>
<p><img src="/2021/08/25/hadoop/image-20210901151616233.png" alt="image-20210901151616233"></p>
</li>
<li><p>在 hadoop102 生成公钥和私钥：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 .ssh]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun/.ssh</span><br><span class="line">[xisun@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/home/xisun/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/xisun/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/xisun/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:j9G3rd2/lBjPliez4vXcinw0R5CJy8mja0u7wBWgPDU xisun@hadoop102</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">|        E    . o |</span></span><br><span class="line"><span class="string">|     . o o  . +  |</span></span><br><span class="line"><span class="string">|      +   .o o . |</span></span><br><span class="line"><span class="string">|       . . .*   .|</span></span><br><span class="line"><span class="string">|        S o..o . |</span></span><br><span class="line"><span class="string">|       . =.. oB +|</span></span><br><span class="line"><span class="string">|        + o..o=X.|</span></span><br><span class="line"><span class="string">|         ooo.=+Bo|</span></span><br><span class="line"><span class="string">|         .++=o+oO|</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br><span class="line"><span class="string">[xisun@hadoop102 .ssh]$ ll</span></span><br><span class="line"><span class="string">总用量 12</span></span><br><span class="line"><span class="string">-rw-------. 1 xisun xisun 1675 9月   1 15:59 id_rsa</span></span><br><span class="line"><span class="string">-rw-r--r--. 1 xisun xisun  397 9月   1 15:59 id_rsa.pub</span></span><br><span class="line"><span class="string">-rw-r--r--. 1 xisun xisun  558 9月   1 14:29 known_hosts</span></span><br></pre></td></tr></table></figure>

<ul>
<li>在 <code>/home/xisun/.ssh</code> 路径下，执行 <code>ssh-keygen -t rsa</code> 命令，敲三次回车，即可生成两个文件，私钥和公钥。</li>
<li>id_rsa 为 hadoop102 的私钥，id_rsa.pub 为 hadoop102 的公钥。</li>
</ul>
</li>
<li><p>将 hadoop102 的公钥，拷贝到要免密登录的目标机器上，即 hadoop102，hadoop103 和 hadoop104：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ ssh-copy-id hadoop102</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/home/xisun/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to <span class="built_in">log</span> <span class="keyword">in</span> with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- <span class="keyword">if</span> you are prompted now it is to install the new keys</span><br><span class="line">xisun@hadoop102<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Number of key(s) added: 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Now try logging into the machine, with:   &quot;ssh &#x27;</span>hadoop102<span class="string">&#x27;&quot;</span></span><br><span class="line"><span class="string">and check to make sure that only the key(s) you wanted were added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ ssh hadoop102</span></span><br><span class="line"><span class="string">Last login: Wed Sep  1 16:11:59 2021 from hadoop102</span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ exit</span></span><br><span class="line"><span class="string">登出</span></span><br><span class="line"><span class="string">Connection to hadoop102 closed.</span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ </span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/home/xisun/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to <span class="built_in">log</span> <span class="keyword">in</span> with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- <span class="keyword">if</span> you are prompted now it is to install the new keys</span><br><span class="line">xisun@hadoop103<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Number of key(s) added: 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Now try logging into the machine, with:   &quot;ssh &#x27;</span>hadoop103<span class="string">&#x27;&quot;</span></span><br><span class="line"><span class="string">and check to make sure that only the key(s) you wanted were added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[xisun@hadoop102 .ssh]$ ssh hadoop103</span></span><br><span class="line"><span class="string">Last login: Wed Sep  1 15:02:49 2021 from hadoop102</span></span><br><span class="line"><span class="string">[xisun@hadoop103 ~]$ exit</span></span><br><span class="line"><span class="string">登出</span></span><br><span class="line"><span class="string">Connection to hadoop103 closed.</span></span><br><span class="line"><span class="string">[xisun@hadoop102 .ssh]$ </span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/home/xisun/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to <span class="built_in">log</span> <span class="keyword">in</span> with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- <span class="keyword">if</span> you are prompted now it is to install the new keys</span><br><span class="line">xisun@hadoop104<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Number of key(s) added: 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Now try logging into the machine, with:   &quot;ssh &#x27;</span>hadoop104<span class="string">&#x27;&quot;</span></span><br><span class="line"><span class="string">and check to make sure that only the key(s) you wanted were added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[xisun@hadoop102 .ssh]$ ssh hadoop104</span></span><br><span class="line"><span class="string">Last failed login: Wed Sep  1 14:43:15 CST 2021 from hadoop102 on ssh:notty</span></span><br><span class="line"><span class="string">There was 1 failed login attempt since the last successful login.</span></span><br><span class="line"><span class="string">Last login: Tue Aug 31 16:48:06 2021 from 192.168.10.1</span></span><br><span class="line"><span class="string">[xisun@hadoop104 ~]$ exit</span></span><br><span class="line"><span class="string">登出</span></span><br><span class="line"><span class="string">Connection to hadoop104 closed.</span></span><br><span class="line"><span class="string">[xisun@hadoop102 .ssh]$ </span></span><br></pre></td></tr></table></figure>
</li>
<li><p>按上面同样的步骤，对 hadoop103 和 hadoop104 进行 ssh 免密登录配置。</p>
</li>
<li><p>注意：上面的配置只对 xisun 用户有效，如果希望 root 用户也能免密 ssh 登录，需要切换到 root 账号，做同样的配置：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ su root</span><br><span class="line">密码：</span><br><span class="line">[root@hadoop102 xisun]<span class="comment"># cd .ssh/</span></span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># pwd</span></span><br><span class="line">/home/xisun/.ssh</span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># ll</span></span><br><span class="line">总用量 16</span><br><span class="line">-rw-------. 1 xisun xisun 1191 9月   1 16:32 authorized_keys</span><br><span class="line">-rw-------. 1 xisun xisun 1675 9月   1 15:59 id_rsa</span><br><span class="line">-rw-r--r--. 1 xisun xisun  397 9月   1 15:59 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 xisun xisun  558 9月   1 14:29 known_hosts</span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># ssh-keygen -t rsa</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:AQtFVBbgnBrY8u/vIGgxFUxqHtKOYzKFIVRbHNJoMEw root@hadoop102</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">|*Eo=B*Bo+.       |</span></span><br><span class="line"><span class="string">|.=.*=B =         |</span></span><br><span class="line"><span class="string">|o X.+ = .        |</span></span><br><span class="line"><span class="string">| B = o   .       |</span></span><br><span class="line"><span class="string">|=.= o   S        |</span></span><br><span class="line"><span class="string">|oo + .           |</span></span><br><span class="line"><span class="string">|  o . o          |</span></span><br><span class="line"><span class="string">| .   o .         |</span></span><br><span class="line"><span class="string">|      .oo        |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br><span class="line"><span class="string">[root@hadoop102 .ssh]# ssh-copy-id hadoop102</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span></span><br><span class="line"><span class="string">root@hadoop102&#x27;</span>s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   <span class="string">&quot;ssh &#x27;hadoop102&#x27;&quot;</span></span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># ssh hadoop102</span></span><br><span class="line">Last login: Wed Sep  1 16:41:01 2021</span><br><span class="line">[root@hadoop102 ~]<span class="comment"># exit</span></span><br><span class="line">登出</span><br><span class="line">Connection to hadoop102 closed.</span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># ssh-copy-id hadoop103</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to <span class="built_in">log</span> <span class="keyword">in</span> with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- <span class="keyword">if</span> you are prompted now it is to install the new keys</span><br><span class="line">root@hadoop103<span class="string">&#x27;s password: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Number of key(s) added: 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Now try logging into the machine, with:   &quot;ssh &#x27;</span>hadoop103<span class="string">&#x27;&quot;</span></span><br><span class="line"><span class="string">and check to make sure that only the key(s) you wanted were added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@hadoop102 .ssh]# ssh hadoop103</span></span><br><span class="line"><span class="string">Last failed login: Wed Sep  1 14:48:11 CST 2021 from hadoop102 on ssh:notty</span></span><br><span class="line"><span class="string">There was 1 failed login attempt since the last successful login.</span></span><br><span class="line"><span class="string">Last login: Tue Aug 31 10:02:38 2021</span></span><br><span class="line"><span class="string">exi[root@hadoop103 ~]# exit</span></span><br><span class="line"><span class="string">登出</span></span><br><span class="line"><span class="string">Connection to hadoop103 closed.</span></span><br><span class="line"><span class="string">[root@hadoop102 .ssh]# ssh-copy-id hadoop104</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span></span><br><span class="line"><span class="string">root@hadoop104&#x27;</span>s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   <span class="string">&quot;ssh &#x27;hadoop104&#x27;&quot;</span></span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># ssh hadoop104</span></span><br><span class="line">Last login: Wed Sep  1 16:39:50 2021</span><br><span class="line">[root@hadoop104 ~]<span class="comment"># exit</span></span><br><span class="line">登出</span><br><span class="line">Connection to hadoop104 closed.</span><br><span class="line">[root@hadoop102 .ssh]<span class="comment"># </span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置完免密登录后，测试可以看出，使用 xsync 脚本分发文件时，不需要输入密码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ xsync a.txt </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 58 bytes  received 12 bytes  46.67 bytes/sec</span><br><span class="line">total size is 0  speedup is 0.00</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">a.txt</span><br><span class="line"></span><br><span class="line">sent 101 bytes  received 35 bytes  272.00 bytes/sec</span><br><span class="line">total size is 0  speedup is 0.00</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">a.txt</span><br><span class="line"></span><br><span class="line">sent 101 bytes  received 35 bytes  272.00 bytes/sec</span><br><span class="line">total size is 0  speedup is 0.00</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>/home/xisun/.ssh</code> 路径下的文件功能解释：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 .ssh]$ ll</span><br><span class="line">总用量 16</span><br><span class="line">-rw-------. 1 xisun xisun  397 9月   1 16:12 authorized_keys</span><br><span class="line">-rw-------. 1 xisun xisun 1675 9月   1 15:59 id_rsa</span><br><span class="line">-rw-r--r--. 1 xisun xisun  397 9月   1 15:59 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 xisun xisun  558 9月   1 14:29 known_hosts</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>文件名</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>known_hosts</td>
<td>记录当前主机ssh访问过的计算机的公钥（public  key）</td>
</tr>
<tr>
<td>id_rsa</td>
<td>当前主机生成的私钥</td>
</tr>
<tr>
<td>id_rsa.pub</td>
<td>当前主机生成的公钥</td>
</tr>
<tr>
<td>authorized_keys</td>
<td>存放授权过的无密登录服务器公钥</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h4 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h4><h5 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h5><table>
<thead>
<tr>
<th></th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td><strong>NameNode</strong><br>DataNode</td>
<td><br>DataNode</td>
<td><strong>SecondaryNameNode</strong><br>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td><br>NodeManager</td>
<td><strong>ResourceManager</strong><br>NodeManager</td>
<td><br>NodeManager</td>
</tr>
</tbody></table>
<ul>
<li>NameNode 和 SecondaryNameNode 都比较消耗内存，不要安装在同一台服务器上。</li>
<li>ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode 配置在同一台服务器上。</li>
</ul>
<h5 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h5><ul>
<li><p>Hadoop 配置文件分两类：默认配置文件和自定义配置文件。只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
</li>
<li><p>默认配置文件</p>
<table>
<thead>
<tr>
<th>要获取的默认文件</th>
<th>文件存放在Hadoop的JAR包中的位置</th>
</tr>
</thead>
<tbody><tr>
<td>[core-default.xml]</td>
<td>hadoop-common-3.2.1.jar/core-default.xml</td>
</tr>
<tr>
<td>[hdfs-default.xml]</td>
<td>hadoop-hdfs-3.2.1.jar/hdfs-default.xml</td>
</tr>
<tr>
<td>[yarn-default.xml]</td>
<td>hadoop-yarn-common-3.2.1.jar/yarn-default.xml</td>
</tr>
<tr>
<td>[mapred-default.xml]</td>
<td>hadoop-mapreduce-client-core-3.2.1.jar/mapred-default.xml</td>
</tr>
</tbody></table>
<ul>
<li><p>core-default.xml：</p>
<p><img src="/2021/08/25/hadoop/image-20210909161942025.png" alt="image-20210909161942025"></p>
</li>
<li><p>hdfs-default.xml：</p>
<p><img src="/2021/08/25/hadoop/image-20210909163524558.png" alt="image-20210909163524558"></p>
<ul>
<li><p>需要添加依赖才能看到：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>yarn-default.xml：</p>
<p><img src="/2021/08/25/hadoop/image-20210909162213537.png" alt="image-20210909162213537"></p>
</li>
<li><p>mapred-default.xml：</p>
<p><img src="/2021/08/25/hadoop/image-20210909162538370.png" alt="image-20210909162538370"></p>
</li>
</ul>
</li>
<li><p>自定义配置文件</p>
<ul>
<li><p>Hadoop 的四个默认配置文件，分别对应以下四个自定义配置文件：core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml。这四个自定义配置文件，存放在 <code>$HADOOP_HOME/etc/hadoop</code> 这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ ll</span><br><span class="line">总用量 172</span><br><span class="line">-rw-r--r--. 1 xisun xisun  8260 9月  11 2019 capacity-scheduler.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1335 9月  11 2019 configuration.xsl</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1940 9月  11 2019 container-executor.cfg</span><br><span class="line">-rw-r--r--. 1 xisun xisun   774 9月  10 2019 core-site.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  3999 9月  10 2019 hadoop-env.cmd</span><br><span class="line">-rw-r--r--. 1 xisun xisun 16235 9月  11 2019 hadoop-env.sh</span><br><span class="line">-rw-r--r--. 1 xisun xisun  3321 9月  10 2019 hadoop-metrics2.properties</span><br><span class="line">-rw-r--r--. 1 xisun xisun 11392 9月  10 2019 hadoop-policy.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  3414 9月  10 2019 hadoop-user-functions.sh.example</span><br><span class="line">-rw-r--r--. 1 xisun xisun   775 9月  11 2019 hdfs-site.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1484 9月  11 2019 httpfs-env.sh</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1657 9月  11 2019 httpfs-log4j.properties</span><br><span class="line">-rw-r--r--. 1 xisun xisun    21 9月  11 2019 httpfs-signature.secret</span><br><span class="line">-rw-r--r--. 1 xisun xisun   620 9月  11 2019 httpfs-site.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  3518 9月  10 2019 kms-acls.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1351 9月  10 2019 kms-env.sh</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1860 9月  10 2019 kms-log4j.properties</span><br><span class="line">-rw-r--r--. 1 xisun xisun   682 9月  10 2019 kms-site.xml</span><br><span class="line">-rw-r--r--. 1 xisun xisun 13326 9月  10 2019 log4j.properties</span><br><span class="line">-rw-r--r--. 1 xisun xisun   951 9月  11 2019 mapred-env.cmd</span><br><span class="line">-rw-r--r--. 1 xisun xisun  1764 9月  11 2019 mapred-env.sh</span><br><span class="line">-rw-r--r--. 1 xisun xisun  4113 9月  11 2019 mapred-queues.xml.template</span><br><span class="line">-rw-r--r--. 1 xisun xisun   758 9月  11 2019 mapred-site.xml</span><br><span class="line">drwxr-xr-x. 2 xisun xisun    24 9月  10 2019 shellprofile.d</span><br><span class="line">-rw-r--r--. 1 xisun xisun  2316 9月  10 2019 ssl-client.xml.example</span><br><span class="line">-rw-r--r--. 1 xisun xisun  2697 9月  10 2019 ssl-server.xml.example</span><br><span class="line">-rw-r--r--. 1 xisun xisun  2642 9月  11 2019 user_ec_policies.xml.template</span><br><span class="line">-rw-r--r--. 1 xisun xisun    10 9月  10 2019 workers</span><br><span class="line">-rw-r--r--. 1 xisun xisun  2250 9月  11 2019 yarn-env.cmd</span><br><span class="line">-rw-r--r--. 1 xisun xisun  6056 9月  11 2019 yarn-env.sh</span><br><span class="line">-rw-r--r--. 1 xisun xisun  2591 9月  11 2019 yarnservice-log4j.properties</span><br><span class="line">-rw-r--r--. 1 xisun xisun   690 9月  11 2019 yarn-site.xml</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h5 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h5><ul>
<li><p>第一步：核心配置文件 — 配置 core-site.xml。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim core-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定Hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.2.1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第二步：HDFS 配置文件 — 配置 hdfs-site.xml。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web端访问地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 2nn web端访问地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第三步：YARN 配置文件 — 配置 yarn-site.xml。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定ResourceManager的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第四步：MapReduce 配置文件 — 配置 mapred-site.xml。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第五步：在集群上分发在 hadoop102 上配置好的 Hadoop 配置文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.2.1/etc/hadoop/</span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 972 bytes  received 18 bytes  1,980.00 bytes/sec</span><br><span class="line">total size is 107,791  speedup is 108.88</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 3,165 bytes  received 139 bytes  2,202.67 bytes/sec</span><br><span class="line">total size is 107,791  speedup is 32.62</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 3,165 bytes  received 139 bytes  6,608.00 bytes/sec</span><br><span class="line">total size is 107,791  speedup is 32.62</span><br></pre></td></tr></table></figure>
</li>
<li><p>第六步：到 hadoop103 和 hadoop104 上查看文件分发情况。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ cat /opt/module/hadoop-3.2.1/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 ~]$ cat /opt/module/hadoop-3.2.1/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h4><h5 id="配置-workers"><a href="#配置-workers" class="headerlink" title="配置 workers"></a>配置 workers</h5><ul>
<li><p>打开 workers 文件，删除默认值 localhost，然后向 workers 文件中添加如下内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim workers</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>
</li>
<li><p>workers 文件中添加的主机名，即是 Hadoop 集群中的各个节点。</p>
</li>
<li><p>注意：workers 文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p>
</li>
<li><p>同步所有节点配置文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.2.1/etc/hadoop/workers </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 59 bytes  received 12 bytes  142.00 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.42</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">workers</span><br><span class="line"></span><br><span class="line">sent 136 bytes  received 41 bytes  354.00 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.17</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">workers</span><br><span class="line"></span><br><span class="line">sent 136 bytes  received 41 bytes  354.00 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.17</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h5><ul>
<li><p>第一步：如果集群是第一次启动，需要在配置了 NameNode 的节点（hadoop102）上格式化 NameNode。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs namenode -format</span><br><span class="line">WARNING: /opt/module/hadoop-3.2.1/logs does not exist. Creating.</span><br><span class="line">2021-09-01 22:39:39,794 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = hadoop102/192.168.10.102</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 3.2.1</span><br><span class="line">STARTUP_MSG:   classpath = /opt/module/hadoop-3.2.1/etc/hadoop:…… ……</span><br><span class="line">STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by <span class="string">&#x27;rohithsharmaks&#x27;</span> on 2019-09-10T15:56Z</span><br><span class="line">STARTUP_MSG:   java = 1.8.0_302</span><br><span class="line">************************************************************/</span><br><span class="line">2021-09-01 22:39:40,092 INFO namenode.NameNode: registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line">2021-09-01 22:39:42,475 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">Formatting using clusterid: CID-ffd49d0a-1e29-4912-91a7-0d6ce7121fda</span><br><span class="line">2021-09-01 22:39:49,477 INFO namenode.FSEditLog: Edit logging is async:<span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:52,982 INFO namenode.FSNamesystem: KeyProvider: null</span><br><span class="line">2021-09-01 22:39:53,002 INFO namenode.FSNamesystem: fsLock is fair: <span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:53,037 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: <span class="literal">false</span></span><br><span class="line">2021-09-01 22:39:53,112 INFO namenode.FSNamesystem: fsOwner             = xisun (auth:SIMPLE)</span><br><span class="line">2021-09-01 22:39:53,112 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">2021-09-01 22:39:53,113 INFO namenode.FSNamesystem: isPermissionEnabled = <span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:53,113 INFO namenode.FSNamesystem: HA Enabled: <span class="literal">false</span></span><br><span class="line">2021-09-01 22:39:54,396 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage <span class="built_in">set</span> to 0. Disabling file IO profiling</span><br><span class="line">2021-09-01 22:39:54,448 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000</span><br><span class="line">2021-09-01 22:39:54,448 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:54,617 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is <span class="built_in">set</span> to 000:00:00:00.000</span><br><span class="line">2021-09-01 22:39:54,618 INFO blockmanagement.BlockManager: The block deletion will start around 2021 九月 01 22:39:54</span><br><span class="line">2021-09-01 22:39:54,621 INFO util.GSet: Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line">2021-09-01 22:39:54,621 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">2021-09-01 22:39:54,654 INFO util.GSet: 2.0% max memory 441 MB = 8.8 MB</span><br><span class="line">2021-09-01 22:39:54,654 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">2021-09-01 22:39:54,679 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled</span><br><span class="line">2021-09-01 22:39:54,679 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = <span class="literal">false</span></span><br><span class="line">2021-09-01 22:39:54,707 INFO Configuration.deprecation: No unit <span class="keyword">for</span> dfs.namenode.safemode.extension(30000) assuming MILLISECONDS</span><br><span class="line">2021-09-01 22:39:54,707 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">2021-09-01 22:39:54,708 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">2021-09-01 22:39:54,708 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000</span><br><span class="line">2021-09-01 22:39:54,708 INFO blockmanagement.BlockManager: defaultReplication         = 3</span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms</span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line">2021-09-01 22:39:54,709 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">2021-09-01 22:39:54,794 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911</span><br><span class="line">2021-09-01 22:39:54,794 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215</span><br><span class="line">2021-09-01 22:39:54,794 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215</span><br><span class="line">2021-09-01 22:39:54,794 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215</span><br><span class="line">2021-09-01 22:39:54,831 INFO util.GSet: Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line">2021-09-01 22:39:54,832 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">2021-09-01 22:39:54,832 INFO util.GSet: 1.0% max memory 441 MB = 4.4 MB</span><br><span class="line">2021-09-01 22:39:54,832 INFO util.GSet: capacity      = 2^19 = 524288 entries</span><br><span class="line">2021-09-01 22:39:54,833 INFO namenode.FSDirectory: ACLs enabled? <span class="literal">false</span></span><br><span class="line">2021-09-01 22:39:54,834 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? <span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:54,834 INFO namenode.FSDirectory: XAttrs enabled? <span class="literal">true</span></span><br><span class="line">2021-09-01 22:39:54,834 INFO namenode.NameNode: Caching file names occurring more than 10 <span class="built_in">times</span></span><br><span class="line">2021-09-01 22:39:54,847 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: <span class="literal">false</span>, skipCaptureAccessTimeOnlyChange: <span class="literal">false</span>, snapshotDiffAllowSnapRootDescendant: <span class="literal">true</span>, maxSnapshotLimit: 65536</span><br><span class="line">2021-09-01 22:39:54,859 INFO snapshot.SnapshotManager: SkipList is disabled</span><br><span class="line">2021-09-01 22:39:54,868 INFO util.GSet: Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line">2021-09-01 22:39:54,868 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">2021-09-01 22:39:54,868 INFO util.GSet: 0.25% max memory 441 MB = 1.1 MB</span><br><span class="line">2021-09-01 22:39:54,868 INFO util.GSet: capacity      = 2^17 = 131072 entries</span><br><span class="line">2021-09-01 22:39:54,899 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10</span><br><span class="line">2021-09-01 22:39:54,899 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10</span><br><span class="line">2021-09-01 22:39:54,899 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25</span><br><span class="line">2021-09-01 22:39:54,914 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">2021-09-01 22:39:54,914 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">2021-09-01 22:39:54,917 INFO util.GSet: Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line">2021-09-01 22:39:54,917 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">2021-09-01 22:39:54,917 INFO util.GSet: 0.029999999329447746% max memory 441 MB = 135.5 KB</span><br><span class="line">2021-09-01 22:39:54,917 INFO util.GSet: capacity      = 2^14 = 16384 entries</span><br><span class="line">2021-09-01 22:39:55,000 INFO namenode.FSImage: Allocated new BlockPoolId: BP-288566776-192.168.10.102-1630507194979</span><br><span class="line">2021-09-01 22:39:55,144 INFO common.Storage: Storage directory /opt/module/hadoop-3.2.1/data/dfs/name has been successfully formatted.</span><br><span class="line">2021-09-01 22:39:57,641 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/module/hadoop-3.2.1/data/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line">2021-09-01 22:39:58,078 INFO namenode.FSImageFormatProtobuf: Image file /opt/module/hadoop-3.2.1/data/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 400 bytes saved <span class="keyword">in</span> 0 seconds .</span><br><span class="line">2021-09-01 22:39:58,126 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">2021-09-01 22:39:58,206 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.</span><br><span class="line">2021-09-01 22:39:58,208 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at hadoop102/192.168.10.102</span><br><span class="line">************************************************************/</span><br><span class="line">[xisun@hadoop102 ~]$ ll /opt/module/hadoop-3.2.1/</span><br><span class="line">总用量 180</span><br><span class="line">drwxr-xr-x. 2 xisun xisun    203 9月  11 2019 bin</span><br><span class="line">drwxrwxr-x. 3 xisun xisun     17 9月   1 22:39 data</span><br><span class="line">drwxr-xr-x. 3 xisun xisun     20 9月  10 2019 etc</span><br><span class="line">drwxr-xr-x. 2 xisun xisun    106 9月  11 2019 include</span><br><span class="line">drwxr-xr-x. 3 xisun xisun     20 9月  11 2019 lib</span><br><span class="line">drwxr-xr-x. 4 xisun xisun    288 9月  11 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 150569 9月  10 2019 LICENSE.txt</span><br><span class="line">drwxrwxr-x. 2 xisun xisun     38 9月   1 22:39 logs</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  22125 9月  10 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1361 9月  10 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 xisun xisun   4096 9月  10 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 xisun xisun     31 9月  11 2019 share</span><br><span class="line">drwxrwxr-x. 2 xisun xisun     22 8月  31 16:00 wcinput</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     88 8月  31 16:04 wcoutput</span><br></pre></td></tr></table></figure>

<ul>
<li><p>格式化 NameNode 完毕后，会在 Hadoop 安装路径下，生成两个新目录 data 和 logs。</p>
</li>
<li><p>注意：第一次格式化 NameNode 之后，如果再次格式化 NameNode 时，会产生新的集群 id，这会导致与前一次生成的 NameNode 和 DataNode 的集群 id 不一致，集群会找不到已往数据。如果集群在运行过程中发生异常，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程（停止 YARN 和 HDFS），并且删除集群上所有机器的 data 和 logs 目录，然后再进行格式化。最后，重新启动集群。原因如下：</p>
<ul>
<li><p>NameNode 的版本号：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">cd</span> /opt/module/hadoop-3.2.1/data/dfs/</span><br><span class="line">[xisun@hadoop102 dfs]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwx------. 3 xisun xisun 40 9月   2 14:05 data</span><br><span class="line">drwxrwxr-x. 3 xisun xisun 40 9月   2 14:05 name</span><br><span class="line">[xisun@hadoop102 dfs]$ <span class="built_in">cd</span> name/current/</span><br><span class="line">[xisun@hadoop102 current]$ ll</span><br><span class="line">总用量 4196</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   1 22:59 edits_0000000000000000001-0000000000000000002</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   1 23:59 edits_0000000000000000003-0000000000000000004</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 00:59 edits_0000000000000000005-0000000000000000006</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 01:59 edits_0000000000000000007-0000000000000000008</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 02:59 edits_0000000000000000009-0000000000000000010</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 03:59 edits_0000000000000000011-0000000000000000012</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 04:59 edits_0000000000000000013-0000000000000000014</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 05:59 edits_0000000000000000015-0000000000000000016</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 06:59 edits_0000000000000000017-0000000000000000018</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 07:59 edits_0000000000000000019-0000000000000000020</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 08:59 edits_0000000000000000021-0000000000000000022</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 09:59 edits_0000000000000000023-0000000000000000024</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    1500 9月   2 10:59 edits_0000000000000000025-0000000000000000045</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 1048576 9月   2 11:34 edits_0000000000000000046-0000000000000000110</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 11:51 edits_0000000000000000111-0000000000000000112</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    8888 9月   2 12:51 edits_0000000000000000113-0000000000000000185</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 1048576 9月   2 12:51 edits_0000000000000000186-0000000000000000186</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 13:11 edits_0000000000000000187-0000000000000000188</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 1048576 9月   2 13:18 edits_0000000000000000189-0000000000000000271</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      42 9月   2 14:06 edits_0000000000000000272-0000000000000000273</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 1048576 9月   2 14:10 edits_inprogress_0000000000000000274</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    2460 9月   2 13:11 fsimage_0000000000000000188</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      62 9月   2 13:11 fsimage_0000000000000000188.md5</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    2955 9月   2 14:06 fsimage_0000000000000000273</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      62 9月   2 14:06 fsimage_0000000000000000273.md5</span><br><span class="line">-rw-rw-r--. 1 xisun xisun       4 9月   2 14:06 seen_txid</span><br><span class="line">-rw-rw-r--. 1 xisun xisun     217 9月   1 22:39 VERSION</span><br><span class="line">[xisun@hadoop102 current]$ cat VERSION </span><br><span class="line"><span class="comment">#Wed Sep 01 22:39:55 CST 2021</span></span><br><span class="line">namespaceID=817173371</span><br><span class="line">clusterID=CID-ffd49d0a-1e29-4912-91a7-0d6ce7121fda</span><br><span class="line">cTime=1630507194979</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-288566776-192.168.10.102-1630507194979</span><br><span class="line">layoutVersion=-65</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataNode 的版本号：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">cd</span> /opt/module/hadoop-3.2.1/data/dfs/</span><br><span class="line">[xisun@hadoop102 dfs]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwx------. 3 xisun xisun 40 9月   2 14:05 data</span><br><span class="line">drwxrwxr-x. 3 xisun xisun 40 9月   2 14:05 name</span><br><span class="line">[xisun@hadoop102 dfs]$ <span class="built_in">cd</span> data/current/</span><br><span class="line">[xisun@hadoop102 current]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwx------. 4 xisun xisun  54 9月   2 14:05 BP-288566776-192.168.10.102-1630507194979</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 229 9月   2 14:05 VERSION</span><br><span class="line">[xisun@hadoop102 current]$ cat VERSION </span><br><span class="line"><span class="comment">#Thu Sep 02 14:05:31 CST 2021</span></span><br><span class="line">storageID=DS-7c2f6c8b-80be-44b0-9905-f1621843d7a3</span><br><span class="line">clusterID=CID-ffd49d0a-1e29-4912-91a7-0d6ce7121fda</span><br><span class="line">cTime=0</span><br><span class="line">datanodeUuid=32411bd2-079d-42fb-874a-8e5b492824af</span><br><span class="line">storageType=DATA_NODE</span><br><span class="line">layoutVersion=-57</span><br></pre></td></tr></table></figure>
</li>
<li><p>集群正常情况下，DataNode 版本与 NameNode 的版本是对应的，如果重新格式化了 NameNode，NameNode 的版本号发生改变，集群上之前存储的 DataNode 下的数据，版本对应不上新的 NameNode，集群也就无法正常启动。因此，格式化 NameNode 之前，需要先删除集群所有机器的 data 和 logs 目录。</p>
<p><img src="/2021/08/25/hadoop/image-20210903165511703.png" alt="image-20210903165511703"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>第二步：在 hadoop102 上启动 HDFS。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ /opt/module/hadoop-3.2.1/sbin/start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">Starting datanodes</span><br><span class="line">hadoop103: WARNING: /opt/module/hadoop-3.2.1/logs does not exist. Creating.</span><br><span class="line">hadoop104: WARNING: /opt/module/hadoop-3.2.1/logs does not exist. Creating.</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以直接使用 start-dfs.sh （脚本存放的位置配置在了环境变量里，因此可以在任何路径使用）启动 HDFS。 </p>
</blockquote>
<ul>
<li><p>在 hadoop102 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">29008 DataNode</span><br><span class="line">28885 NameNode</span><br><span class="line">29365 Jps</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 hadoop103 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ jps</span><br><span class="line">23137 DataNode</span><br><span class="line">23283 Jps</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 hadoop104 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 ~]$ jps</span><br><span class="line">23146 SecondaryNameNode</span><br><span class="line">23259 Jps</span><br><span class="line">23023 DataNode</span><br></pre></td></tr></table></figure>
</li>
<li><p>Web 端查看 HDFS 的 NameNode，浏览器输入 <a target="_blank" rel="noopener" href="http://192.168.10.102:9870/">http://192.168.10.102:9870/</a> 或者  <a target="_blank" rel="noopener" href="http://hadoop102:9870/%EF%BC%88%E8%A6%81%E6%B1%82">http://hadoop102:9870/（要求</a> Windows 电脑上配置了 hadoop102 的主机映射）。</p>
<p><img src="/2021/08/25/hadoop/image-20210901231013153.png" alt="image-20210901231013153"></p>
<p><img src="/2021/08/25/hadoop/image-20210901231122710.png" alt="image-20210901231122710"></p>
</li>
</ul>
</li>
<li><p>第三步：在配置了 ResourceManager 的节点（hadoop103）上启动 YARN。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ /opt/module/hadoop-3.2.1/sbin/start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在 hadoop102 上也可以启动 YARN。</p>
<p>可以直接使用 start-yarn.sh （脚本存放的位置配置在了环境变量里，因此可以在任何路径使用）启动 YARN。</p>
</blockquote>
<ul>
<li><p>在 hadoop102 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">29008 DataNode</span><br><span class="line">28885 NameNode</span><br><span class="line">29671 Jps</span><br><span class="line">29563 NodeManager</span><br></pre></td></tr></table></figure>

<blockquote>
<p>hadoop102 是 NameNode 所在的节点。</p>
</blockquote>
</li>
<li><p>在 hadoop103 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 ~]$ jps</span><br><span class="line">23137 DataNode</span><br><span class="line">23523 ResourceManager</span><br><span class="line">23646 NodeManager</span><br><span class="line">23998 Jps</span><br></pre></td></tr></table></figure>

<blockquote>
<p>hadoop103 是 ResourceManager 所在的节点。</p>
</blockquote>
</li>
<li><p>在 hadoop104 上查看集群进程启动情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 ~]$ jps</span><br><span class="line">23602 Jps</span><br><span class="line">23480 NodeManager</span><br><span class="line">23146 SecondaryNameNode</span><br><span class="line">23023 DataNode</span><br></pre></td></tr></table></figure>

<blockquote>
<p>hadoop104 是 SecondaryNameNode 所在的节点。</p>
</blockquote>
</li>
<li><p>Web 端查看 YARN 的 ResourceManager，浏览器输入 <a target="_blank" rel="noopener" href="http://192.168.10.103:8088/">http://192.168.10.103:8088/</a> 或者 <a target="_blank" rel="noopener" href="http://hadoop103:8088/%EF%BC%88%E8%A6%81%E6%B1%82">http://hadoop103:8088/（要求</a> Windows 电脑上配置了 hadoop103 的主机映射）。</p>
<p><img src="/2021/08/25/hadoop/image-20210901232124548.png" alt="image-20210901232124548"></p>
</li>
</ul>
</li>
</ul>
<h5 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h5><ul>
<li><p>上传文件到集群</p>
<ul>
<li><p>上传小文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs dfs -mkdir /wcinput</span><br><span class="line">[xisun@hadoop102 ~]$ hdfs dfs -put /opt/module/hadoop-3.2.1/wcinput/word.txt /wcinput</span><br><span class="line">2021-09-02 10:14:15,604 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>在 Web 端查看 HDFS，根目录下新建了一个 wcinput 目录，wcinput 目录下也上传了一个 word.txt 文件：</p>
<p><img src="/2021/08/25/hadoop/image-20210902101737216.png" alt="image-20210902101737216"></p>
<p><img src="/2021/08/25/hadoop/image-20210902101938588.png" alt="image-20210902101938588"></p>
<p><img src="/2021/08/25/hadoop/image-20210902102355046.png" alt="image-20210902102355046"></p>
</li>
<li><p>说明：如果需要在 Web 页面上删除 HDFS 上的文件，需要配置 core-site.xml，添加如下配置，然后集群分发 core-site.xml 文件，并重新启动集群。否则没有权限删除。</p>
<p><img src="/2021/08/25/hadoop/image-20210903145651737.png" alt="image-20210903145651737"></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>xisun<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>上传大文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs dfs -put /opt/software/hadoop-3.2.1.tar.gz /</span><br><span class="line">2021-09-02 10:41:41,346 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 10:43:40,782 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 10:44:58,477 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210902104359318.png" alt="image-20210902104359318"></p>
</li>
</ul>
</li>
<li><p>集群上文件的存储位置</p>
<ul>
<li><p>查看 HDFS 文件存储路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">cd</span> /opt/module/hadoop-3.2.1/data/</span><br><span class="line">[xisun@hadoop102 data]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data</span><br><span class="line">[xisun@hadoop102 data]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 4 xisun xisun 30 9月   1 22:58 dfs</span><br><span class="line">drwxr-xr-x. 5 xisun xisun 57 9月   1 23:15 nm-local-dir</span><br><span class="line">[xisun@hadoop102 data]$ <span class="built_in">cd</span> dfs/</span><br><span class="line">[xisun@hadoop102 dfs]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwx------. 3 xisun xisun 40 9月   1 22:58 data</span><br><span class="line">drwxrwxr-x. 3 xisun xisun 40 9月   1 22:58 name</span><br><span class="line">[xisun@hadoop102 dfs]$ <span class="built_in">cd</span> data/</span><br><span class="line">[xisun@hadoop102 data]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 3 xisun xisun 70 9月   1 22:58 current</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 15 9月   1 22:58 in_use.lock</span><br><span class="line">[xisun@hadoop102 data]$ <span class="built_in">cd</span> current/BP-288566776-192.168.10.102-1630507194979/</span><br><span class="line">current/ tmp/     </span><br><span class="line">[xisun@hadoop102 data]$ <span class="built_in">cd</span> current/BP-288566776-192.168.10.102-1630507194979/current/</span><br><span class="line">finalized/ rbw/       </span><br><span class="line">[xisun@hadoop102 data]$ <span class="built_in">cd</span> current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0/</span><br><span class="line">[xisun@hadoop102 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/data/current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0</span><br><span class="line">[xisun@hadoop102 subdir0]$ ll</span><br><span class="line">总用量 353540</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        41 9月   2 10:14 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        11 9月   2 10:14 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:43 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:43 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:44 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:44 blk_1073741827_1003.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  90761455 9月   2 10:45 blk_1073741828</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    709083 9月   2 10:45 blk_1073741828_1004.meta</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看 HDFS 在磁盘存储的 word.txt 文件的内容，可以看出，blk_1073741825 就是之前上传的 word.txt 文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 subdir0]$ cat blk_1073741825</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xisun</span><br><span class="line">xisun</span><br></pre></td></tr></table></figure>
</li>
<li><p>拼接 HDFS 在磁盘存储的 hadoop-3.2.1.tar.gz 文件的内容，追加到临时的压缩文件中，解压之后可以看出，blk_1073741826，blk_1073741827 和 blk_1073741828 就是之前上传的 hadoop-3.2.1.tar.gz 压缩文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 subdir0]$ cat blk_1073741826 &gt;&gt; ~/tmp.tar.gz</span><br><span class="line">[xisun@hadoop102 subdir0]$ cat blk_1073741827 &gt;&gt; ~/tmp.tar.gz</span><br><span class="line">[xisun@hadoop102 subdir0]$ cat blk_1073741828 &gt;&gt; ~/tmp.tar.gz</span><br><span class="line">[xisun@hadoop102 subdir0]$ <span class="built_in">cd</span> ~</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 393216</span><br><span class="line">drwxrwxr-x. 2 xisun xisun        19 9月   1 13:33 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 359196911 9月   2 11:00 tmp.tar.gz</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ tar -zxf tmp.tar.gz </span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 393216</span><br><span class="line">drwxrwxr-x. 2 xisun xisun        19 9月   1 13:33 bin</span><br><span class="line">drwxr-xr-x. 9 xisun xisun       149 9月  11 2019 hadoop-3.2.1</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 359196911 9月   2 11:00 tmp.tar.gz</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun         6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>

<ul>
<li><p>说明：HDFS 在磁盘上存储的文件，可能是分散的，需要了解分散到哪些文件了，才能追加拼接。</p>
<p><img src="/2021/08/25/hadoop/image-20210903150350257.png" alt="image-20210903150350257"></p>
<p><img src="/2021/08/25/hadoop/image-20210903150602428.png" alt="image-20210903150602428"></p>
</li>
</ul>
</li>
<li><p>HDFS 上的文件是备份在集群的每一台服务器上的（也就是集群的每一台服务器，都是 DataNode），在 hadoop102，hadoop103 和 hadoop104 上相同的路径下，都有相同的数据备份。</p>
<p><img src="/2021/08/25/hadoop/image-20210902111343188.png" alt="image-20210902111343188"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/data/current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0</span><br><span class="line">[xisun@hadoop102 subdir0]$ ll</span><br><span class="line">总用量 353540</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        41 9月   2 10:14 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        11 9月   2 10:14 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:43 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:43 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:44 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:44 blk_1073741827_1003.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  90761455 9月   2 10:45 blk_1073741828</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    709083 9月   2 10:45 blk_1073741828_1004.meta</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop103 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/data/current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0</span><br><span class="line">[xisun@hadoop103 subdir0]$ ll</span><br><span class="line">总用量 353540</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        41 9月   2 10:14 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        11 9月   2 10:14 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:43 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:43 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:44 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:44 blk_1073741827_1003.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  90761455 9月   2 10:45 blk_1073741828</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    709083 9月   2 10:45 blk_1073741828_1004.meta</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop104 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/data/current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0</span><br><span class="line">[xisun@hadoop104 subdir0]$ ll</span><br><span class="line">总用量 353540</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        41 9月   2 10:14 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 xisun xisun        11 9月   2 10:14 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:43 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:43 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 134217728 9月   2 10:44 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   1048583 9月   2 10:44 blk_1073741827_1003.meta</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  90761455 9月   2 10:45 blk_1073741828</span><br><span class="line">-rw-rw-r--. 1 xisun xisun    709083 9月   2 10:45 blk_1073741828_1004.meta</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>从集群下载文件到本地</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 19 9月   1 13:33 bin</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -get /wcinput/word.txt ./</span><br><span class="line">2021-09-02 11:24:37,690 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 19 9月   1 13:33 bin</span><br><span class="line">-rw-r--r--. 1 xisun xisun 41 9月   2 11:24 word.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ cat word.txt </span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xisun</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行 wordcount 程序，查看 YARN 的执行情况。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop jar /opt/module/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount /wcinput /wcoutput</span><br><span class="line">2021-09-02 13:15:36,538 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.10.103:8032</span><br><span class="line">2021-09-02 13:15:36,985 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding <span class="keyword">for</span> path: /tmp/hadoop-yarn/staging/xisun/.staging/job_1630509320297_0004</span><br><span class="line">2021-09-02 13:15:37,189 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 13:15:38,237 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">2021-09-02 13:15:38,317 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 13:15:38,407 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 13:15:38,456 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">2021-09-02 13:15:38,608 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-02 13:15:38,673 INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_1630509320297_0004</span><br><span class="line">2021-09-02 13:15:38,673 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2021-09-02 13:15:38,887 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2021-09-02 13:15:38,887 INFO resource.ResourceUtils: Unable to find <span class="string">&#x27;resource-types.xml&#x27;</span>.</span><br><span class="line">2021-09-02 13:15:38,964 INFO impl.YarnClientImpl: Submitted application application_1630509320297_0004</span><br><span class="line">2021-09-02 13:15:39,063 INFO mapreduce.Job: The url to track the job: http://hadoop103:8088/proxy/application_1630509320297_0004/</span><br><span class="line">2021-09-02 13:15:39,063 INFO mapreduce.Job: Running job: job_1630509320297_0004</span><br><span class="line">2021-09-02 13:15:48,877 INFO mapreduce.Job: Job job_1630509320297_0004 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span><br><span class="line">2021-09-02 13:15:48,879 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2021-09-02 13:17:39,986 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2021-09-02 13:18:46,452 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2021-09-02 13:18:48,469 INFO mapreduce.Job: Job job_1630509320297_0004 completed successfully</span><br><span class="line">2021-09-02 13:18:48,743 INFO mapreduce.Job: Counters: 54</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes <span class="built_in">read</span>=58</span><br><span class="line">		FILE: Number of bytes written=452423</span><br><span class="line">		FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes <span class="built_in">read</span>=144</span><br><span class="line">		HDFS: Number of bytes written=36</span><br><span class="line">		HDFS: Number of <span class="built_in">read</span> operations=8</span><br><span class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		HDFS: Number of write operations=2</span><br><span class="line">		HDFS: Number of bytes <span class="built_in">read</span> erasure-coded=0</span><br><span class="line">	Job Counters </span><br><span class="line">		Launched map tasks=1</span><br><span class="line">		Launched reduce tasks=1</span><br><span class="line">		Data-local map tasks=1</span><br><span class="line">		Total time spent by all maps <span class="keyword">in</span> occupied slots (ms)=108569</span><br><span class="line">		Total time spent by all reduces <span class="keyword">in</span> occupied slots (ms)=63584</span><br><span class="line">		Total time spent by all map tasks (ms)=108569</span><br><span class="line">		Total time spent by all reduce tasks (ms)=63584</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=108569</span><br><span class="line">		Total vcore-milliseconds taken by all reduce tasks=63584</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=111174656</span><br><span class="line">		Total megabyte-milliseconds taken by all reduce tasks=65110016</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=4</span><br><span class="line">		Map output records=6</span><br><span class="line">		Map output bytes=65</span><br><span class="line">		Map output materialized bytes=58</span><br><span class="line">		Input split bytes=103</span><br><span class="line">		Combine input records=6</span><br><span class="line">		Combine output records=4</span><br><span class="line">		Reduce input groups=4</span><br><span class="line">		Reduce shuffle bytes=58</span><br><span class="line">		Reduce input records=4</span><br><span class="line">		Reduce output records=4</span><br><span class="line">		Spilled Records=8</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=11835</span><br><span class="line">		CPU time spent (ms)=68260</span><br><span class="line">		Physical memory (bytes) snapshot=507523072</span><br><span class="line">		Virtual memory (bytes) snapshot=5576531968</span><br><span class="line">		Total committed heap usage (bytes)=404226048</span><br><span class="line">		Peak Map Physical memory (bytes)=297627648</span><br><span class="line">		Peak Map Virtual memory (bytes)=2785103872</span><br><span class="line">		Peak Reduce Physical memory (bytes)=209895424</span><br><span class="line">		Peak Reduce Virtual memory (bytes)=2791428096</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=41</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=36</span><br></pre></td></tr></table></figure>

<ul>
<li><p>查看执行结果：</p>
<p><img src="/2021/08/25/hadoop/image-20210902132243410.png" alt="image-20210902132243410"></p>
</li>
<li><p>执行时异常的排除：在初次执行时，报异常 <code>错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster</code>，解决方法是停止集群，然后向 yarn-site.xml 配置文件中，添加一个属性值。然后，重新运行 wordcount 程序，即能正常执行。</p>
<ul>
<li><p>停止集群：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ stop-yarn.sh </span><br><span class="line">Stopping nodemanagers</span><br><span class="line">hadoop103: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">hadoop104: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">hadoop102: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">Stopping resourcemanager</span><br><span class="line">[xisun@hadoop102 ~]$ stop-dfs.sh </span><br><span class="line">Stopping namenodes on [hadoop102]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop104]</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">42220 Jps</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 yarn-site.xml，添加 <code>yarn.application.classpath</code> 属性值：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ hadoop classpath</span><br><span class="line">/opt/module/hadoop-3.2.1/etc/hadoop:/opt/module/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/common/*:/opt/module/hadoop-3.2.1/share/hadoop/hdfs:/opt/module/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.1/share/hadoop/yarn:/opt/module/hadoop-3.2.1/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/yarn/*</span><br><span class="line">[xisun@hadoop102 hadoop]$ vim yarn-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.2.1/etc/hadoop:/opt/module/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/common/*:/opt/module/hadoop-3.2.1/share/hadoop/hdfs:/opt/module/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.1/share/hadoop/yarn:/opt/module/hadoop-3.2.1/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.1/share/hadoop/yarn/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>分发 yarn-site.xml 到集群所有主机上：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ xsync /opt/module/hadoop-3.2.1/etc/hadoop/yarn-site.xml </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 66 bytes  received 12 bytes  156.00 bytes/sec</span><br><span class="line">total size is 1,621  speedup is 20.78</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 1,038 bytes  received 47 bytes  434.00 bytes/sec</span><br><span class="line">total size is 1,621  speedup is 1.49</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 1,038 bytes  received 47 bytes  2,170.00 bytes/sec</span><br><span class="line">total size is 1,621  speedup is 1.49</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动集群：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line">[xisun@hadoop102 hadoop]$ start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line">[xisun@hadoop102 hadoop]$ jps</span><br><span class="line">42544 NameNode</span><br><span class="line">43346 Jps</span><br><span class="line">42680 DataNode</span><br><span class="line">43177 NodeManager</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>与本地模式执行 wordcount 一样，HDFS 上不能已经存在 <code>/wcoutput</code> 目录，否则报错。如果已经存在，则需要删除：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs dfs -rm -r /wcoutput</span><br><span class="line">Deleted /wcoutput</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h4 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h4><ul>
<li><p>为了查看程序的历史运行情况，需要配置一下历史服务器。</p>
</li>
<li><p>第一步：编辑 mapred-site.xml，增加历史服务器的配置。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ vim /opt/module/hadoop-3.2.1/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器Web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第二步：集群分发 mapred-site.xml。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ xsync /opt/module/hadoop-3.2.1/etc/hadoop/mapred-site.xml </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 67 bytes  received 12 bytes  158.00 bytes/sec</span><br><span class="line">total size is 1,229  speedup is 15.56</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">mapred-site.xml</span><br><span class="line"></span><br><span class="line">sent 647 bytes  received 47 bytes  462.67 bytes/sec</span><br><span class="line">total size is 1,229  speedup is 1.77</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">mapred-site.xml</span><br><span class="line"></span><br><span class="line">sent 647 bytes  received 47 bytes  1,388.00 bytes/sec</span><br><span class="line">total size is 1,229  speedup is 1.77</span><br></pre></td></tr></table></figure>
</li>
<li><p>第三步：在 hadoop102 上启动历史服务器。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ mapred --daemon start historyserver</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">47605 Jps</span><br><span class="line">46106 NodeManager</span><br><span class="line">45612 DataNode</span><br><span class="line">47564 JobHistoryServer</span><br><span class="line">45485 NameNode</span><br></pre></td></tr></table></figure>
</li>
<li><p>第四步：重新运行一次 wordcount（需要先删除 HDFS 上的 <code>/wcoutput</code>），查看任务的历史日志。</p>
<p><img src="/2021/08/25/hadoop/image-20210902152328283.png" alt="image-20210902152328283"></p>
<p><img src="/2021/08/25/hadoop/image-20210902152507027.png" alt="image-20210902152507027"></p>
</li>
</ul>
<h4 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h4><ul>
<li><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。</p>
<p><img src="/2021/08/25/hadoop/image-20210902153939242.png" alt="image-20210902153939242"></p>
</li>
<li><p>如果不配置日志聚集，在 Web 端查看历史日志时，点击 logs 会无法查看（程序的运行日志，可能会分布在集群的各个机器上）。</p>
<p><img src="/2021/08/25/hadoop/image-20210902153854565.png" alt="image-20210902153854565"></p>
</li>
<li><p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
</li>
<li><p>第一步：编辑 yarn-site.xml，添加日志聚集的配置。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ vim /opt/module/hadoop-3.2.1/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能，默认不开启 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>第二步：集群分发 yarn-site.xml 文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ xsync /opt/module/hadoop-3.2.1/etc/hadoop/yarn-site.xml </span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 66 bytes  received 12 bytes  156.00 bytes/sec</span><br><span class="line">total size is 2,115  speedup is 27.12</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 836 bytes  received 53 bytes  1,778.00 bytes/sec</span><br><span class="line">total size is 2,115  speedup is 2.38</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 836 bytes  received 53 bytes  1,778.00 bytes/sec</span><br><span class="line">total size is 2,115  speedup is 2.38</span><br></pre></td></tr></table></figure>
</li>
<li><p>第三步：重新启动 NodeManager 、ResourceManager 和 HistoryServer。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ mapred --daemon stop historyserver</span><br><span class="line">[xisun@hadoop102 ~]$ stop-yarn.sh </span><br><span class="line">Stopping nodemanagers</span><br><span class="line">hadoop102: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">hadoop104: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">hadoop103: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to <span class="built_in">kill</span> with <span class="built_in">kill</span> -9</span><br><span class="line">Stopping resourcemanager</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">48872 Jps</span><br><span class="line">45612 DataNode</span><br><span class="line">45485 NameNode</span><br><span class="line">[xisun@hadoop102 ~]$ start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line">[xisun@hadoop102 ~]$ mapred --daemon start historyserver</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">49696 Jps</span><br><span class="line">49636 JobHistoryServer</span><br><span class="line">45612 DataNode</span><br><span class="line">45485 NameNode</span><br><span class="line">49134 NodeManager</span><br></pre></td></tr></table></figure>
</li>
<li><p>第四步：重新运行一次 wordcount（需要先删除 HDFS 上的 <code>/wcoutput</code>），查看任务的历史日志。</p>
<p><img src="/2021/08/25/hadoop/image-20210902165115208.png" alt="image-20210902165115208"></p>
</li>
</ul>
<h4 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h4><ul>
<li><p>各个模块分开启动/停止（配置 ssh 是前提）— 常用</p>
<ul>
<li><p>整体启动/停止 HDFS</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ start-dfs.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ stop-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>整体启动/停止 YARN</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ start-yarn.sh </span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ stop-yarn.sh </span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>各个服务组件逐一启动/停止</p>
<ul>
<li><p>分别启动/停止 HDFS 组件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs --daemon start namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hdfs --daemon stop namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动/停止 YARN</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ yarn --daemon start  resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ yarn --daemon stop  resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h4 id="编写-Hadoop-集群常用脚本"><a href="#编写-Hadoop-集群常用脚本" class="headerlink" title="编写 Hadoop 集群常用脚本"></a>编写 Hadoop 集群常用脚本</h4><ul>
<li><p>Hadoop 集群启停脚本（包含 HDFS，Yarn 和 Historyserver）：myhadoop.sh</p>
<ul>
<li><p>编写脚本：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 bin]$ <span class="built_in">pwd</span></span><br><span class="line">/home/xisun/bin</span><br><span class="line">[xisun@hadoop102 bin]$ vim myhadoop.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No Args Input...&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> ;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 启动 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; ------------------- 启动 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.2.1/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.2.1/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.2.1/bin/mapred --daemon start historyserver&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.2.1/bin/mapred --daemon stop historyserver&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.2.1/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.2.1/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>在脚本中，使用全路径，如：<code>/opt/module/hadoop-3.2.1/sbin/start-dfs.sh</code>，不要使用 <code>start-dfs.sh</code>。</p>
</blockquote>
</li>
<li><p>赋予脚本执行权限：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 bin]$ chmod 777 myhadoop.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试脚本停止集群：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ myhadoop.sh stop</span><br><span class="line"> =================== 关闭 hadoop集群 ===================</span><br><span class="line"> --------------- 关闭 historyserver ---------------</span><br><span class="line"> --------------- 关闭 yarn ---------------</span><br><span class="line">Stopping nodemanagers</span><br><span class="line">Stopping resourcemanager</span><br><span class="line"> --------------- 关闭 hdfs ---------------</span><br><span class="line">Stopping namenodes on [hadoop102]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop104]</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">51019 Jps</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试脚本启动集群：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ myhadoop.sh start</span><br><span class="line"> =================== 启动 hadoop集群 ===================</span><br><span class="line"> --------------- 启动 hdfs ---------------</span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line"> --------------- 启动 yarn ---------------</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line"> --------------- 启动 historyserver ---------------</span><br><span class="line">[xisun@hadoop102 ~]$ jps</span><br><span class="line">51666 NodeManager</span><br><span class="line">51209 NameNode</span><br><span class="line">51339 DataNode</span><br><span class="line">51917 Jps</span><br><span class="line">51839 JobHistoryServer</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>查看三台服务器 Java 进程脚本：jpsall</p>
<ul>
<li><p>编写脚本：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line">        ssh <span class="variable">$host</span> jps</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line">        ssh <span class="variable">$host</span> jps</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>赋予脚本执行权限：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 bin]$ chmod 777 jpsall</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试脚本：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ jpsall </span><br><span class="line">=============== hadoop102 ===============</span><br><span class="line">51666 NodeManager</span><br><span class="line">51209 NameNode</span><br><span class="line">51339 DataNode</span><br><span class="line">51979 Jps</span><br><span class="line">51839 JobHistoryServer</span><br><span class="line">=============== hadoop103 ===============</span><br><span class="line">40195 Jps</span><br><span class="line">39492 DataNode</span><br><span class="line">39800 NodeManager</span><br><span class="line">39677 ResourceManager</span><br><span class="line">=============== hadoop104 ===============</span><br><span class="line">40920 NodeManager</span><br><span class="line">40809 SecondaryNameNode</span><br><span class="line">41081 Jps</span><br><span class="line">40699 DataNode</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>分发 hadoop102 上的 <code>/home/xisun/bin</code> 目录，保证自定义脚本在集群的所有机器上都可以使用。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ xsync /home/xisun/bin/</span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 139 bytes  received 17 bytes  312.00 bytes/sec</span><br><span class="line">total size is 2,175  speedup is 13.94</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">bin/</span><br><span class="line">bin/jpsall</span><br><span class="line">bin/myhadoop.sh</span><br><span class="line"></span><br><span class="line">sent 1,499 bytes  received 58 bytes  3,114.00 bytes/sec</span><br><span class="line">total size is 2,175  speedup is 1.40</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">bin/</span><br><span class="line">bin/jpsall</span><br><span class="line">bin/myhadoop.sh</span><br><span class="line"></span><br><span class="line">sent 1,499 bytes  received 58 bytes  3,114.00 bytes/sec</span><br><span class="line">total size is 2,175  speedup is 1.40</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="常用端口号和配置文件说明"><a href="#常用端口号和配置文件说明" class="headerlink" title="常用端口号和配置文件说明"></a>常用端口号和配置文件说明</h4><ul>
<li><p>常用端口号</p>
<table>
<thead>
<tr>
<th>端口名称</th>
<th>Hadoop 2.x</th>
<th>Hadoop 3.x</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS NameNode 内部通信端口</td>
<td>8020 / 9000</td>
<td>8020 / 9000 / 9820</td>
</tr>
<tr>
<td>HDFS NameNode HTTP UI<br>（对用户的查询端口）</td>
<td>50070</td>
<td><strong>9870</strong></td>
</tr>
<tr>
<td>YARN MapReduce 查看执行任务端口</td>
<td>8088</td>
<td><strong>8088</strong></td>
</tr>
<tr>
<td>历史服务器通信端口</td>
<td>19888</td>
<td>19888</td>
</tr>
</tbody></table>
</li>
<li><p>常用配置文件</p>
<ul>
<li>Hadoop 2.x：core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml，slaves。</li>
<li>Hadoop 3.x：core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml，workers。</li>
</ul>
</li>
</ul>
<h4 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h4><ul>
<li>如果服务器在公网环境（能连接外网），可以不采用集群时间同步，因为服务器会定期和公网时间进行校准。</li>
<li>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。</li>
<li>配置过程略。</li>
</ul>
<h2 id="HDFS-概述"><a href="#HDFS-概述" class="headerlink" title="HDFS 概述"></a>HDFS 概述</h2><h3 id="HDFS-产生背景及定义"><a href="#HDFS-产生背景及定义" class="headerlink" title="HDFS 产生背景及定义"></a>HDFS 产生背景及定义</h3><h4 id="HDFS-产生背景"><a href="#HDFS-产生背景" class="headerlink" title="HDFS 产生背景"></a>HDFS 产生背景</h4><ul>
<li><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS 只是分布式文件管理系统中的一种。</p>
<ul>
<li><p>个人电脑上的磁盘，是 NTFS 文件管理系统。</p>
<p><img src="/2021/08/25/hadoop/image-20210903163243434.png" alt="image-20210903163243434"></p>
</li>
</ul>
</li>
</ul>
<h4 id="HDFS-定义"><a href="#HDFS-定义" class="headerlink" title="HDFS 定义"></a>HDFS 定义</h4><ul>
<li>HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</li>
<li>HDFS 的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭之后就不需要改变。</li>
</ul>
<h3 id="HDFS-优缺点"><a href="#HDFS-优缺点" class="headerlink" title="HDFS 优缺点"></a>HDFS 优缺点</h3><h4 id="HDFS-优点"><a href="#HDFS-优点" class="headerlink" title="HDFS 优点"></a>HDFS 优点</h4><ul>
<li><p>高容错性</p>
<ul>
<li><p>数据自动保存多个副本。它通过增加副本的形式，提高容错性。</p>
<p><img src="/2021/08/25/hadoop/image-20210903165715516.png" alt="image-20210903165715516"></p>
</li>
<li><p>某一个副本丢失以后，它可以自动恢复。</p>
<p><img src="/2021/08/25/hadoop/image-20210903165748149.png" alt="image-20210903165748149"></p>
</li>
</ul>
</li>
<li><p>适合处理大数据</p>
<ul>
<li>数据规模：能够处理数据规模达到 GB、TB、甚至 PB 级别的数据。</li>
<li>文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li>
</ul>
</li>
<li><p>可构建在廉价机器上，通过多副本机制，提高可靠性。</p>
</li>
</ul>
<h4 id="HDFS-缺点"><a href="#HDFS-缺点" class="headerlink" title="HDFS 缺点"></a>HDFS 缺点</h4><ul>
<li><p>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</p>
</li>
<li><p>无法高效的对大量小文件进行存储。</p>
<ul>
<li>存储大量小文件的话，它会占用 NameNode 大量的内存来存储文件目录和块信息。这样是不可取的，因为 NameNode 的内存总是有限的。</li>
<li>小文件存储的寻址时间会超过读取时间，它违反了 HDFS 的设计目标。</li>
</ul>
</li>
<li><p>不支持并发写入、文件随机修改。</p>
<ul>
<li><p>一个文件只能有一个写，不允许多个线程同时写。</p>
<p><img src="/2021/08/25/hadoop/image-20210903170115237.png" alt="image-20210903170115237"></p>
</li>
<li><p>仅支持数据 append（追加），不支持文件的随机修改。</p>
</li>
</ul>
</li>
</ul>
<h3 id="HDFS-组成架构"><a href="#HDFS-组成架构" class="headerlink" title="HDFS 组成架构"></a>HDFS 组成架构</h3><ul>
<li><p>官方文档：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/">https://hadoop.apache.org/docs/</a></p>
</li>
<li><p>hadoop-3.2.1 HDFS 文档：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a></p>
</li>
<li><p>HDFS 组成架构：</p>
<p><img src="/2021/08/25/hadoop/image-20210903170728742.png" alt="image-20210903170728742"></p>
<ul>
<li>NameNode：nn，就是 Master，它是一个主管、管理者。<ul>
<li>管理 HDFS 的名称空间；</li>
<li>配置副本策略；</li>
<li>管理数据块（Block）映射信息；</li>
<li>处理客户端读写请求。</li>
</ul>
</li>
<li>DataNode：就是 Slave。NameNode下达命令，DataNode 执行实际的操作。<ul>
<li>存储实际的数据块；</li>
<li>执行数据块的读/写操作。</li>
</ul>
</li>
</ul>
</li>
<li><p>Client：就是客户端。比如，Web 打开的 Browse Directory 页面就是一个客户端，能够对 HDFS 进行操作。</p>
<ul>
<li>文件切分。文件上传到 HDFS 的时候，Client 将文件切分成一个一个的 Block，然后进行上传；</li>
<li>与 NameNode 交互，获取文件的位置信息；</li>
<li>与 DataNode 交互，读取或者写入数据；</li>
<li>Client 提供一些命令来管理 HDFS，比如 NameNode 格式化；</li>
<li>Client 可以通过一些命令来访问 HDFS，比如对 HDFS 增删查改操作。</li>
</ul>
</li>
<li><p>Secondary NameNode：2nn，并非 NameNode 的热备。当 NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务。</p>
<ul>
<li>辅助 NameNode，分担其工作量，比如定期合并 Fsimage 和 Edits，并推送给 NameNode；</li>
<li>在紧急情况下，可辅助恢复 NameNode（只能恢复一部分数据，无法恢复全部数据）。</li>
</ul>
</li>
</ul>
<h3 id="HDFS-文件块大小"><a href="#HDFS-文件块大小" class="headerlink" title="HDFS 文件块大小"></a>HDFS 文件块大小</h3><ul>
<li>HDFS 中的文件在物理上是分块存储（Block），块的大小可以通过配置参数 <code>dfs.blocksize</code> 来规定，默认大小在 Hadoop 2.x/3.x 版本中是 128 MB，Hadoop 1.x 版本中是 64 MB。<ul>
<li>如果寻址时间约为 10 ms，即查找到集群中的目标 Block 的时间为 10 ms。当寻址时间为传输时间的 1% 时（专家研究），则为最佳状态。因此，传输时间 = 10 ms / 0.01 = 1000 ms = 1 s。而目前磁盘的传输速率普遍为 100 MB/s，因此，Block 大小 = 1 s * 100 MB/s = 100 MB。在计算机系统中，取 1024 的整数倍，即取 Block 大小为 128 MB。如果是固态硬盘，传输速率可以达到 200 ~ 300 MB/s，此时，一般取 Block 大小为 256 MB。</li>
</ul>
</li>
<li>HDFS 的 Block 块的大小设置主要取决于磁盘传输速率。<ul>
<li>如果 HDFS 的 Block 块设置的太小，会增加寻址时间，程序一直在找块的开始位置。</li>
<li>如果 HDFS 的 Block 块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间，导致程序在处理这块数据时，会非常慢。</li>
</ul>
</li>
</ul>
<h2 id="HDFS-的-Shell-操作"><a href="#HDFS-的-Shell-操作" class="headerlink" title="HDFS 的 Shell 操作"></a>HDFS 的 Shell 操作</h2><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><ul>
<li>方式一：<code>hadoop fs 具体命令</code></li>
<li>方式二：<code>hdfs dfs 具体命令</code></li>
</ul>
<h3 id="命令大全"><a href="#命令大全" class="headerlink" title="命令大全"></a>命令大全</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs</span><br><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-checksum &lt;src&gt; ...]</span><br><span class="line">	[-chgrp [-R] GROUP PATH...]</span><br><span class="line">	[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">	[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-count [-q] [-h] [-v] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-x] [-e] &lt;path&gt; ...]</span><br><span class="line">	[-cp [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">	[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">	[-du [-s] [-h] [-v] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-expunge [-immediate]]</span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]</span><br><span class="line">	[-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-head &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">help</span> [cmd ...]]</span><br><span class="line">	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]]</span><br><span class="line">	[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">	[-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]</span><br><span class="line">	[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">	[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">	[-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;]</span><br><span class="line">	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">stat</span> [format] &lt;path&gt; ...]</span><br><span class="line">	[-tail [-f] [-s &lt;sleep interval&gt;] &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">test</span> -[defswrz] &lt;path&gt;]</span><br><span class="line">	[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] &lt;path&gt; ...]</span><br><span class="line">	[-touchz &lt;path&gt; ...]</span><br><span class="line">	[-truncate [-w] &lt;length&gt; &lt;path&gt; ...]</span><br><span class="line">	[-usage [cmd ...]]</span><br><span class="line"></span><br><span class="line">Generic options supported are:</span><br><span class="line">-conf &lt;configuration file&gt;        specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;               define a value <span class="keyword">for</span> a given property</span><br><span class="line">-fs &lt;file:///|hdfs://namenode:port&gt; specify default filesystem URL to use, overrides <span class="string">&#x27;fs.defaultFS&#x27;</span> property from configurations.</span><br><span class="line">-jt &lt;<span class="built_in">local</span>|resourcemanager:port&gt;  specify a ResourceManager</span><br><span class="line">-files &lt;file1,...&gt;                specify a comma-separated list of files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;jar1,...&gt;               specify a comma-separated list of jar files to be included <span class="keyword">in</span> the classpath</span><br><span class="line">-archives &lt;archive1,...&gt;          specify a comma-separated list of archives to be unarchived on the compute machines</span><br><span class="line"></span><br><span class="line">The general <span class="built_in">command</span> line syntax is:</span><br><span class="line"><span class="built_in">command</span> [genericOptions] [commandOptions]</span><br></pre></td></tr></table></figure>

<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="查看帮助"><a href="#查看帮助" class="headerlink" title="查看帮助"></a>查看帮助</h4><ul>
<li><p>-help：查看命令的使用说明</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -<span class="built_in">help</span> rm</span><br><span class="line">-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ... :</span><br><span class="line">  Delete all files that match the specified file pattern. Equivalent to the Unix</span><br><span class="line">  <span class="built_in">command</span> <span class="string">&quot;rm &lt;src&gt;&quot;</span></span><br><span class="line">                                                                                 </span><br><span class="line">  -f          If the file does not exist, <span class="keyword">do</span> not display a diagnostic message or </span><br><span class="line">              modify the <span class="built_in">exit</span> status to reflect an error.                        </span><br><span class="line">  -[rR]       Recursively deletes directories.                                   </span><br><span class="line">  -skipTrash  option bypasses trash, <span class="keyword">if</span> enabled, and immediately deletes &lt;src&gt;.  </span><br><span class="line">  -safely     option requires safety confirmation, <span class="keyword">if</span> enabled, requires          </span><br><span class="line">              confirmation before deleting large directory with more than        </span><br><span class="line">              &lt;hadoop.shell.delete.limit.num.files&gt; files. Delay is expected when</span><br><span class="line">              walking over large directory recursively to count the number of    </span><br><span class="line">              files to be deleted before the confirmation. </span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="直接操作-HDFS"><a href="#直接操作-HDFS" class="headerlink" title="直接操作 HDFS"></a>直接操作 HDFS</h4><ul>
<li><p>-ls：显示目录信息。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /</span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup  359196911 2021-09-02 10:45 /hadoop-3.2.1.tar.gz</span><br><span class="line">drwx------   - xisun supergroup          0 2021-09-02 16:35 /tmp</span><br><span class="line">drwxr-xr-x   - xisun supergroup          0 2021-09-02 10:14 /wcinput</span><br><span class="line">drwxr-xr-x   - xisun supergroup          0 2021-09-02 16:36 /wcoutput</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /wcinput</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup         41 2021-09-02 10:14 /wcinput/word.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>-cat：显示文件内容。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -cat /wcinput/word.txt</span><br><span class="line">2021-09-06 14:07:12,091 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xisun</span><br><span class="line">xisun</span><br></pre></td></tr></table></figure>
</li>
<li><p>-mkdir：创建路径。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -mkdir /sanguo</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /</span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup  359196911 2021-09-02 10:45 /hadoop-3.2.1.tar.gz</span><br><span class="line">drwxr-xr-x   - xisun supergroup          0 2021-09-06 13:35 /sanguo</span><br><span class="line">drwx------   - xisun supergroup          0 2021-09-02 16:35 /tmp</span><br><span class="line">drwxr-xr-x   - xisun supergroup          0 2021-09-02 10:14 /wcinput</span><br><span class="line">drwxr-xr-x   - xisun supergroup          0 2021-09-02 16:36 /wcoutput</span><br></pre></td></tr></table></figure>
</li>
<li><p>-cp：从 HDFS 的一个路径拷贝到 HDFS 的另一个路径。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -cp /wcinput/word.txt /sanguo</span><br><span class="line">2021-09-06 16:16:26,225 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">2021-09-06 16:16:27,148 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup         41 2021-09-06 16:16 /sanguo/word.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>-mv：在 HDFS 目录中移动文件或重命名文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -mv /sanguo/word.txt /sanguo/sanguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup         41 2021-09-06 16:16 /sanguo/sanguo.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>-tail：显示一个文件的末尾 1 kb 的数据。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -tail /sanguo/sanguo.txt</span><br><span class="line">2021-09-06 16:19:45,518 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xisun</span><br><span class="line">xisun</span><br></pre></td></tr></table></figure>
</li>
<li><p>-rm：删除文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -rm /sanguo/sanguo.txt</span><br><span class="line">Deleted /sanguo/sanguo.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>-rm -r：递归删除目录及目录里面内容。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -rm /sanguo</span><br><span class="line">rm: `/sanguo<span class="string">&#x27;: Is a directory</span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ hadoop fs -rm -r /sanguo</span></span><br><span class="line"><span class="string">Deleted /sanguo</span></span><br><span class="line"><span class="string">[xisun@hadoop102 ~]$ hadoop fs -ls /</span></span><br><span class="line"><span class="string">Found 4 items</span></span><br><span class="line"><span class="string">-rw-r--r--   3 xisun supergroup  359196911 2021-09-02 10:45 /hadoop-3.2.1.tar.gz</span></span><br><span class="line"><span class="string">drwx------   - xisun supergroup          0 2021-09-02 16:35 /tmp</span></span><br><span class="line"><span class="string">drwxr-xr-x   - xisun supergroup          0 2021-09-02 10:14 /wcinput</span></span><br><span class="line"><span class="string">drwxr-xr-x   - xisun supergroup          0 2021-09-02 16:36 /wcoutput</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>-du：统计文件夹的大小信息。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -du -s -h /wcinput</span><br><span class="line">41  123  /wcinput</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -du -h /wcinput</span><br><span class="line">41  123  /wcinput/word.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>41 表示文件大小；123 表示 41 * 3 个副本；/wcinput 表示查看的目录。</li>
</ul>
</li>
<li><p>-chgrp、-chmod、-chown：与 Linux 文件系统中的用法一样，修改文件所属权限。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /wcinput</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup         41 2021-09-02 10:14 /wcinput/word.txt</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -chmod 666 /wcinput/word.txt</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /wcinput</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-rw-rw-   3 xisun supergroup         41 2021-09-02 10:14 /wcinput/word.txt</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -chown xisun:xisun /wcinput/word.txt</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /wcinput</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-rw-rw-   3 xisun xisun         41 2021-09-02 10:14 /wcinput/word.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>-setrep：设置 HDFS 中文件的副本数量。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -setrep 10 /wcinput/word.txt</span><br><span class="line">Replication 10 <span class="built_in">set</span>: /wcinput/word.txt</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/25/hadoop/image-20210906163539785.png" alt="image-20210906163539785"></p>
<p><img src="/2021/08/25/hadoop/image-20210906163702812.png" alt="image-20210906163702812"></p>
<ul>
<li>这里设置的副本数只是记录在 NameNode 的元数据中，是否真的会有这么多副本，取决于 DataNode 的数量。因为目前只有 3 台设备，最多也就 3 个副本，只有节点数的增加到 10 台时，副本数才能达到 10。</li>
</ul>
</li>
</ul>
<h4 id="上传到-HDFS"><a href="#上传到-HDFS" class="headerlink" title="上传到 HDFS"></a>上传到 HDFS</h4><ul>
<li><p>-moveFromLocal：从本地文件系统剪切文件粘贴到 HDFS 路径。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ vim shuguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  7 9月   6 16:39 shuguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -mkdir /sanguo</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -moveFromLocal ./shuguo.txt /sanguo</span><br><span class="line">2021-09-06 16:40:09,950 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup          7 2021-09-06 16:40 /sanguo/shuguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>-copyFromLocal：从本地文件系统中拷贝文件到 HDFS 路径。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ vim weiguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  7 9月   6 16:43 weiguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -copyFromLocal weiguo.txt /sanguo</span><br><span class="line">2021-09-06 16:43:50,298 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup          7 2021-09-06 16:40 /sanguo/shuguo.txt</span><br><span class="line">-rw-r--r--   3 xisun supergroup          7 2021-09-06 16:43 /sanguo/weiguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  7 9月   6 16:43 weiguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>-put：等同于 -copyFromLocal，生产环境更习惯用 -put。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ vim wuguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 8</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  7 9月   6 16:43 weiguo.txt</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  6 9月   6 16:45 wuguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -put wuguo.txt /sanguo</span><br><span class="line">2021-09-06 16:46:14,881 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 3 items</span><br><span class="line">-rw-r--r--   3 xisun supergroup          7 2021-09-06 16:40 /sanguo/shuguo.txt</span><br><span class="line">-rw-r--r--   3 xisun supergroup          7 2021-09-06 16:43 /sanguo/weiguo.txt</span><br><span class="line">-rw-r--r--   3 xisun supergroup          6 2021-09-06 16:46 /sanguo/wuguo.txt</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 8</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  7 9月   6 16:43 weiguo.txt</span><br><span class="line">-rw-rw-r--. 1 xisun xisun  6 9月   6 16:45 wuguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>-appendToFile：追加一个文件到已经存在的文件末尾。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -cat /sanguo/shuguo.txt</span><br><span class="line">2021-09-06 16:47:33,926 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">shuguo</span><br><span class="line">[xisun@hadoop102 ~]$ vim liubei.txt</span><br><span class="line">[xisun@hadoop102 ~]$ cat liubei.txt </span><br><span class="line">liubei</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt</span><br><span class="line">2021-09-06 16:48:18,942 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 hadoop fs -cat /sanguo/shuguo.txt</span><br><span class="line">2021-09-06 16:48:32,423 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">shuguo</span><br><span class="line">liubei</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="下载至-HDFS"><a href="#下载至-HDFS" class="headerlink" title="下载至 HDFS"></a>下载至 HDFS</h4><ul>
<li><p>-copyToLocal：从 HDFS 路径拷贝文件到本地文件系统。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ rm liubei.txt weiguo.txt wuguo.txt </span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br><span class="line">[xisun@hadoop102 ~]$ hadoop fs -copyToLocal /sanguo/shuguo.txt ./</span><br><span class="line">2021-09-06 16:49:58,344 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-r--r--. 1 xisun xisun 14 9月   6 16:49 shuguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>-get：等同于 -copyToLocal，生产环境更习惯用 -get。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ hadoop fs -get /sanguo/weiguo.txt ./</span><br><span class="line">2021-09-06 16:50:23,583 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 8</span><br><span class="line">drwxrwxr-x. 2 xisun xisun 52 9月   2 23:15 bin</span><br><span class="line">-rw-r--r--. 1 xisun xisun 14 9月   6 16:49 shuguo.txt</span><br><span class="line">-rw-r--r--. 1 xisun xisun  7 9月   6 16:50 weiguo.txt</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun  6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="HDFS-的-API-操作"><a href="#HDFS-的-API-操作" class="headerlink" title="HDFS 的 API 操作"></a>HDFS 的 API 操作</h2><h3 id="客户端环境准备"><a href="#客户端环境准备" class="headerlink" title="客户端环境准备"></a>客户端环境准备</h3><ul>
<li><p>Windows 系统开发 Hadoop 时，如果是远程连接 Linux 上的 Hadoop 集群，则不需要再下载安装 Windows 版本的 Hadoop。但是，需要在本地配置相关的 Hadoop 变量，主要包括 hadoop.dll 与 winutils.exe 等。</p>
<ul>
<li><p>由于 Hadoop 主要基于 Linux 编写，winutil.exe 主要用于模拟 Linux 下的目录环境。当 Hadoop 在 Windows 下运行或调用远程 Hadoop 集群的时候，需要该辅助程序才能运行。winutils.exe 是 Windows 中的二进制文件，适用于不同版本的 Hadoop 系统并构建在 Windows VM 上，该 VM 用以在 Windows 系统中测试 Hadoop/YARN 相关的应用程序。参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/HeyShHeyou/article/details/103441110%E3%80%82">https://blog.csdn.net/HeyShHeyou/article/details/103441110。</a></p>
</li>
<li><p>相关异常信息：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https:<span class="comment">//wiki.apache.org/hadoop/WindowsProblems</span></span><br><span class="line">        at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:<span class="number">528</span>) ~[hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:<span class="number">549</span>) ~[hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:<span class="number">572</span>) ~[hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.util.Shell.&lt;clinit&gt;(Shell.java:<span class="number">669</span>) ~[hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.util.StringUtils.&lt;clinit&gt;(StringUtils.java:<span class="number">79</span>) [hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:<span class="number">1555</span>) [hadoop-common-<span class="number">2.8</span>.<span class="number">4.</span>jar:na]</span><br><span class="line">        at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:<span class="number">66</span>) [hbase-common-<span class="number">2.0</span>.<span class="number">0.</span>jar:<span class="number">2.0</span>.<span class="number">0</span>]</span><br><span class="line">        at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:<span class="number">80</span>) [hbase-common-<span class="number">2.0</span>.<span class="number">0.</span>jar:<span class="number">2.0</span>.<span class="number">0</span>]</span><br><span class="line">        at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:<span class="number">94</span>) [hbase-common-<span class="number">2.0</span>.<span class="number">0.</span>jar:<span class="number">2.0</span>.<span class="number">0</span>]</span><br><span class="line">        at org.apache.phoenix.query.ConfigurationFactory$ConfigurationFactoryImpl$<span class="number">1.</span>call(ConfigurationFactory.java:<span class="number">49</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.query.ConfigurationFactory$ConfigurationFactoryImpl$<span class="number">1.</span>call(ConfigurationFactory.java:<span class="number">46</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.util.PhoenixContextExecutor.call(PhoenixContextExecutor.java:<span class="number">76</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.util.PhoenixContextExecutor.callWithoutPropagation(PhoenixContextExecutor.java:<span class="number">91</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.query.ConfigurationFactory$ConfigurationFactoryImpl.getConfiguration(ConfigurationFactory.java:<span class="number">46</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.jdbc.PhoenixDriver.initializeConnectionCache(PhoenixDriver.java:<span class="number">151</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br><span class="line">        at org.apache.phoenix.jdbc.PhoenixDriver.&lt;init&gt;(PhoenixDriver.java:<span class="number">143</span>) [phoenix-core-<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>.jar:<span class="number">5.0</span>.<span class="number">0</span>-HBase-<span class="number">2.0</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>根据 Linux 上 Hadoop 版本，下载对应的 winutils.exe 版本：<a target="_blank" rel="noopener" href="https://github.com/cdarlint/winutils%EF%BC%8Chttps://github.com/steveloughran/winutils%E3%80%82">https://github.com/cdarlint/winutils，https://github.com/steveloughran/winutils。</a></p>
<p><img src="/2021/08/25/hadoop/image-20210906233413928.png" alt="image-20210906233413928"></p>
</li>
<li><p>配置 HADOOP_HOME 环境变量：</p>
<p><img src="/2021/08/25/hadoop/image-20210906232417504.png" alt="image-20210906232417504"></p>
</li>
<li><p>配置 Path 环境变量：</p>
<p><img src="/2021/08/25/hadoop/image-20210906232525065.png" alt="image-20210906232525065"></p>
</li>
<li><p>验证 Hadoop 环境变量是否正常。双击 winutils.exe，如果一闪而过，说明正常；如果报如下错误，说明缺少微软运行库（正版系统往往有这个问题）。</p>
<p><img src="/2021/08/25/hadoop/image-20210906232834423.png" alt="image-20210906232834423"></p>
<p><img src="/2021/08/25/hadoop/image-20210906233140290.png" alt="image-20210906233140290"></p>
</li>
<li><p>Hadoop 环境变量配置好后，可能需要重启 IDEA 或者重启电脑。</p>
</li>
</ul>
<h3 id="项目创建"><a href="#项目创建" class="headerlink" title="项目创建"></a>项目创建</h3><ul>
<li><p>添加依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.xisun.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>xisun-hadoop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">maven.compiler.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>3.2.1<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 日志相关 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-classic<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- Hadoop客户端 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;maven.compiler.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>$&#123;maven.compiler.source&#125;<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>$&#123;maven.compiler.target&#125;<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>日志配置：</p>
<ul>
<li><p>log4j.properties:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">log4j.rootLogger</span>=<span class="string">INFO, stdout</span></span><br><span class="line"><span class="meta">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="meta">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br><span class="line"><span class="meta">log4j.appender.logfile</span>=<span class="string">org.apache.log4j.FileAppender</span></span><br><span class="line"><span class="meta">log4j.appender.logfile.File</span>=<span class="string">target/spring.log</span></span><br><span class="line"><span class="meta">log4j.appender.logfile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.logfile.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>logback.xml：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span></span></span><br><span class="line"><span class="tag">        <span class="attr">debug</span>=<span class="string">&quot;false&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns</span>=<span class="string">&quot;http://ch.qos.logback/xml/ns/logback&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://ch.qos.logback/xml/ns/logback</span></span></span><br><span class="line"><span class="tag"><span class="string">        https://raw.githubusercontent.com/enricopulatzo/logback-XSD/master/src/main/xsd/logback.xsd&quot;</span></span></span><br><span class="line"><span class="tag">&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 定义日志文件的存储地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;logging.path&quot;</span> <span class="attr">value</span>=<span class="string">&quot;./&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;logging.level&quot;</span> <span class="attr">value</span>=<span class="string">&quot;DEBUG&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;message.format&quot;</span></span></span><br><span class="line"><span class="tag">              <span class="attr">value</span>=<span class="string">&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n%ex&#123;full, DISPLAY_EX_EVAL&#125;&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 控制台输出日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;STDOUT&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.ConsoleAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 自定义滚动日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;RollingAppender&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">append</span>&gt;</span>true<span class="tag">&lt;/<span class="name">append</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>$&#123;logging.level&#125;<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">FileNamePattern</span>&gt;</span>$&#123;logging.path&#125;/reaction-extractor-%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">FileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">MaxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">MaxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;message.format&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 异步输出日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;ASYNC&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.classic.AsyncAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discardingThreshold</span>&gt;</span>0<span class="tag">&lt;/<span class="name">discardingThreshold</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">queueSize</span>&gt;</span>100<span class="tag">&lt;/<span class="name">queueSize</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;RollingAppender&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">&quot;$&#123;logging.level&#125;&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;ASYNC&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>项目结构：</p>
<p><img src="/2021/08/25/hadoop/image-20210907150906533.png" alt="image-20210907150906533"></p>
</li>
</ul>
<h3 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h3><h4 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> XiSun</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2021/9/6 22:46</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsClient</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> FileSystem fileSystem;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            init();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (URISyntaxException | IOException | InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取文件系统</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> URISyntaxException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// 集群nn的连接地址</span></span><br><span class="line">        URI uri = <span class="keyword">new</span> URI(<span class="string">&quot;hdfs://hadoop102:8020&quot;</span>);</span><br><span class="line">        <span class="comment">// 创建一个配置文件，按需求自定义配置条件</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">// 用户</span></span><br><span class="line">        String user = <span class="string">&quot;xisun&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取客户端对象</span></span><br><span class="line">        fileSystem = FileSystem.get(uri, configuration, user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭资源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (fileSystem != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                fileSystem.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">                exception.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mkdirs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">&quot;/xiyou/huaguoshan/&quot;</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">            exception.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        mkdirs();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>客户端去操作 HDFS 时，是有一个用户身份的。默认情况下，HDFS 客户端 API 会从采用 Windows 默认用户访问 HDFS，这通常会报权限异常错误。因此，在创建文件系统对象时，一定要配置用户。</li>
</ul>
</li>
<li><p>控制台输出：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">02</span>.<span class="number">744</span> [main] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation <span class="meta">@org</span>.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=<span class="keyword">false</span>, valueName=Time, about=, interval=<span class="number">10</span>, type=DEFAULT, value=[<span class="function">Rate of successful kerberos logins and <span class="title">latency</span> <span class="params">(milliseconds)</span>])</span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.750 [main] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.<span class="title">Metric</span><span class="params">(sampleName=Ops, always=<span class="keyword">false</span>, valueName=Time, about=, interval=<span class="number">10</span>, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)</span>])</span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.750 [main] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.<span class="title">Metric</span><span class="params">(sampleName=Ops, always=<span class="keyword">false</span>, valueName=Time, about=, interval=<span class="number">10</span>, type=DEFAULT, value=[GetGroups])</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.751 [main] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field <span class="keyword">private</span> org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.<span class="title">Metric</span><span class="params">(sampleName=Ops, always=<span class="keyword">false</span>, valueName=Time, about=, interval=<span class="number">10</span>, type=DEFAULT, value=[Renewal failures since startup])</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.751 [main] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field <span class="keyword">private</span> org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.<span class="title">Metric</span><span class="params">(sampleName=Ops, always=<span class="keyword">false</span>, valueName=Time, about=, interval=<span class="number">10</span>, type=DEFAULT, value=[Renewal failures since last successful login])</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.752 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics</span></span><br><span class="line"><span class="function">2021-09-07 15:35:02.761 [main] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:<span class="title">xisun</span> <span class="params">(auth:SIMPLE)</span> from:org.apache.hadoop.fs.FileSystem.<span class="title">get</span><span class="params">(FileSystem.java:<span class="number">214</span>)</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.049 [main] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems</span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.065 [main] DEBUG org.apache.hadoop.fs.FileSystem - file:<span class="comment">// = class org.apache.hadoop.fs.LocalFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.073 [main] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:<span class="comment">// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.076 [main] DEBUG org.apache.hadoop.fs.FileSystem - har:<span class="comment">// = class org.apache.hadoop.fs.HarFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.077 [main] DEBUG org.apache.hadoop.fs.FileSystem - http:<span class="comment">// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.078 [main] DEBUG org.apache.hadoop.fs.FileSystem - https:<span class="comment">// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.090 [main] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:<span class="comment">// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.102 [main] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:<span class="comment">// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.104 [main] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:<span class="comment">// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/java/maven-repo/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar</span></span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.104 [main] DEBUG org.apache.hadoop.fs.FileSystem - Looking <span class="keyword">for</span> FS supporting hdfs</span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.104 [main] DEBUG org.apache.hadoop.fs.FileSystem - looking <span class="keyword">for</span> configuration option fs.hdfs.impl</span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.120 [main] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems <span class="keyword">for</span> implementation class</span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.121 [main] DEBUG org.apache.hadoop.fs.FileSystem - FS <span class="keyword">for</span> hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem</span></span><br><span class="line"><span class="function">2021-09-07 15:35:03.204 [main] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local </span>= <span class="keyword">false</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">205</span> [main] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = <span class="keyword">false</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">205</span> [main] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = <span class="keyword">false</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">205</span> [main] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = </span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">219</span> [main] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">240</span> [main] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to <span class="keyword">true</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">254</span> [main] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = <span class="keyword">null</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">291</span> [main] DEBUG org.apache.hadoop.security.Groups -  Creating <span class="keyword">new</span> Groups object</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">293</span> [main] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built <span class="keyword">native</span>-hadoop library...</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">297</span> [main] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the <span class="keyword">native</span>-hadoop library</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">298</span> [main] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping <span class="keyword">for</span> Group resolution</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">298</span> [main] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">335</span> [main] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=<span class="number">300000</span>; warningDeltaMs=<span class="number">5000</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">347</span> [main] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">hadoop</span>.<span class="title">ipc</span>.<span class="title">ProtobufRpcEngine</span>$<span class="title">RpcProtobufRequest</span>, <span class="title">rpcInvoker</span></span>=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@<span class="number">3</span>ce1e309</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">03</span>.<span class="number">672</span> [main] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@<span class="number">52</span>bf72b5</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">085</span> [main] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both <span class="keyword">short</span>-circuit local reads and UNIX domain socket are disabled.</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">092</span> [main] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration <span class="keyword">for</span> dfs.data.transfer.protection</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">112</span> [main] DEBUG org.apache.hadoop.hdfs.DFSClient - /xiyou/huaguoshan: masked=&#123; masked: rwxr-xr-x, unmasked: rwxrwxrwx &#125;</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">151</span> [main] DEBUG org.apache.hadoop.ipc.Client - The ping interval is <span class="number">60000</span> ms.</span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">153</span> [main] DEBUG org.apache.hadoop.ipc.Client - Connecting to hadoop102/<span class="number">192.168</span>.<span class="number">10.102</span>:<span class="number">8020</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">227</span> [<span class="function">IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun] DEBUG org.apache.hadoop.ipc.Client - IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun: starting, having connections 1</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.230 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.244 [IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun] DEBUG org.apache.hadoop.ipc.Client - IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun got value #0</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.245 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 118ms</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [main] DEBUG org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@52bf72b5</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [main] DEBUG org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@52bf72b5</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [main] DEBUG org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@52bf72b5</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [main] DEBUG org.apache.hadoop.ipc.Client - Stopping client</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun] DEBUG org.apache.hadoop.ipc.Client - IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun: closed</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.248 [IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun] DEBUG org.apache.hadoop.ipc.Client - IPC <span class="title">Client</span> <span class="params">(<span class="number">956420404</span>)</span> connection to hadoop102/192.168.10.102:8020 from xisun: stopped, remaining connections 0</span></span><br><span class="line"><span class="function">2021-09-07 15:35:04.354 [Thread-4] DEBUG org.apache.hadoop.util.ShutdownHookManager - Completed shutdown in 0.001 seconds</span>; Timeouts: <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">04</span>.<span class="number">363</span> [Thread-<span class="number">4</span>] DEBUG org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger completed shutdown.</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建结果：</p>
<p><img src="/2021/08/25/hadoop/image-20210907153615806.png" alt="image-20210907153615806"></p>
</li>
</ul>
<h4 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 上传文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyFromLocalFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 参数一：Windows原文件是否删除；参数二：若HDFS目的地文件已存在，是否允许覆盖；参数三：Windows原文件路径；参数四：HDFS目的地路径</span></span><br><span class="line">        fileSystem.copyFromLocalFile(<span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">new</span> Path(<span class="string">&quot;E:\\sunwukong.txt&quot;</span>),</span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">&quot;hdfs://hadoop102/xiyou/huaguoshan&quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>控制台输出：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">15</span>:<span class="number">46</span>:<span class="number">03</span>.<span class="number">654</span> [Thread-<span class="number">6</span>] INFO  o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = <span class="keyword">false</span>, remoteHostTrusted = <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>上传结果：</p>
<p><img src="/2021/08/25/hadoop/image-20210907154935556.png" alt="image-20210907154935556"></p>
<ul>
<li><p>可以看出，上传文件，默认备份数是 3，参数的优先级顺序：hdfs-default.xml &lt; hdfs-site.xml &lt; 在项目资源目录下的配置文件 &lt; 代码里面的配置。</p>
<img src="/2021/08/25/hadoop/image-20210907155850375.png" alt="image-20210907155850375" style="zoom:80%;">

<ul>
<li><p>项目资源目录下的配置文件：</p>
<p><img src="/2021/08/25/hadoop/image-20210907155455332.png" alt="image-20210907155455332"></p>
</li>
<li><p>代码里面的配置：</p>
<p><img src="/2021/08/25/hadoop/image-20210907155532293.png" alt="image-20210907155532293"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="文件下载"><a href="#文件下载" class="headerlink" title="文件下载"></a>文件下载</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 下载文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyToLocalFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 参数一：HDFS原文件是否删除；参数二：HDFS原文件路径；参数三：Windows目标地址路径；参数四：是否开启本地文件校验，false表示开启</span></span><br><span class="line">        fileSystem.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">&quot;hdfs://hadoop102/wcinput/word.txt&quot;</span>),</span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">&quot;E:\\11\\&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>也可以直接下载 HDFS 上的文件路径。</p>
</blockquote>
</li>
<li><p>控制台输出：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">09</span>-<span class="number">07</span> <span class="number">16</span>:<span class="number">06</span>:<span class="number">31.318</span> [main] INFO  o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = <span class="keyword">false</span>, remoteHostTrusted = <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>下载结果：</p>
<p><img src="/2021/08/25/hadoop/image-20210907161117479.png" alt="image-20210907161117479"></p>
</li>
</ul>
<h4 id="文件删除"><a href="#文件删除" class="headerlink" title="文件删除"></a>文件删除</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">rm</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 参数1：HDFS要删除的路径；参数2：是否递归删除</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 删除文件</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">&quot;/hadoop-3.2.1.tar.gz&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除空目录</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">&quot;/honglou&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除非空目录</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">&quot;/xiyou&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="文件的更名和移动"><a href="#文件的更名和移动" class="headerlink" title="文件的更名和移动"></a>文件的更名和移动</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 文件的更名和移动</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mv</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 参数1：HDFS原文件路径；参数2：HDFS目标文件路径</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对文件名称的修改</span></span><br><span class="line">        <span class="comment">// fileSystem.rename(new Path(&quot;/wcinput/word.txt&quot;), new Path(&quot;/wcinput/words.txt&quot;));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 文件的移动和更名</span></span><br><span class="line">        <span class="comment">// fileSystem.rename(new Path(&quot;/wcinput/words.txt&quot;), new Path(&quot;/wordout.txt&quot;));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 目录更名</span></span><br><span class="line">        fileSystem.rename(<span class="keyword">new</span> Path(<span class="string">&quot;/honglou&quot;</span>), <span class="keyword">new</span> Path(<span class="string">&quot;/hongloumeng&quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="文件详情查看"><a href="#文件详情查看" class="headerlink" title="文件详情查看"></a>文件详情查看</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取文件详细信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">listFiles</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 获取所有文件信息，第二个参数表示是否递归</span></span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fileSystem.listFiles(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 遍历文件</span></span><br><span class="line">        <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">            LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;==========&quot;</span> + fileStatus.getPath() + <span class="string">&quot;=========&quot;</span>);</span><br><span class="line">            System.out.println(fileStatus.getPermission());</span><br><span class="line">            System.out.println(fileStatus.getOwner());</span><br><span class="line">            System.out.println(fileStatus.getGroup());</span><br><span class="line">            System.out.println(fileStatus.getLen());</span><br><span class="line">            System.out.println(fileStatus.getModificationTime());</span><br><span class="line">            System.out.println(fileStatus.getReplication());</span><br><span class="line">            System.out.println(fileStatus.getBlockSize());</span><br><span class="line">            System.out.println(fileStatus.getPath().getName());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 获取块信息</span></span><br><span class="line">            BlockLocation[] blockLocations = fileStatus.getBlockLocations();</span><br><span class="line">            System.out.println(Arrays.toString(blockLocations));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>控制台输出：</p>
<p><img src="/2021/08/25/hadoop/image-20210907171215574.png" alt="image-20210907171215574"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">==========hdfs:<span class="comment">//hadoop102:8020/sanguoyanyi/shuguo.txt=========</span></span><br><span class="line">rw-r--r--</span><br><span class="line">xisun</span><br><span class="line">supergroup</span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="number">1630918100557</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">134217728</span></span><br><span class="line">shuguo.txt</span><br><span class="line">[<span class="number">0</span>,<span class="number">14</span>,hadoop102,hadoop103,hadoop104]</span><br><span class="line">==========hdfs:<span class="comment">//hadoop102:8020/sanguoyanyi/weiguo.txt=========</span></span><br><span class="line">rw-r--r--</span><br><span class="line">xisun</span><br><span class="line">supergroup</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">1630917830657</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">134217728</span></span><br><span class="line">weiguo.txt</span><br><span class="line">[<span class="number">0</span>,<span class="number">7</span>,hadoop102,hadoop103,hadoop104]</span><br><span class="line">==========hdfs:<span class="comment">//hadoop102:8020/sanguoyanyi/wuguo.txt=========</span></span><br><span class="line">rw-r--r--</span><br><span class="line">xisun</span><br><span class="line">supergroup</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">1630917975305</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">134217728</span></span><br><span class="line">wuguo.txt</span><br><span class="line">[<span class="number">0</span>,<span class="number">6</span>,hadoop102,hadoop103,hadoop104]</span><br><span class="line">    </span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="文件和文件夹类型判断"><a href="#文件和文件夹类型判断" class="headerlink" title="文件和文件夹类型判断"></a>文件和文件夹类型判断</h4><ul>
<li><p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 判断是文件夹还是文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fileType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        FileStatus[] listStatus = fileSystem.listStatus(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (FileStatus status : listStatus) &#123;</span><br><span class="line">            <span class="keyword">if</span> (status.isFile()) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;文件：&quot;</span> + status.getPath().getName());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;目录：&quot;</span> + status.getPath().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException exception) &#123;</span><br><span class="line">        exception.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>控制台输出：</p>
<p><img src="/2021/08/25/hadoop/image-20210907171344066.png" alt="image-20210907171344066"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">目录：sanguoyanyi</span><br><span class="line">目录：tmp</span><br><span class="line">目录：wcinput</span><br><span class="line">目录：wcoutput</span><br><span class="line">文件：wordout.txt</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="HDFS-的读写流程"><a href="#HDFS-的读写流程" class="headerlink" title="HDFS 的读写流程"></a>HDFS 的读写流程</h2><h3 id="HDFS-写数据流程"><a href="#HDFS-写数据流程" class="headerlink" title="HDFS 写数据流程"></a>HDFS 写数据流程</h3><p><img src="/2021/08/25/hadoop/image-20210908104338787.png" alt="image-20210908104338787"></p>
<ol>
<li>客户端通过 Distributed FileSystem 模块向 NameNode 请求上传文件，NameNode 检查目标文件是否已存在，父目录是否存在。</li>
<li>NameNode 返回是否可以上传。</li>
<li>客户端请求第一个 Block 上传到哪几个 DataNode 服务器上。</li>
<li>NameNode 返回 3 个 DataNode 节点，分别为 dn1、dn2、dn3。</li>
<li>客户端通过 FSDataOutputStream 模块请求向 dn1 上传数据，dn1 收到请求会继续调用 dn2，然后 dn2 调用 dn3，将这个通信管道建立完成。</li>
<li>dn1、dn2、dn3 逐级应答客户端。</li>
<li>客户端开始往 dn1 上传第一个 Block（先从磁盘读取数据放到一个本地内存缓存），以 Packet 为单位，dn1 收到一个 Packet 就会传给 dn2，dn2 再传给 dn3；dn1 每传一个 Packet 会放入一个应答队列等待应答。</li>
<li>当一个 Block 传输完成之后，客户端再次请求 NameNode 上传第二个 Block 的服务器。（重复执行 3 - 7 步）</li>
</ol>
<h4 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑 - 节点距离计算"></a>网络拓扑 - 节点距离计算</h4><ul>
<li><p>在 HDFS 写数据的过程中，NameNode 会选择距离待上传数据最近距离的 DataNode 接收数据。</p>
</li>
<li><p>节点距离：两个节点到达最近的共同祖先的距离总和。</p>
</li>
<li><p>假设有集群 d1 机架 r1 中的节点 n1，则该节点可以表示为 /d1/r1/n1。利用这种标记，这里给出四种距离描述，如下图所示：</p>
<p><img src="/2021/08/25/hadoop/image-20210908104610376.png" alt="image-20210908104610376"></p>
<ul>
<li>节点到其自身的距离为 0，到其所属机架的距离为 1，到其所属集群的距离为 2，到其所属机房的距离为 3。</li>
<li>Distance(/d1/r1/n0, /d1/r1/n0) = 0：同一节点上的进程。/d1/r1/n0 与 /d1/r1/n0 的共同祖先是 n0，因此，距离为 0 + 0 = 0。</li>
<li>Distance(/d1/r1/n1, /d1/r1/n2) = 2：同一机架上的不同节点。/d1/r1/n1 与 /d1/r1/n2 的共同祖先是机架 r1，因此，距离为 1 + 1 = 2。</li>
<li>Distance(/d1/r2/n0, /d1/r3/n2) = 4：同一数据中心不同机架上的节点。/d1/r2/n0 与 /d1/r3/n2 的共同祖先是集群 d1，因此，距离为 2 + 2 = 4。</li>
<li>Distance(/d1/r2/n1, /d2/r4/n1) = 6：不同数据中心的节点。/d1/r2/n1 与 /d2/r4/n1 的共同祖先是机房，因此，距离为 3 + 3 = 6。</li>
</ul>
</li>
<li><p>再比如下图互联网上的一个计算机群，5 号机和 9 号机的节点距离为 3，2 号机和 10 号机的节点距离也为 3。</p>
<p><img src="/2021/08/25/hadoop/image-20210908091317080.png" alt="image-20210908091317080"></p>
</li>
</ul>
<h4 id="机架感知-副本存储节点选择"><a href="#机架感知-副本存储节点选择" class="headerlink" title="机架感知 - 副本存储节点选择"></a>机架感知 - 副本存储节点选择</h4><ul>
<li><p>机架感知说明</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on the local machine if the writer is on a datanode, otherwise on a random datanode in the same rack as that of the writer, another replica on a node in a different (remote) rack, and the last on a different node in the same remote rack. This policy cuts the inter-rack write traffic which generally improves write performance. The chance of rack failure is far less than that of node failure; this policy does not impact data reliability and availability guarantees. However, it does reduce the aggregate network bandwidth used when reading data since a block is placed in only two unique racks rather than three. With this policy, the replicas of a file do not evenly distribute across the racks. One third of replicas are on one node, two thirds of replicas are on one rack, and the other third are evenly distributed across the remaining racks. This policy improves write performance without compromising data reliability or read performance.</span><br></pre></td></tr></table></figure>
</li>
<li><p>副本存储节点选择</p>
<p><img src="/2021/08/25/hadoop/image-20210908102248682.png" alt="image-20210908102248682"></p>
<ul>
<li>第一个副本，在 Client 所处的节点上，节点距离最近，上传速度最快。如果客户端在集群外，则随机选一个。比如：/d1/r1/n0。</li>
<li>第二个副本，在另一个机架的随机一个节点，以保证数据的可靠性。比如：/d1/r2/n0。</li>
<li>第三个副本，在第二个副本所在机架的随机节点，考虑的是传输效率。比如：/d1/r2/n1。</li>
</ul>
</li>
</ul>
<h3 id="HDFS-读数据流程"><a href="#HDFS-读数据流程" class="headerlink" title="HDFS 读数据流程"></a>HDFS 读数据流程</h3><p><img src="/2021/08/25/hadoop/image-20210908105937977.png" alt="image-20210908105937977"></p>
<ol>
<li>客户端通过 DistributedFileSystem 向 NameNode 请求下载文件，NameNode 通过检查权限和查询元数据，找到文件块所在的 DataNode 地址。</li>
<li>挑选一台 DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode 开始传输数据给客户端（从磁盘里面读取数据输入流，以 Packet 为单位来做校验）。</li>
<li>客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件。</li>
</ol>
<h2 id="NameNode-和-SecondaryNameNode"><a href="#NameNode-和-SecondaryNameNode" class="headerlink" title="NameNode 和 SecondaryNameNode"></a>NameNode 和 SecondaryNameNode</h2><h3 id="NN-和-2NN-工作机制"><a href="#NN-和-2NN-工作机制" class="headerlink" title="NN 和 2NN 工作机制"></a>NN 和 2NN 工作机制</h3><p><img src="/2021/08/25/hadoop/image-20210908114133555.png" alt="image-20210908114133555"></p>
<ul>
<li>NameNode 中的元数据如何存储的？<ul>
<li>首先，我们做个假设，如果存储在 NameNode 节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此，需要一个在磁盘中备份元数据的 FsImage。</li>
<li>其次，这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新 FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦 NameNode 节点断电，就会产生数据丢失。因此，引入 Edits 文件（此文件只进行追加操作，即只记录每一个请求的过程，不计算结果，效率很高）。每当元数据有更新或者添加元数据时，修改内存中的元数据并将请求操作追加到 Edits 中。这样，一旦 NameNode 节点断电，可以通过 FsImage 和 Edits 的合并，合成元数据。</li>
<li>但是，如果长时间添加数据到 Edits 中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行 FsImage 和 Edits 的合并，如果这个操作由 NameNode 节点完成，又会效率过低。因此，引入一个新的节点 SecondaryNamenode，专门用于 FsImage 和 Edits 的合并。</li>
</ul>
</li>
<li>第一阶段：NameNode 启动。<ol>
<li>第一次启动 NameNode 格式化后，创建 Fsimage（镜像文件）和 Edits（编辑日志）文件。如果不是第一次启动，直接加载 Fsimage 和 Edits 到内存。</li>
<li>客户端发送对元数据进行增删改的请求。</li>
<li>NameNode 记录操作日志，更新滚动日志。</li>
<li>NameNode 在内存中对元数据进行增删改。</li>
</ol>
</li>
<li>第二阶段：Secondary NameNode 工作。<ol>
<li>Secondary NameNode 询问 NameNode 是否需要 CheckPoint，并直接带回 NameNode 是否检查的结果。</li>
<li>Secondary NameNode 请求执行 CheckPoint。</li>
<li>NameNode 滚动正在写的 Edits 日志。</li>
<li>NameNode 将滚动前的镜像文件和编辑日志拷贝到 Secondary NameNode。</li>
<li>Secondary NameNode 加载镜像文件和编辑日志到内存，并合并。</li>
<li>Secondary NameNode 生成新的镜像文件 fsimage.chkpoint。</li>
<li>Secondary NameNode 拷贝 fsimage.chkpoint 到 NameNode。</li>
<li>NameNode 将 fsimage.chkpoint 重新命名成 fsimage。</li>
</ol>
</li>
</ul>
<h3 id="Fsimage-和-Edits-解析"><a href="#Fsimage-和-Edits-解析" class="headerlink" title="Fsimage 和 Edits 解析"></a>Fsimage 和 Edits 解析</h3><h4 id="Fsimage-和-Edits-的概念"><a href="#Fsimage-和-Edits-的概念" class="headerlink" title="Fsimage 和 Edits 的概念"></a>Fsimage 和 Edits 的概念</h4><ul>
<li><p>NameNode 被格式化之后，将在 <code>/opt/module/hadoop-3.1.3/data/tmp/dfs/name/current</code> 路径中产生如下文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 current]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/name/current</span><br><span class="line">[xisun@hadoop102 current]$ ll</span><br><span class="line">总用量 701</span><br><span class="line">-rw-rw-r--. 1 xisun xisun     418 9月   8 13:43 fsimage_0000000000000000000</span><br><span class="line">-rw-rw-r--. 1 xisun xisun      62 9月   8 13:43 fsimage_0000000000000000000.md5</span><br><span class="line">-rw-rw-r--. 1 xisun xisun       4 9月   8 13:43 seen_txid</span><br><span class="line">-rw-rw-r--. 1 xisun xisun     217 9月   7 11:44 VERSION</span><br></pre></td></tr></table></figure>
</li>
<li><p>Fsimage 文件：HDFS 文件系统元数据的一个永久性的检查点，其中包含 HDFS 文件系统的所有目录和文件 inode 的序列化信息。</p>
</li>
<li><p>Edits 文件：存放 HDFS 文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到 Edits 文件中。</p>
</li>
<li><p>seen_txid 文件：保存的是一个数字，就是最后一个 edits_ 的数字。</p>
<p><img src="/2021/08/25/hadoop/image-20210908162349654.png" alt="image-20210908162349654"></p>
</li>
<li><p>每次 NameNode 启动的时候都会将 Fsimage 文件读入内存，加载 Edits 里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成当 NameNode 启动的时候就将 Fsimage 和 Edits 文件进行了合并。</p>
</li>
</ul>
<h4 id="oiv-查看-Fsimage-文件"><a href="#oiv-查看-Fsimage-文件" class="headerlink" title="oiv 查看 Fsimage 文件"></a>oiv 查看 Fsimage 文件</h4><ul>
<li><p>查看 oiv 和 oev 命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 current]$ hdfs</span><br><span class="line">Usage: hdfs [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]</span><br><span class="line">...</span><br><span class="line">oev                  apply the offline edits viewer to an edits file</span><br><span class="line">oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>基本语法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p 文件类型 -i 镜像文件名称 -o 转换后文件的输出路径</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-o 参数需要制定转换后文件的具体名称，不能只是一个目录。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000931 -o ~</span><br><span class="line">Encountered exception.  Exiting: /home/xisun (是一个目录)</span><br><span class="line">java.io.FileNotFoundException: /home/xisun (是一个目录)</span><br><span class="line">	at java.io.FileOutputStream.open0(Native Method)</span><br><span class="line">	at java.io.FileOutputStream.open(FileOutputStream.java:270)</span><br><span class="line">	at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:213)</span><br><span class="line">	at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:101)</span><br><span class="line">	at java.io.PrintStream.&lt;init&gt;(PrintStream.java:248)</span><br><span class="line">	at org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.run(OfflineImageViewerPB.java:178)</span><br><span class="line">	at org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.main(OfflineImageViewerPB.java:137)</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 current]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.2.1/data/dfs/name/current</span><br><span class="line">[xisun@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000931 -o ~/fsimage.XML</span><br><span class="line">2021-09-08 16:35:27,445 INFO offlineImageViewer.FSImageHandler: Loading 6 strings</span><br><span class="line">2021-09-08 16:35:29,097 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911</span><br><span class="line">2021-09-08 16:35:29,097 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215</span><br><span class="line">2021-09-08 16:35:29,097 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215</span><br><span class="line">2021-09-08 16:35:29,097 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215</span><br><span class="line">[xisun@hadoop102 current]$ <span class="built_in">cd</span> ~</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 28</span><br><span class="line">drwxrwxr-x. 2 xisun xisun    52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 19241 9月   8 16:35 fsimage.XML</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载文件并查看</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ sz fsimage.XML</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fsimage</span>&gt;</span><span class="tag">&lt;<span class="name">version</span>&gt;</span><span class="tag">&lt;<span class="name">layoutVersion</span>&gt;</span>-65<span class="tag">&lt;/<span class="name">layoutVersion</span>&gt;</span><span class="tag">&lt;<span class="name">onDiskVersion</span>&gt;</span>1<span class="tag">&lt;/<span class="name">onDiskVersion</span>&gt;</span><span class="tag">&lt;<span class="name">oivRevision</span>&gt;</span>b3cbbb467e22ea829b3808f4b7b01d07e0bf3842<span class="tag">&lt;/<span class="name">oivRevision</span>&gt;</span><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">NameSection</span>&gt;</span><span class="tag">&lt;<span class="name">namespaceId</span>&gt;</span>817173371<span class="tag">&lt;/<span class="name">namespaceId</span>&gt;</span><span class="tag">&lt;<span class="name">genstampV1</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">genstampV1</span>&gt;</span><span class="tag">&lt;<span class="name">genstampV2</span>&gt;</span>1068<span class="tag">&lt;/<span class="name">genstampV2</span>&gt;</span><span class="tag">&lt;<span class="name">genstampV1Limit</span>&gt;</span>0<span class="tag">&lt;/<span class="name">genstampV1Limit</span>&gt;</span><span class="tag">&lt;<span class="name">lastAllocatedBlockId</span>&gt;</span>1073741891<span class="tag">&lt;/<span class="name">lastAllocatedBlockId</span>&gt;</span><span class="tag">&lt;<span class="name">txid</span>&gt;</span>931<span class="tag">&lt;/<span class="name">txid</span>&gt;</span><span class="tag">&lt;/<span class="name">NameSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ErasureCodingSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">policyId</span>&gt;</span>1<span class="tag">&lt;/<span class="name">policyId</span>&gt;</span><span class="tag">&lt;<span class="name">policyName</span>&gt;</span>RS-6-3-1024k<span class="tag">&lt;/<span class="name">policyName</span>&gt;</span><span class="tag">&lt;<span class="name">cellSize</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">cellSize</span>&gt;</span><span class="tag">&lt;<span class="name">policyState</span>&gt;</span>DISABLED<span class="tag">&lt;/<span class="name">policyState</span>&gt;</span><span class="tag">&lt;<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">codecName</span>&gt;</span>rs<span class="tag">&lt;/<span class="name">codecName</span>&gt;</span><span class="tag">&lt;<span class="name">dataUnits</span>&gt;</span>6<span class="tag">&lt;/<span class="name">dataUnits</span>&gt;</span><span class="tag">&lt;<span class="name">parityUnits</span>&gt;</span>3<span class="tag">&lt;/<span class="name">parityUnits</span>&gt;</span><span class="tag">&lt;/<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">policyId</span>&gt;</span>2<span class="tag">&lt;/<span class="name">policyId</span>&gt;</span><span class="tag">&lt;<span class="name">policyName</span>&gt;</span>RS-3-2-1024k<span class="tag">&lt;/<span class="name">policyName</span>&gt;</span><span class="tag">&lt;<span class="name">cellSize</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">cellSize</span>&gt;</span><span class="tag">&lt;<span class="name">policyState</span>&gt;</span>DISABLED<span class="tag">&lt;/<span class="name">policyState</span>&gt;</span><span class="tag">&lt;<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">codecName</span>&gt;</span>rs<span class="tag">&lt;/<span class="name">codecName</span>&gt;</span><span class="tag">&lt;<span class="name">dataUnits</span>&gt;</span>3<span class="tag">&lt;/<span class="name">dataUnits</span>&gt;</span><span class="tag">&lt;<span class="name">parityUnits</span>&gt;</span>2<span class="tag">&lt;/<span class="name">parityUnits</span>&gt;</span><span class="tag">&lt;/<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">policyId</span>&gt;</span>3<span class="tag">&lt;/<span class="name">policyId</span>&gt;</span><span class="tag">&lt;<span class="name">policyName</span>&gt;</span>RS-LEGACY-6-3-1024k<span class="tag">&lt;/<span class="name">policyName</span>&gt;</span><span class="tag">&lt;<span class="name">cellSize</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">cellSize</span>&gt;</span><span class="tag">&lt;<span class="name">policyState</span>&gt;</span>DISABLED<span class="tag">&lt;/<span class="name">policyState</span>&gt;</span><span class="tag">&lt;<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">codecName</span>&gt;</span>rs-legacy<span class="tag">&lt;/<span class="name">codecName</span>&gt;</span><span class="tag">&lt;<span class="name">dataUnits</span>&gt;</span>6<span class="tag">&lt;/<span class="name">dataUnits</span>&gt;</span><span class="tag">&lt;<span class="name">parityUnits</span>&gt;</span>3<span class="tag">&lt;/<span class="name">parityUnits</span>&gt;</span><span class="tag">&lt;/<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">policyId</span>&gt;</span>4<span class="tag">&lt;/<span class="name">policyId</span>&gt;</span><span class="tag">&lt;<span class="name">policyName</span>&gt;</span>XOR-2-1-1024k<span class="tag">&lt;/<span class="name">policyName</span>&gt;</span><span class="tag">&lt;<span class="name">cellSize</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">cellSize</span>&gt;</span><span class="tag">&lt;<span class="name">policyState</span>&gt;</span>DISABLED<span class="tag">&lt;/<span class="name">policyState</span>&gt;</span><span class="tag">&lt;<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">codecName</span>&gt;</span>xor<span class="tag">&lt;/<span class="name">codecName</span>&gt;</span><span class="tag">&lt;<span class="name">dataUnits</span>&gt;</span>2<span class="tag">&lt;/<span class="name">dataUnits</span>&gt;</span><span class="tag">&lt;<span class="name">parityUnits</span>&gt;</span>1<span class="tag">&lt;/<span class="name">parityUnits</span>&gt;</span><span class="tag">&lt;/<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">policyId</span>&gt;</span>5<span class="tag">&lt;/<span class="name">policyId</span>&gt;</span><span class="tag">&lt;<span class="name">policyName</span>&gt;</span>RS-10-4-1024k<span class="tag">&lt;/<span class="name">policyName</span>&gt;</span><span class="tag">&lt;<span class="name">cellSize</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">cellSize</span>&gt;</span><span class="tag">&lt;<span class="name">policyState</span>&gt;</span>DISABLED<span class="tag">&lt;/<span class="name">policyState</span>&gt;</span><span class="tag">&lt;<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">codecName</span>&gt;</span>rs<span class="tag">&lt;/<span class="name">codecName</span>&gt;</span><span class="tag">&lt;<span class="name">dataUnits</span>&gt;</span>10<span class="tag">&lt;/<span class="name">dataUnits</span>&gt;</span><span class="tag">&lt;<span class="name">parityUnits</span>&gt;</span>4<span class="tag">&lt;/<span class="name">parityUnits</span>&gt;</span><span class="tag">&lt;/<span class="name">ecSchema</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">erasureCodingPolicy</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">ErasureCodingSection</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">INodeSection</span>&gt;</span><span class="tag">&lt;<span class="name">lastInodeId</span>&gt;</span>16535<span class="tag">&lt;/<span class="name">lastInodeId</span>&gt;</span><span class="tag">&lt;<span class="name">numInodes</span>&gt;</span>48<span class="tag">&lt;/<span class="name">numInodes</span>&gt;</span><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span><span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1631005240758<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>9223372036854775807<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16386<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>wcinput<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1631005111883<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16387<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>wordout.txt<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>10<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630548862351<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1631005650890<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:0666<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741825<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1001<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>41<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16389<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>tmp<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571709992<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16390<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop-yarn<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553418947<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16391<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>staging<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630554923848<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16392<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>xisun<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553418948<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16393<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>.staging<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571777142<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16394<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0001<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553421706<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">xattrs</span>&gt;</span><span class="tag">&lt;<span class="name">xattr</span>&gt;</span><span class="tag">&lt;<span class="name">ns</span>&gt;</span>SYSTEM<span class="tag">&lt;/<span class="name">ns</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>hdfs.erasurecoding.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">val</span>&gt;</span>\0000;\0000;\0000;\000b;replication<span class="tag">&lt;/<span class="name">val</span>&gt;</span><span class="tag">&lt;/<span class="name">xattr</span>&gt;</span><span class="tag">&lt;/<span class="name">xattrs</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16395<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.jar<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>10<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553421192<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553420729<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741829<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1005<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>316534<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16396<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.split<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>10<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553421574<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553421453<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741830<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1006<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>110<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16397<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.splitmetainfo<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553421698<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553421586<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741831<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1007<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>43<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16398<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553422297<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553421706<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741832<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1008<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>192215<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16399<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0002<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553679452<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0700<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">xattrs</span>&gt;</span><span class="tag">&lt;<span class="name">xattr</span>&gt;</span><span class="tag">&lt;<span class="name">ns</span>&gt;</span>SYSTEM<span class="tag">&lt;/<span class="name">ns</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>hdfs.erasurecoding.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">val</span>&gt;</span>\0000;\0000;\0000;\000b;replication<span class="tag">&lt;/<span class="name">val</span>&gt;</span><span class="tag">&lt;/<span class="name">xattr</span>&gt;</span><span class="tag">&lt;/<span class="name">xattrs</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16400<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.jar<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>10<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553679124<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553678890<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741833<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1009<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>316534<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16401<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.split<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>10<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553679334<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553679221<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741834<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1010<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>110<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16402<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.splitmetainfo<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553679443<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553679339<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741835<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1011<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>43<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16403<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630553679670<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630553679452<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741836<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1012<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>192215<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16409<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>history<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567073024<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16410<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>done_intermediate<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630554923873<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:1777<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16411<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>xisun<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571854446<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16418<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0003-1630554915644-xisun-word+count-1630554943250-0-0-FAILED-default-1630554928660.jhist<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630554943458<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630554943411<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741844<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1020<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>14969<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16419<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0003_conf.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630554943540<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630554943476<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741845<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1021<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>222769<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16437<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0004-1630559739775-xisun-word+count-1630559924980-1-1-SUCCEEDED-default-1630559746457.jhist<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630559927155<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630559927104<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741854<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1030<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>22803<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16438<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0004_conf.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630559927279<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630559927177<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741855<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1031<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>223439<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16456<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0005-1630562908651-xisun-word+count-1630563047214-1-1-SUCCEEDED-default-1630562921426.jhist<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630563046601<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630563046543<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741864<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1040<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>22770<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16457<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0005_conf.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630563046693<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630563046621<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741865<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1041<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>223439<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16458<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>done<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567231439<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16476<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0006-1630567142285-xisun-word+count-1630567220324-1-1-SUCCEEDED-default-1630567156915.jhist<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567219772<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630567219669<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741874<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1050<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>22792<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16477<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0006_conf.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567219913<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630567219802<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741875<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1051<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>223437<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16478<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>2021<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567231440<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16479<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>09<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567231440<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16480<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>02<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630567231441<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16481<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571854446<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16487<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>logs<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571710042<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:1777<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16488<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>xisun<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571710049<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16489<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>logs-tfile<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571710069<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16490<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>application_1630509320297_0007<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571783775<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16492<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>wcoutput<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571775649<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16498<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>part-r-00000<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571775482<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630571775197<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741882<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1058<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>36<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16500<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>_SUCCESS<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571775653<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630571775649<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16503<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0007-1630571709613-xisun-word+count-1630571776516-1-1-SUCCEEDED-default-1630571719711.jhist<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571775936<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630656192752<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741884<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1060<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>22765<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16504<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>job_1630509320297_0007_conf.xml<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571776037<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630571775955<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0770<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741885<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1061<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>223615<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16505<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop103_43362<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630571783767<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630571783609<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:xisun:0640<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741886<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1062<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>136973<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16508<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>sanguoyanyi<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630917975333<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span><span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16509<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>shuguo.txt<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630918100557<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630917608900<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741888<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1067<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>14<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16510<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>weiguo.txt<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630917830657<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630917830222<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741889<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1065<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>7<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>16511<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>wuguo.txt<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span><span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1630917975305<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span><span class="tag">&lt;<span class="name">atime</span>&gt;</span>1630917974782<span class="tag">&lt;/<span class="name">atime</span>&gt;</span><span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span><span class="tag">&lt;<span class="name">permission</span>&gt;</span>xisun:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span><span class="tag">&lt;<span class="name">blocks</span>&gt;</span><span class="tag">&lt;<span class="name">block</span>&gt;</span><span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741890<span class="tag">&lt;/<span class="name">id</span>&gt;</span><span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1066<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span><span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>6<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span><span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">INodeSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">INodeReferenceSection</span>&gt;</span><span class="tag">&lt;/<span class="name">INodeReferenceSection</span>&gt;</span><span class="tag">&lt;<span class="name">SnapshotSection</span>&gt;</span><span class="tag">&lt;<span class="name">snapshotCounter</span>&gt;</span>0<span class="tag">&lt;/<span class="name">snapshotCounter</span>&gt;</span><span class="tag">&lt;<span class="name">numSnapshots</span>&gt;</span>0<span class="tag">&lt;/<span class="name">numSnapshots</span>&gt;</span><span class="tag">&lt;/<span class="name">SnapshotSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">INodeDirectorySection</span>&gt;</span><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16508<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16389<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16386<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16492<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16387<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16389<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16390<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16487<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16390<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16391<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16391<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16409<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16392<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16392<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16393<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16393<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16394<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16399<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16394<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16395<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16396<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16397<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16398<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16399<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16400<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16401<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16402<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16403<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16409<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16458<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16410<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16410<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16411<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16458<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16478<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16478<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16479<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16479<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16480<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16480<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16481<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16481<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16418<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16419<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16437<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16438<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16456<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16457<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16476<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16477<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16503<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16504<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16487<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16488<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16488<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16489<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16489<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16490<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16490<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16505<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16492<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16500<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16498<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">directory</span>&gt;</span><span class="tag">&lt;<span class="name">parent</span>&gt;</span>16508<span class="tag">&lt;/<span class="name">parent</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16509<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16510<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;<span class="name">child</span>&gt;</span>16511<span class="tag">&lt;/<span class="name">child</span>&gt;</span><span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">INodeDirectorySection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">FileUnderConstructionSection</span>&gt;</span><span class="tag">&lt;/<span class="name">FileUnderConstructionSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">SecretManagerSection</span>&gt;</span><span class="tag">&lt;<span class="name">currentId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">currentId</span>&gt;</span><span class="tag">&lt;<span class="name">tokenSequenceNumber</span>&gt;</span>0<span class="tag">&lt;/<span class="name">tokenSequenceNumber</span>&gt;</span><span class="tag">&lt;<span class="name">numDelegationKeys</span>&gt;</span>0<span class="tag">&lt;/<span class="name">numDelegationKeys</span>&gt;</span><span class="tag">&lt;<span class="name">numTokens</span>&gt;</span>0<span class="tag">&lt;/<span class="name">numTokens</span>&gt;</span><span class="tag">&lt;/<span class="name">SecretManagerSection</span>&gt;</span><span class="tag">&lt;<span class="name">CacheManagerSection</span>&gt;</span><span class="tag">&lt;<span class="name">nextDirectiveId</span>&gt;</span>1<span class="tag">&lt;/<span class="name">nextDirectiveId</span>&gt;</span><span class="tag">&lt;<span class="name">numDirectives</span>&gt;</span>0<span class="tag">&lt;/<span class="name">numDirectives</span>&gt;</span><span class="tag">&lt;<span class="name">numPools</span>&gt;</span>0<span class="tag">&lt;/<span class="name">numPools</span>&gt;</span><span class="tag">&lt;/<span class="name">CacheManagerSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fsimage</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Fsimage 文件中保存了 HDFS 上存储的文件的信息，包括父节点和子节点的关系。</li>
<li>Fsimage 文件中没有记录 Block 块所对应的 DataNode 信息，这是因为，在集群启动后，会要求 DataNode 上报数据块信息，并间隔一段时间后再次上报。</li>
</ul>
</li>
</ul>
<h4 id="oev-查看-Edits-文件"><a href="#oev-查看-Edits-文件" class="headerlink" title="oev 查看 Edits 文件"></a>oev 查看 Edits 文件</h4><ul>
<li><p>基本语法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev -p 文件类型 -i 编辑日志名称 -o 转换后文件的输出路径</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">cd</span> /opt/module/hadoop-3.2.1/data/dfs/name/current</span><br><span class="line">[xisun@hadoop102 current]$ hdfs oev -p XML -i edits_inprogress_0000000000000000936 -o ~/edits.XML</span><br><span class="line">[xisun@hadoop102 current]$ <span class="built_in">cd</span> ~</span><br><span class="line">[xisun@hadoop102 ~]$ ll</span><br><span class="line">总用量 24</span><br><span class="line">drwxrwxr-x. 2 xisun xisun    52 9月   2 23:15 bin</span><br><span class="line">-rw-rw-r--. 1 xisun xisun   221 9月   8 16:46 edits.XML</span><br><span class="line">-rw-rw-r--. 1 xisun xisun 19241 9月   8 16:35 fsimage.XML</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 公共</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 模板</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 视频</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 图片</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 文档</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 下载</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 音乐</span><br><span class="line">drwxr-xr-x. 2 xisun xisun     6 8月  28 23:56 桌面</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载文件并查看</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 current]$ sz ~/edits.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-65<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>936<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_DELETE<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>937<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguoyanyi<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TIMESTAMP</span>&gt;</span>1631092478280<span class="tag">&lt;/<span class="name">TIMESTAMP</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span>db87d83d-dba1-4362-add1-ff9cbdbceea0<span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>3<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>NameNode 如何确定下次开机启动的时候合并哪些 Edits：假设当前 fsimage 最大编号为 935，则会将所有编号大于 935 的 Edits 合并。</li>
</ul>
</li>
</ul>
<h3 id="CheckPoint-时间设置"><a href="#CheckPoint-时间设置" class="headerlink" title="CheckPoint 时间设置"></a>CheckPoint 时间设置</h3><ul>
<li><p>CheckPoint 是指 SecondaryNameNode 向 nn 执行的操作。</p>
</li>
<li><p>通常情况下，SecondaryNameNode 每隔一小时执行一次。间隔时间在 hdfs-default.xml 文件中进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    The number of seconds between two periodic checkpoints.</span><br><span class="line">    Support multiple time unit suffix(case insensitive), as described</span><br><span class="line">    in dfs.heartbeat.interval.</span><br><span class="line">   <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>另外，SecondaryNameNode 每隔一分钟检查一次 NameNode 的操作次数，当操作次数达到 1 百万时，SecondaryNameNode 执行一次 CheckPoint。间隔时间和操作次数在 hdfs-default.xml 文件中进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The Secondary NameNode or CheckpointNode will create a checkpoint</span><br><span class="line">  of the namespace every &#x27;dfs.namenode.checkpoint.txns&#x27; transactions, regardless</span><br><span class="line">  of whether &#x27;dfs.namenode.checkpoint.period&#x27; has expired.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The SecondaryNameNode and CheckpointNode will poll the NameNode</span><br><span class="line">  every &#x27;dfs.namenode.checkpoint.check.period&#x27; seconds to query the number</span><br><span class="line">  of uncheckpointed transactions. Support multiple time unit suffix(case insensitive),</span><br><span class="line">  as described in dfs.heartbeat.interval.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h2><h3 id="DataNode-工作机制"><a href="#DataNode-工作机制" class="headerlink" title="DataNode 工作机制"></a>DataNode 工作机制</h3><p><img src="/2021/08/25/hadoop/image-20210908232731057.png" alt="image-20210908232731057"></p>
<ul>
<li><p>一个数据块在 DataNode 上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据，包括数据块的长度，块数据的校验和，以及时间戳。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 ~]$ <span class="built_in">cd</span> /opt/module/hadoop-3.2.1/data/dfs/data/current/BP-288566776-192.168.10.102-1630507194979/current/finalized/subdir0/subdir0</span><br><span class="line">[xisun@hadoop102 subdir0]$ ll</span><br><span class="line">总用量 52</span><br><span class="line">-rw-rw-r--. 1 xisun xisun     41 9月   2 10:14 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 xisun xisun     11 9月   2 10:14 blk_1073741825_1001.meta</span><br></pre></td></tr></table></figure>

<blockquote>
<p>.meta 文件存储的是元数据，另一个文件存储的是数据本身。</p>
</blockquote>
</li>
<li><p>DataNode 启动后向 NameNode 注册，通过后，再周期性（6 小时）的向 NameNode 上报所有的块信息。</p>
<ul>
<li><p>DataNode 扫描自己节点块信息列表的时间，默认 6 小时。在 hdfs-default.xml 文件中配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.directoryscan.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>21600s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Interval in seconds for Datanode to scan data directories and</span><br><span class="line">  reconcile the difference between blocks in memory and on the disk.</span><br><span class="line">  Support multiple time unit suffix(case insensitive), as described</span><br><span class="line">  in dfs.heartbeat.interval.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>DataNode 向 NameNode 汇报当前节点块信息的时间间隔，默认 6 小时。在 hdfs-default.xml 文件中配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blockreport.intervalMsec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>21600000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Determines block reporting interval in milliseconds.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>可以看出，DataNode 每隔 6 小时自查一次，自查完成后，立即向 NameNode 上报一次当前节点的信息。如果服务器中存在某些服务器性能差，可以设置自查和上报的时间间隔短一点。</p>
</li>
</ul>
</li>
<li><p>心跳是每 3 秒一次，心跳返回结果带有 NameNode 给该 DataNode 的命令，比如复制块数据到另一台机器，或删除某个数据块。如果超过 10 分钟没有收到某个 DataNode 的心跳，则认为该节点不可用，NameNode 也就不会再和该 DataNode 有数据交互。</p>
</li>
<li><p>集群运行中可以安全加入和退出一些机器。</p>
</li>
</ul>
<h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><ul>
<li><p>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理，如果 DataNode 节点上的数据损坏了，却没有发现，也很危险，那么如何解决呢？</p>
</li>
<li><p>如下是 DataNode 节点保证数据完整性的方法：</p>
<ol>
<li><p>当 DataNode 读取 Block 的时候，它会计算 CheckSum。</p>
</li>
<li><p>如果计算后的 CheckSum，与 Block 创建时的值不一样，说明 Block 已经损坏。</p>
</li>
<li><p>然后，Client 读取其他 DataNode 上的 Block。</p>
</li>
<li><p>DataNode 会在其文件创建后周期验证 CheckSum。</p>
</li>
<li><p>常见的校验算法有： crc（32），md5（128），sha1（160）。</p>
<p><img src="/2021/08/25/hadoop/image-20210909092530067.png" alt="image-20210909092530067"></p>
<ul>
<li>奇偶校验位方法，是检验算法中极其简单的一种。原始数据封装时，查看待传输数据中 1 的个数，如果为偶数，则在数据后添加一个校验位，值为 0，如果为奇数，则校验位值为 1。当接收到数据后，对数据进行重新计算，查看数据中 1 的个数，验证其是否与传输前的校验位相同。如果在数据传输过程中，导致数据发生了错误，接收到的数据校验位与原始数据的不同，则认为数据损坏，不再使用。</li>
<li>奇偶校验法，并不能保证一定检验出数据传输过程中可能出现的错误。crc 校验算法会更复杂，也更可靠，但原理上是相同的。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h3><ul>
<li><p>如果 DataNode 进程死亡或者网络故障，造成 DataNode 无法与 NameNode 通信；</p>
</li>
<li><p>此时，NameNode 不会立即把该 DataNode 节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。</p>
</li>
<li><p>HDFS 默认的超时时长为 10 分钟 + 30 秒。（实际上，这就是 DataNode 工作机制中，DataNode 向 NameNode 发送心跳的超时时间）</p>
</li>
<li><p>如果定义超时时间为 TimeOut，则超时时长的计算公式为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TimeOut = 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 hdfs-default.xml 文件中，<code>dfs.namenode.heartbeat.recheck-interval</code> 默认为 300000 毫秒（5 分钟），<code>dfs.heartbeat.interval</code> 默认为 3 秒。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>300000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    This time decides the interval to check for expired datanodes.</span><br><span class="line">    With this value and dfs.heartbeat.interval, the interval of</span><br><span class="line">    deciding the datanode is stale or not is also calculated.</span><br><span class="line">    The unit of this configuration is millisecond.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Determines datanode heartbeat interval in seconds.</span><br><span class="line">    Can use the following suffix (case insensitive):</span><br><span class="line">    ms(millis), s(sec), m(min), h(hour), d(day)</span><br><span class="line">    to specify the time (such as 2s, 2m, 1h, etc.).</span><br><span class="line">    Or provide complete number in seconds (such as 30 for 30 seconds).</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="YARN-资源调度器"><a href="#YARN-资源调度器" class="headerlink" title="YARN 资源调度器"></a>YARN 资源调度器</h2><ul>
<li>YARN 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而 MapReduce 等运算程序则相当于运行于操作系统之上的应用程序。</li>
</ul>
<h3 id="YARN-基础架构"><a href="#YARN-基础架构" class="headerlink" title="YARN 基础架构"></a>YARN 基础架构</h3><p><img src="/2021/08/25/hadoop/image-20210909113318240.png" alt="image-20210909113318240"></p>
<ul>
<li>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件构成。</li>
<li>ResourceManager（RM）的主要作用如下：<ul>
<li>处理客户端请求。</li>
<li>监控 NodeManager。</li>
<li>启动或监控 ApplicationMaster。</li>
<li>资源的分配与调度。</li>
</ul>
</li>
<li>NodeManager（NM）的主要作用如下：<ul>
<li>管理单个节点上的资源。</li>
<li>处理来自 ResourceManager 的命令。</li>
<li>处理来自 ApplicationMaster 的命令。</li>
</ul>
</li>
<li>ApplicationMaster（AM）的主要作用如下：<ul>
<li>为应用程序申请资源并分配给内部的任务。</li>
<li>任务的监控与容错。</li>
</ul>
</li>
<li>Container 的主要作用如下：<ul>
<li>Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。</li>
</ul>
</li>
</ul>
<h3 id="YARN-工作机制"><a href="#YARN-工作机制" class="headerlink" title="YARN 工作机制"></a>YARN 工作机制</h3><p><img src="/2021/08/25/hadoop/image-20210909132534626.png" alt="image-20210909132534626"></p>
<ul>
<li>MapReduce 程序（任务分为 MapTask 和 ReduceTask）提交到客户端所在的节点，程序执行后创建一个 YarnRunner。</li>
<li>YarnRunner 向 ResourceManager 申请一个 Application。</li>
<li>ResourceManager 将该应用程序的资源提交路径返回给 YarnRunner。</li>
<li>该程序将运行所需资源（split 切片信息，xml 配置文件，JAR 包等）提交到 HDFS 上。</li>
<li>程序运行所需的资源提交到 HDFS 完毕后，再向 ResourceManager 申请运行 ApplicationMaster。</li>
<li>ResourceManager 将客户端（用户）的请求初始化成一个 Task。并将 Task 以及其他客户端的请求所初始化的 Task，都放到一个任务调度队列中（Apache Hadoop 默认使用容量调度器）。</li>
<li>集群中的一个空闲的 NodeManager，从任务调度队列中领取到 Task 任务。</li>
<li>然后，该 NodeManager 创建一个容器 Container，并启动一个 ApplicationMaster 进程。</li>
<li>Container 从 HDFS 上拷贝程序运行所需的资源到本地。</li>
<li>ApplicationMaster 进程拿到 Job 的切片信息之后，再向 ResourceManager 申请运行 MapTask 的资源（假设 MapTask 有两个任务）。</li>
<li>ResourceManager 将运行 MapTask 的任务分配给集群另外两个 NodeManager（也有可能是同一个 NodeManager 的两个 Container 上），这两个 NodeManager 分别领取任务并创建容器，并拷贝任务运行所需的 JAR 包等资源。</li>
<li>MapReduce 向两个接收到任务的 NodeManager 发送程序启动脚本，然后这两个 NodeManager 分别启动 MapTask，各自开启一个 YarnChild 子进程，之后，MapTask 开始执行，对数据分区排序。</li>
<li>ApplicationMaster 进程等待所有的 MapTask 运行完毕后，再向 ResourceManager 申请容器，运行 ReduceTask。这一步与运行 MapTask 的操作相同。</li>
<li>ReduceTask 启动时，向 MapTask 获取相应分区的数据，然后执行任务。</li>
<li>当程序运行完毕后，MapReduce 会向 ResourceManager 申请注销任务执行过程中所使用的资源。</li>
</ul>
<h3 id="作业提交全过程"><a href="#作业提交全过程" class="headerlink" title="作业提交全过程"></a>作业提交全过程</h3><ul>
<li><p>HDFS、YARN、MapReduce 三者关系</p>
<p><img src="/2021/08/25/hadoop/image-20210909152245552.png" alt="image-20210909152245552"></p>
</li>
<li><p>作业提交过程之 YARN</p>
<p><img src="/2021/08/25/hadoop/image-20210909132534626.png" alt="image-20210909132534626"></p>
</li>
<li><p>作业提交过程之 HDFS &amp; MapReduce</p>
<p><img src="/2021/08/25/hadoop/image-20210909153850477.png" alt="image-20210909153850477"></p>
</li>
<li><p>作业提交全过程详解</p>
<ul>
<li>作业提交：<ul>
<li>第 1 步：Client 调用 job.waitForCompletion 方法，向整个集群提交 MR 作业。</li>
<li>第 2 步：Client 向 RM 申请一个作业 id。</li>
<li>第 3 步：RM 给 Client 返回该 Job 资源的 HDFS 提交路径和作业 id。</li>
<li>第 4 步：Client 提交 JAR 包、切片信息和配置文件到指定的 HDFS 资源提交路径。</li>
<li>第 5 步：Client 提交完资源后，向 RM 申请运行 AM。</li>
</ul>
</li>
<li>作业初始化：<ul>
<li>第 6 步：当 RM 收到 Client 的请求后，将该 Job 添加到容量调度器中。</li>
<li>第 7 步：某一个空闲的 NM 领取到该 Job。</li>
<li>第 8 步：该 NM 创建 Container，并启动 AM 进程。</li>
<li>第 9 步：该 Container 下载 Client 提交到 HDFS 的资源到本地。</li>
</ul>
</li>
<li>任务分配：<ul>
<li>第 10 步：AM 向 RM 申请执行多个 MapTask 任务的资源。</li>
<li>第 11 步：RM 将运行 MapTask 的任务分配给相应的 NM，这些 NM 分别领取任务并创建 Container。</li>
</ul>
</li>
<li>任务运行：<ul>
<li>第 12 步：MR 向接收到任务的 NM 发送程序启动脚本，这些 NM 分别启动 MapTask，MapTask 对数据分区排序。</li>
<li>第 13 步：AM 等待所有 MapTask 运行完毕后，再向 RM 申请容器，运行 ReduceTask。</li>
<li>第 14 步：ReduceTask 向 MapTask 获取相应分区的数据。</li>
<li>第 15 步：程序运行完毕后，MR 向 RM 申请注销自己。</li>
</ul>
</li>
<li>进度和状态更新：<ul>
<li>YARN 中的任务将其进度和状态（包括 counter）返回给应用管理器, 客户端每秒（通过 <code>mapreduce.client.progressmonitor.pollinterval</code> 设置）向应用管理器请求进度更新，展示给用户。</li>
</ul>
</li>
<li>作业完成：<ul>
<li>除了向应用管理器请求作业进度外，客户端每 5 秒都会通过调用 <code>waitForCompletion()</code> 来检查作业是否完成。时间间隔可以通过 <code>mapreduce.client.completion.pollinterval</code> 来设置。作业完成之后，应用管理器和 Container 会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="YARN-调度器和调度算法"><a href="#YARN-调度器和调度算法" class="headerlink" title="YARN 调度器和调度算法"></a>YARN 调度器和调度算法</h3><ul>
<li><p>目前，Hadoop 提供的任务队列调度器主要有三种：先进先出调度器（FIFO）、容量调度器（Capacity Scheduler）和公平调度器（Fair Scheduler）。</p>
</li>
<li><p>Apache Hadoop-3.2.1 默认的资源调度器是 Capacity Scheduler，在 yarn-default.xml 文件中，有具体的配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Cloudera Hadoop 默认使用的调度器是 Fair Scheduler。</p>
</blockquote>
</li>
</ul>
<h4 id="先进先出调度器（FIFO）"><a href="#先进先出调度器（FIFO）" class="headerlink" title="先进先出调度器（FIFO）"></a>先进先出调度器（FIFO）</h4><p><img src="/2021/08/25/hadoop/image-20210909164336456.png" alt="image-20210909164336456"></p>
<ul>
<li>FIFO 调度器（First In First Out）：单队列，根据提交作业的先后顺序，先来的先服务。</li>
<li>优点：简单易懂。</li>
<li>缺点：不支持多队列，生产环境很少使用。</li>
</ul>
<h4 id="容量调度器（Capacity-Scheduler）"><a href="#容量调度器（Capacity-Scheduler）" class="headerlink" title="容量调度器（Capacity Scheduler）"></a>容量调度器（Capacity Scheduler）</h4><ul>
<li><p>Capacity Scheduler 是 Yahoo 开发的多用户调度器。</p>
</li>
<li><p>容量调度器的特点</p>
<p><img src="/2021/08/25/hadoop/image-20210909170809620.png" alt="image-20210909170809620"></p>
<ul>
<li>多队列：每个队列可配置一定的资源量，每个队列采用 FIFO 调度策略。</li>
<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上限。</li>
<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列（非强制回收）。</li>
<li>多租户：支持多用户共享集群和多应用程序同时运行。为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定。比如，queueC 队列中，有 ss 和 cls 两个用户提交的作业，调度器可以限制每一个用户所占的资源量为自身资源的 50%。</li>
</ul>
</li>
<li><p>容量调度器的队列的资源分配方式</p>
<ul>
<li>FIFO 策略，默认。<ul>
<li>具体的资源分配过程：<ul>
<li>第一步：队列资源分配。<ul>
<li>从 root 开始，使用深度优先算法，优先选择资源利用率最低（已使用的资源量/队列分配的资源容量）的队列分配资源。</li>
</ul>
</li>
<li>第二步：作业资源分配。<ul>
<li>默认按照提交作业的优先级和提交时间顺序分配资源。</li>
</ul>
</li>
<li>第三步：容器资源分配。<ul>
<li>按照容器的优先级分配资源。</li>
<li>如果容器的优先级相同，按照数据本地性原则（节点距离最小的）：<ul>
<li>任务和数据在同一节点。</li>
<li>任务和数据在同一机架。</li>
<li>任务和数据不在同一节点也不在同一机架。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>DRF 策略</li>
</ul>
</li>
<li><p>容量调度器的资源分配算法实例</p>
<p><img src="/2021/08/25/hadoop/image-20210909171256904.png" alt="image-20210909171256904"></p>
</li>
</ul>
<h4 id="公平调度器（Fair-Scheduler-）"><a href="#公平调度器（Fair-Scheduler-）" class="headerlink" title="公平调度器（Fair Scheduler ）"></a>公平调度器（Fair Scheduler ）</h4><ul>
<li><p>Fair Schedulere 是 Facebook 开发的多用户调度器。</p>
</li>
<li><p>公平调度器的特点</p>
<p><img src="/2021/08/25/hadoop/image-20210909173251464.png" alt="image-20210909173251464"></p>
<ul>
<li>与容量调度器的相同点<ul>
<li>多队列：支持多队列多作业。</li>
<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上限。</li>
<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列。</li>
<li>多租户：支持多用户共享集群和多应用程序同时运行。为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定。</li>
</ul>
</li>
<li>与容量调度器的不同点<ul>
<li>核心调度策略不同：<ul>
<li>容量调度器：优先选择资源利用率低的队列。</li>
<li>公平调度器：优先选择对资源的缺额比例大的。</li>
</ul>
</li>
<li>每个队列可以单独设置资源的分配方式不同：<ul>
<li>容量调度器：FIFO、DRF。</li>
<li>公平调度器：FIFO、FAIR、DRF。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>公平调度器的缺额概念</p>
<p><img src="/2021/08/25/hadoop/image-20210909234011348.png" alt="image-20210909234011348"></p>
<ul>
<li>公平调度器设计目标是：在时间尺度上，所有作业获得公平的资源。在某一时刻，一个作业应获取的资源和它实际获取的资源的差距叫“缺额”。</li>
<li>公平调度器会优先为缺额大的作业分配资源。</li>
</ul>
</li>
<li><p>公平调度器的队列的资源分配方式</p>
<ul>
<li><p>FIFO 策略</p>
<ul>
<li>公平调度器每个队列资源分配策略如果选择 FIFO 的话，此时公平调度器相当于上面讲过的容量调度器。</li>
</ul>
</li>
<li><p>Fair 策略，默认。</p>
<ul>
<li><p>Fair 策略是一种基于最大最小公平算法实现的资源多路复用方式，默认情况下，每个队列内部采用该方式分配资源。这意味着，如果一个队列中有两个应用程序同时运行，则每个应用程序可得到 1/2 的资源；如果三个应用程序同时运行，则每个应用程序可得到 1/3 的资源。</p>
</li>
<li><p>具体的资源分配过程和容量调度器一致：</p>
<ul>
<li><p>选择队列</p>
</li>
<li><p>选择作业</p>
</li>
<li><p>选择容器</p>
</li>
<li><p>注意：以上三步，每一步都是按照公平策略来分配资源。</p>
<p><img src="/2021/08/25/hadoop/image-20210910171552241.png" alt="image-20210910171552241"></p>
<ul>
<li>实际最小资源份额：<code>mindshare = Min(资源需求量, 配置的最小资源)</code></li>
<li>是否饥饿：<code>isNeedy = 资源使用量 &lt; mindshare</code></li>
<li>资源分配比：<code>minShareRatio = 资源使用量 / Max（mindshare, 1)</code></li>
<li>资源使用权重比：<code>useToWeightRatio = 资源使用量 / 权重</code></li>
<li>假设一个任务，其资源需求量为 4，配置的最小资源为 2，现在的资源使用量为 1，权重为 8。则 mindshare 为 2，因为资源使用量小于 mindshare，所以该任务处于饥饿状态。另外，其 minShareRatio 的值为 1/2，useToWeightRatio 值为 1/6。同理，计算出其他任务的这些状态值，按上图流程，决定资源优先分配到哪个任务。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>DRF 策略</p>
<ul>
<li>DRF（Dominant Resource Fairness），前面说的资源，都是单一标准，例如只考虑内存（也是 YARN 默认的情况）。但是很多时候资源有很多种，例如内存，CPU，网络带宽等，这样就很难衡量两个应用应该分配的资源比例。</li>
<li>在 YARN 中，用 DRF 来决定如何调度：<ul>
<li>假设集群一共有 100 CPU 和 10 T 内存，而应用 A 需要（2 CPU，300 GB 内存），应用 B 需要（6 CPU，100 GB 内存）。则两个应用分别需要 A（2% CPU，3% 内存）和 B（6% CPU，1% 内存）的资源，这就意味着 A 是内存主导的，B 是 CPU 主导的，针对这种情况，我们可以选择 DRF 策略对不同应用进行不同资源（CPU 和内存）的一个不同比例的限制。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>公平调度器的资源分配算法实例</p>
<p><img src="/2021/08/25/hadoop/image-20210910230253307.png" alt="image-20210910230253307"></p>
<ul>
<li>队列资源分配<ul>
<li>需求：集群总资源 100，有三个队列，对资源的需求分别是：queueA —&gt; 20，queueB —&gt; 50，queueC —&gt; 30。</li>
<li>第一次算：100 / 3 = 33.33，即每个队列应得资源 33.33。<ul>
<li>queueA：分 33.33  —&gt; 多 13.33。</li>
<li>queueB：分 33.33  —&gt; 少 16.67。</li>
<li>queueC：分 33.33  —&gt; 多 3.33。</li>
</ul>
</li>
<li>第二次算：(13.33 + 3.33) / 1 = 16.66，各队列空闲资源的总和，与需要资源的队列数的比值。<ul>
<li>queueA：分 20。</li>
<li>queueB：分 33.33 + 16.66 = 50。</li>
<li>queueC：分 30。</li>
</ul>
</li>
</ul>
</li>
<li>作业资源分配<ul>
<li>不加权（关注点是 job 的个数）<ul>
<li>需求：有一条队列总资源 12 个，有 4 个 job，对资源的需求分别是：job1 —&gt; 1，job2 —&gt; 2，job3 —&gt; 6，job4 —&gt; 5。</li>
<li>第一次算：12 / 4 = 3。<ul>
<li>job1：分 3 —&gt; 多 2 个。</li>
<li>job2：分 3 —&gt; 多 1 个。</li>
<li>job3：分 3 —&gt; 少 3 个。</li>
<li>job4：分 3 —&gt; 少 2 个。</li>
</ul>
</li>
<li>第二次算：3 / 2 = 1.5<ul>
<li>job1：分 1 —&gt; 最终：1。</li>
<li>job2：分 2 —&gt; 最终：2。</li>
<li>job3：分 3 —&gt; 少 3 个 —&gt; 分 1.5 —&gt; 最终：4.5。</li>
<li>job4：分 3 —&gt; 少 2 个 —&gt; 分 1.5 —&gt; 最终：4.5。</li>
</ul>
</li>
<li>job3 和 job4 的资源都不够，继续等待，运行过程中，有资源释放出来时，继续按平均计算。</li>
<li>第 n 次算：一直算到没有空闲资源。</li>
</ul>
</li>
<li>加权（ 关注点是 job 的权重）<ul>
<li>需求：有一条队列总资源 16 个，有 4 个 job，对资源的需求分别是：job1 —&gt; 4，job2 —&gt; 2，job3 —&gt;10，job4 —&gt; 4，每个 job 的权重为：job1 —&gt; 5，job2 —&gt; 8，job3 —&gt; 1，job4 —&gt; 2。</li>
<li>第一次算：16 / (5 + 8 + 1 + 2) = 1。<ul>
<li>job1：分 5 * 1 —&gt; 多 1 个。</li>
<li>job2：分 8 * 1 —&gt; 多 6 个。</li>
<li>job3：分 1 * 1 —&gt; 少 9 个。</li>
<li>job4：分 2 * 1 —&gt; 少 2 个。</li>
</ul>
</li>
<li>第二次算：7 / (1 + 2) = 7/3。<ul>
<li>job1：分 4。</li>
<li>job2：分 2。</li>
<li>job3：分 1 —&gt; 少 9 个 —&gt; 分 1 * 7/3 ≈ 2.33 —&gt; 少 6.67 个。</li>
<li>job4：分 2 —&gt; 少 2 个 —&gt; 分 2 * 7/3 ≈ 4.66 —&gt; 多 2.66 个。</li>
</ul>
</li>
<li>第三次算：2.66 / 1 = 2.66。<ul>
<li>job1：分 4 —&gt; 最终：4。</li>
<li>job2：分 2 —&gt; 最终：2。</li>
<li>job3：分 1 —&gt; 少 9 个 —&gt; 分 1 * 7/3 ≈ 2.33 —&gt; 少 6.67 个 —&gt; 分 1 * 2.66 —&gt; 最终：6。</li>
<li>job4：分 4 —&gt; 最终：4。</li>
</ul>
</li>
<li>job3 资源不够，继续等待，运行过程中，有资源释放出来时，继续按平均计算。</li>
<li>第 n 次算：一直算到没有空闲资源。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="YARN-常用命令"><a href="#YARN-常用命令" class="headerlink" title="YARN 常用命令"></a>YARN 常用命令</h3><ul>
<li>YARN 状态的查询，除了可以在 <a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088/</a> 页面查看外，还可以通过命令操作。</li>
</ul>
<h4 id="yarn-node-查看节点"><a href="#yarn-node-查看节点" class="headerlink" title="yarn node 查看节点"></a>yarn node 查看节点</h4><ul>
<li><p>列出所有节点</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn node -list -all</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yarn-queue-查看队列"><a href="#yarn-queue-查看队列" class="headerlink" title="yarn queue 查看队列"></a>yarn queue 查看队列</h4><ul>
<li><p>查询队列信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn queue -status &lt;QueueName&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yarn-application-查看任务"><a href="#yarn-application-查看任务" class="headerlink" title="yarn application 查看任务"></a>yarn application 查看任务</h4><ul>
<li><p>列出所有 Application</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn application -list</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据 Application 的状态查询</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn application -list -appStates [option]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>状态参数可选项有：ALL、NEW、NEW_SAVING、SUBMITTED、ACCEPTED、RUNNING、FINISHED、FAILED、KILLED。</p>
</blockquote>
</li>
<li><p>Kill Application</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn application -<span class="built_in">kill</span> [ApplicationId]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yarn-container-查看容器"><a href="#yarn-container-查看容器" class="headerlink" title="yarn container 查看容器"></a>yarn container 查看容器</h4><ul>
<li><p>列出所有 Container</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn container -list &lt;ApplicationId&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>打印 Container 状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn container -status &lt;ContainerId&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>只有在任务运行的过程中，才能看到 Container 的状态。如果任务运行结束了，Container 也就被回收了。</p>
</blockquote>
</li>
</ul>
<h4 id="yarn-logs-查看日志"><a href="#yarn-logs-查看日志" class="headerlink" title="yarn logs 查看日志"></a>yarn logs 查看日志</h4><ul>
<li><p>查询 Application 日志</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn logs -applicationId &lt;ApplicationId&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询 Container 日志</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn logs -applicationId &lt;ApplicationId&gt; -containerId &lt;ContainerId&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yarn-applicationattempt-查看尝试运行的任务"><a href="#yarn-applicationattempt-查看尝试运行的任务" class="headerlink" title="yarn applicationattempt 查看尝试运行的任务"></a>yarn applicationattempt 查看尝试运行的任务</h4><ul>
<li><p>列出所有 Application 尝试的列表</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn applicationattempt -list &lt;ApplicationId&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>打印 ApplicationAttemp 状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn applicationattempt -status &lt;ApplicationAttemptId&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yarn-rmadmin-更新配置"><a href="#yarn-rmadmin-更新配置" class="headerlink" title="yarn rmadmin 更新配置"></a>yarn rmadmin 更新配置</h4><ul>
<li><p>更新队列配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xisun@hadoop102 hadoop]$ yarn rmadmin -refreshQueues</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果修改了队列的相关信息，不需要重启 YARN，执行此命令即可生效。</p>
</blockquote>
</li>
</ul>
<h3 id="YARN-生产环境核心参数"><a href="#YARN-生产环境核心参数" class="headerlink" title="YARN 生产环境核心参数"></a>YARN 生产环境核心参数</h3><ul>
<li>ResourceManager 相关<ul>
<li><code>yarn.resourcemanager.scheduler.class</code>：配置调度器，Apache Hadoop 默认使用容量调度器。</li>
<li><code>yarn.resourcemanager.scheduler.client.thread-count</code>：ResourceManager 处理调度器请求的线程数量，默认 50。</li>
</ul>
</li>
<li>NodeManager 相关<ul>
<li><code>yarn.nodemanager.resource.detect-hardware-capabilities</code>：是否让 YARN 自己检测硬件进行配置，默认 false。</li>
<li><code>yarn.nodemanager.resource.count-logical-processors-as-cores</code>：是否将虚拟核数当作 CPU 核数，默认 false。<ul>
<li>虚拟 CPU 和物理 CPU。如果集群中的多台服务器，CPU 性能差距较大，可以考虑设置此参数为 true。</li>
</ul>
</li>
<li><code>yarn.nodemanager.resource.pcores-vcores-multiplier</code>：虚拟核数和物理核数乘数，例如：4 核 8 线程，该参数就应设为 2。默认为 1.0。如果上一个参数设置为 true，此参数按实际配置。</li>
<li><code>yarn.nodemanager.resource.memory-mb</code>：NodeManager 使用的内存，默认 8 G。</li>
<li><code>yarn.nodemanager.resource.system-reserved-memory-mb</code>：NodeManager 为系统保留多少内存（系统内存与使用内存的差值）。与上一个参数，二者配置一个即可。</li>
<li><code>yarn.nodemanager.resource.cpu-vcores</code>：NodeManager 使用的 CPU 核数，默认 8 个。</li>
<li><code>yarn.nodemanager.pmem-check-enabled</code>：是否开启物理内存检查限制 Container，默认打开。<ul>
<li>一种安全机制：如果 NodeManager 使用的内存，即将超过其可以使用的内存量时，触发报警机制，防止 NodeManager 占用虚拟机正常运行时的内存，导致系统崩溃。</li>
</ul>
</li>
<li><code>yarn.nodemanager.vmem-check-enabled</code>：是否开启虚拟内存检查限制 Container，默认打开。</li>
<li><code>yarn.nodemanager.vmem-pmem-ratio</code>：虚拟内存与物理内存的比例，默认 2.1。</li>
</ul>
</li>
<li>Container 相关<ul>
<li><code>yarn.scheduler.minimum-allocation-mb</code>：容器最小内存，默认 1 G。</li>
<li><code>yarn.scheduler.maximum-allocation-mb</code>：容器最大内存，默认 8 G。不能超过 NodeManager 能使用的内存。</li>
<li><code>yarn.scheduler.minimum-allocation-vcores</code>：容器最小 CPU 核数，默认 1 个。</li>
<li><code>yarn.scheduler.maximum-allocation-vcores</code>：容器最大 CPU 核数，默认 4 个。</li>
</ul>
</li>
</ul>
<h2 id="YARN-案例实操"><a href="#YARN-案例实操" class="headerlink" title="YARN 案例实操"></a>YARN 案例实操</h2><ul>
<li><p>调整下列参数之前尽量拍摄 Linux 快照，否则后续的案例，还需要重新准备集群。</p>
<p><img src="/2021/08/25/hadoop/image-20210912181004046.png" alt="image-20210912181004046"></p>
<p><img src="/2021/08/25/hadoop/image-20210912180732521.png" alt="image-20210912180732521"></p>
<p><img src="/2021/08/25/hadoop/image-20210912180838645.png" alt="image-20210912180838645"></p>
</li>
</ul>
<h3 id="YARN-生产环境核心参数配置案例"><a href="#YARN-生产环境核心参数配置案例" class="headerlink" title="YARN 生产环境核心参数配置案例"></a>YARN 生产环境核心参数配置案例</h3><ul>
<li>需求：从 1 G 数据中，统计每个单词出现的次数。服务器 3 台，每台配置 4 G 内存，4 核 CPU，4 线程。</li>
</ul>
<h2 id="本文参考"><a href="#本文参考" class="headerlink" title="本文参考"></a>本文参考</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Qp4y1n7EN">https://www.bilibili.com/video/BV1Qp4y1n7EN</a></p>
<p>声明：写作本文初衷是个人学习记录，鉴于本人学识有限，如有侵权或不当之处，请联系 <a href="mailto:wdshfut@163.com">wdshfut@163.com</a>。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/08/25/movie/" rel="prev" title="movie">
      <i class="fa fa-chevron-left"></i> movie
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/08/26/linux-virtualmachine/" rel="next" title="虚拟机安装">
      虚拟机安装 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">1.</span> <span class="nav-text">大数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5"><span class="nav-number">1.1.</span> <span class="nav-text">大数据概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%89%B9%E7%82%B9"><span class="nav-number">1.2.</span> <span class="nav-text">大数据特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-%E6%A6%82%E8%BF%B0"><span class="nav-number">2.</span> <span class="nav-text">Hadoop 概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">2.1.</span> <span class="nav-text">Hadoop 是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><span class="nav-number">2.2.</span> <span class="nav-text">Hadoop 发展历史</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC"><span class="nav-number">2.3.</span> <span class="nav-text">Hadoop 三大发行版本</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Apache-Hadoop"><span class="nav-number">2.3.1.</span> <span class="nav-text">Apache Hadoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cloudera-Hadoop"><span class="nav-number">2.3.2.</span> <span class="nav-text">Cloudera Hadoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hortonworks-Hadoop"><span class="nav-number">2.3.3.</span> <span class="nav-text">Hortonworks Hadoop</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E4%BC%98%E5%8A%BF"><span class="nav-number">2.4.</span> <span class="nav-text">Hadoop 优势</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E7%BB%84%E6%88%90"><span class="nav-number">2.5.</span> <span class="nav-text">Hadoop 组成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">2.5.1.</span> <span class="nav-text">HDFS 架构概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">2.5.2.</span> <span class="nav-text">YARN 架构概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">2.5.3.</span> <span class="nav-text">MapReduce 架构概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E3%80%81YARN-%E3%80%81MapReduce-%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB"><span class="nav-number">2.5.4.</span> <span class="nav-text">HDFS 、YARN 、MapReduce 三者关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB"><span class="nav-number">2.6.</span> <span class="nav-text">大数据技术生态体系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%A1%86%E6%9E%B6%E5%9B%BE"><span class="nav-number">2.7.</span> <span class="nav-text">推荐系统框架图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-number">3.</span> <span class="nav-text">Hadoop 运行环境搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E6%9D%BF%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">3.1.</span> <span class="nav-text">模板虚拟机环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="nav-number">3.2.</span> <span class="nav-text">克隆虚拟机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-JDK"><span class="nav-number">3.3.</span> <span class="nav-text">安装 JDK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Hadoop"><span class="nav-number">3.4.</span> <span class="nav-text">安装 Hadoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-number">3.5.</span> <span class="nav-text">Hadoop 目录结构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="nav-number">4.</span> <span class="nav-text">Hadoop 运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="nav-number">4.1.</span> <span class="nav-text">本地模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F"><span class="nav-number">4.2.</span> <span class="nav-text">完全分布式模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%87%86%E5%A4%87"><span class="nav-number">4.2.1.</span> <span class="nav-text">虚拟机准备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC-xsync"><span class="nav-number">4.2.2.</span> <span class="nav-text">编写集群分发脚本 xsync</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#scp%EF%BC%88secure-copy%EF%BC%89%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">scp（secure copy）安全拷贝</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#rsync-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">rsync 远程同步工具</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#xsync-%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="nav-number">4.2.2.3.</span> <span class="nav-text">xsync 集群分发脚本</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="nav-number">4.2.3.</span> <span class="nav-text">ssh 免密登录配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE"><span class="nav-number">4.2.4.</span> <span class="nav-text">集群配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="nav-number">4.2.4.1.</span> <span class="nav-text">集群部署规划</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="nav-number">4.2.4.2.</span> <span class="nav-text">配置文件说明</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="nav-number">4.2.4.3.</span> <span class="nav-text">配置集群</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BE%A4%E8%B5%B7%E9%9B%86%E7%BE%A4"><span class="nav-number">4.2.5.</span> <span class="nav-text">群起集群</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-workers"><span class="nav-number">4.2.5.1.</span> <span class="nav-text">配置 workers</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="nav-number">4.2.5.2.</span> <span class="nav-text">启动集群</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95"><span class="nav-number">4.2.5.3.</span> <span class="nav-text">集群基本测试</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">4.2.6.</span> <span class="nav-text">配置历史服务器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86"><span class="nav-number">4.2.7.</span> <span class="nav-text">配置日志的聚集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93"><span class="nav-number">4.2.8.</span> <span class="nav-text">集群启动&#x2F;停止方式总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E5%86%99-Hadoop-%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC"><span class="nav-number">4.2.9.</span> <span class="nav-text">编写 Hadoop 集群常用脚本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="nav-number">4.2.10.</span> <span class="nav-text">常用端口号和配置文件说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="nav-number">4.2.11.</span> <span class="nav-text">集群时间同步</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-%E6%A6%82%E8%BF%B0"><span class="nav-number">5.</span> <span class="nav-text">HDFS 概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E4%BA%A7%E7%94%9F%E8%83%8C%E6%99%AF%E5%8F%8A%E5%AE%9A%E4%B9%89"><span class="nav-number">5.1.</span> <span class="nav-text">HDFS 产生背景及定义</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E4%BA%A7%E7%94%9F%E8%83%8C%E6%99%AF"><span class="nav-number">5.1.1.</span> <span class="nav-text">HDFS 产生背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E5%AE%9A%E4%B9%89"><span class="nav-number">5.1.2.</span> <span class="nav-text">HDFS 定义</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">5.2.</span> <span class="nav-text">HDFS 优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E4%BC%98%E7%82%B9"><span class="nav-number">5.2.1.</span> <span class="nav-text">HDFS 优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-%E7%BC%BA%E7%82%B9"><span class="nav-number">5.2.2.</span> <span class="nav-text">HDFS 缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="nav-number">5.3.</span> <span class="nav-text">HDFS 组成架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="nav-number">5.4.</span> <span class="nav-text">HDFS 文件块大小</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-%E7%9A%84-Shell-%E6%93%8D%E4%BD%9C"><span class="nav-number">6.</span> <span class="nav-text">HDFS 的 Shell 操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="nav-number">6.1.</span> <span class="nav-text">基本语法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8"><span class="nav-number">6.2.</span> <span class="nav-text">命令大全</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">6.3.</span> <span class="nav-text">常用命令</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E5%B8%AE%E5%8A%A9"><span class="nav-number">6.3.1.</span> <span class="nav-text">查看帮助</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E6%93%8D%E4%BD%9C-HDFS"><span class="nav-number">6.3.2.</span> <span class="nav-text">直接操作 HDFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0%E5%88%B0-HDFS"><span class="nav-number">6.3.3.</span> <span class="nav-text">上传到 HDFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E8%87%B3-HDFS"><span class="nav-number">6.3.4.</span> <span class="nav-text">下载至 HDFS</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-%E7%9A%84-API-%E6%93%8D%E4%BD%9C"><span class="nav-number">7.</span> <span class="nav-text">HDFS 的 API 操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">7.1.</span> <span class="nav-text">客户端环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA"><span class="nav-number">7.2.</span> <span class="nav-text">项目创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="nav-number">7.3.</span> <span class="nav-text">案例实操</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="nav-number">7.3.1.</span> <span class="nav-text">创建目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0"><span class="nav-number">7.3.2.</span> <span class="nav-text">文件上传</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="nav-number">7.3.3.</span> <span class="nav-text">文件下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%88%A0%E9%99%A4"><span class="nav-number">7.3.4.</span> <span class="nav-text">文件删除</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E7%9A%84%E6%9B%B4%E5%90%8D%E5%92%8C%E7%A7%BB%E5%8A%A8"><span class="nav-number">7.3.5.</span> <span class="nav-text">文件的更名和移动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E8%AF%A6%E6%83%85%E6%9F%A5%E7%9C%8B"><span class="nav-number">7.3.6.</span> <span class="nav-text">文件详情查看</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD"><span class="nav-number">7.3.7.</span> <span class="nav-text">文件和文件夹类型判断</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B"><span class="nav-number">8.</span> <span class="nav-text">HDFS 的读写流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-number">8.1.</span> <span class="nav-text">HDFS 写数据流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="nav-number">8.1.1.</span> <span class="nav-text">网络拓扑 - 节点距离计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5-%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9"><span class="nav-number">8.1.2.</span> <span class="nav-text">机架感知 - 副本存储节点选择</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-number">8.2.</span> <span class="nav-text">HDFS 读数据流程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NameNode-%E5%92%8C-SecondaryNameNode"><span class="nav-number">9.</span> <span class="nav-text">NameNode 和 SecondaryNameNode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NN-%E5%92%8C-2NN-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">9.1.</span> <span class="nav-text">NN 和 2NN 工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fsimage-%E5%92%8C-Edits-%E8%A7%A3%E6%9E%90"><span class="nav-number">9.2.</span> <span class="nav-text">Fsimage 和 Edits 解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Fsimage-%E5%92%8C-Edits-%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-number">9.2.1.</span> <span class="nav-text">Fsimage 和 Edits 的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oiv-%E6%9F%A5%E7%9C%8B-Fsimage-%E6%96%87%E4%BB%B6"><span class="nav-number">9.2.2.</span> <span class="nav-text">oiv 查看 Fsimage 文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oev-%E6%9F%A5%E7%9C%8B-Edits-%E6%96%87%E4%BB%B6"><span class="nav-number">9.2.3.</span> <span class="nav-text">oev 查看 Edits 文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CheckPoint-%E6%97%B6%E9%97%B4%E8%AE%BE%E7%BD%AE"><span class="nav-number">9.3.</span> <span class="nav-text">CheckPoint 时间设置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataNode"><span class="nav-number">10.</span> <span class="nav-text">DataNode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DataNode-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">10.1.</span> <span class="nav-text">DataNode 工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="nav-number">10.2.</span> <span class="nav-text">数据完整性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%89%E7%BA%BF%E6%97%B6%E9%99%90%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="nav-number">10.3.</span> <span class="nav-text">掉线时限参数设置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YARN-%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="nav-number">11.</span> <span class="nav-text">YARN 资源调度器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="nav-number">11.1.</span> <span class="nav-text">YARN 基础架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">11.2.</span> <span class="nav-text">YARN 工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E5%85%A8%E8%BF%87%E7%A8%8B"><span class="nav-number">11.3.</span> <span class="nav-text">作业提交全过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E8%B0%83%E5%BA%A6%E5%99%A8%E5%92%8C%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="nav-number">11.4.</span> <span class="nav-text">YARN 调度器和调度算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%88%E8%BF%9B%E5%85%88%E5%87%BA%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88FIFO%EF%BC%89"><span class="nav-number">11.4.1.</span> <span class="nav-text">先进先出调度器（FIFO）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%B9%E9%87%8F%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88Capacity-Scheduler%EF%BC%89"><span class="nav-number">11.4.2.</span> <span class="nav-text">容量调度器（Capacity Scheduler）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88Fair-Scheduler-%EF%BC%89"><span class="nav-number">11.4.3.</span> <span class="nav-text">公平调度器（Fair Scheduler ）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">11.5.</span> <span class="nav-text">YARN 常用命令</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-node-%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9"><span class="nav-number">11.5.1.</span> <span class="nav-text">yarn node 查看节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-queue-%E6%9F%A5%E7%9C%8B%E9%98%9F%E5%88%97"><span class="nav-number">11.5.2.</span> <span class="nav-text">yarn queue 查看队列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-application-%E6%9F%A5%E7%9C%8B%E4%BB%BB%E5%8A%A1"><span class="nav-number">11.5.3.</span> <span class="nav-text">yarn application 查看任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-container-%E6%9F%A5%E7%9C%8B%E5%AE%B9%E5%99%A8"><span class="nav-number">11.5.4.</span> <span class="nav-text">yarn container 查看容器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-logs-%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97"><span class="nav-number">11.5.5.</span> <span class="nav-text">yarn logs 查看日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-applicationattempt-%E6%9F%A5%E7%9C%8B%E5%B0%9D%E8%AF%95%E8%BF%90%E8%A1%8C%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="nav-number">11.5.6.</span> <span class="nav-text">yarn applicationattempt 查看尝试运行的任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yarn-rmadmin-%E6%9B%B4%E6%96%B0%E9%85%8D%E7%BD%AE"><span class="nav-number">11.5.7.</span> <span class="nav-text">yarn rmadmin 更新配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0"><span class="nav-number">11.6.</span> <span class="nav-text">YARN 生产环境核心参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YARN-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="nav-number">12.</span> <span class="nav-text">YARN 案例实操</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%A1%88%E4%BE%8B"><span class="nav-number">12.1.</span> <span class="nav-text">YARN 生产环境核心参数配置案例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E5%8F%82%E8%80%83"><span class="nav-number">13.</span> <span class="nav-text">本文参考</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="XiSun"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">XiSun</p>
  <div class="site-description" itemprop="description">心如止水者，虽世间繁华之红尘纷扰，已然空无一物</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XiSun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1.8m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">27:20</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
